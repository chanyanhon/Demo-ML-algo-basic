{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fbad0f0",
   "metadata": {},
   "source": [
    "# Dataset background information\n",
    "\n",
    "Telco customer churn dataset:\n",
    "\n",
    "The Telco customer churn data contains information about a fictional telco company that provided home phone and Internet services to 7043 customers in California in Q3. It indicates which customers have left, stayed, or signed up for their service. Multiple important demographics are included for each customer, as well as a Satisfaction Score, Churn Score, and Customer Lifetime Value (CLTV) index.\n",
    "\n",
    "## Data-dictionary\n",
    "\n",
    "Each row represents a customer, each column contains customer’s attributes.\n",
    "\n",
    "The data set includes information about:\n",
    "\n",
    "- Customers who left within the last month – the column is called Churn\n",
    "- Services that each customer has signed up for – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n",
    "- Customer account information – how long they’ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n",
    "- Demographic info about customers – gender, age range, and if they have partners and dependents\n",
    "\n",
    "\n",
    "# Objective of analysis\n",
    "\n",
    "\"Predict behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs.\"  The benefit of this analysis will be keeping the old customers renewing program to increase the customer lifetime value (CLV).\n",
    "\n",
    "So in our modelling, we have to locate & approach the churned customers before they perform churning action. \n",
    "\n",
    "For the modelling details, we will use deep learning models with different hyperparameter to classify the customers.\n",
    "\n",
    "This dataset is detailed in:\n",
    "https://community.ibm.com/community/user/businessanalytics/blogs/steven-macko/2019/07/11/telco-customer-churn-1113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01286cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bbbf0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip3 install tensorflow\n",
    "\n",
    "## Import Keras objects for Deep Learning\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a14c30f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7043, 21)\n",
      "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
      "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
      "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
      "3  7795-CFOCW    Male              0      No         No      45           No   \n",
      "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
      "\n",
      "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
      "0  No phone service             DSL             No  ...               No   \n",
      "1                No             DSL            Yes  ...              Yes   \n",
      "2                No             DSL            Yes  ...               No   \n",
      "3  No phone service             DSL            Yes  ...              Yes   \n",
      "4                No     Fiber optic             No  ...               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
      "0          No          No              No  Month-to-month              Yes   \n",
      "1          No          No              No        One year               No   \n",
      "2          No          No              No  Month-to-month              Yes   \n",
      "3         Yes          No              No        One year               No   \n",
      "4          No          No              No  Month-to-month              Yes   \n",
      "\n",
      "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
      "0           Electronic check          29.85         29.85    No  \n",
      "1               Mailed check          56.95        1889.5    No  \n",
      "2               Mailed check          53.85        108.15   Yes  \n",
      "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
      "4           Electronic check          70.70        151.65   Yes  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "customerID           object\n",
      "gender               object\n",
      "SeniorCitizen         int64\n",
      "Partner              object\n",
      "Dependents           object\n",
      "tenure                int64\n",
      "PhoneService         object\n",
      "MultipleLines        object\n",
      "InternetService      object\n",
      "OnlineSecurity       object\n",
      "OnlineBackup         object\n",
      "DeviceProtection     object\n",
      "TechSupport          object\n",
      "StreamingTV          object\n",
      "StreamingMovies      object\n",
      "Contract             object\n",
      "PaperlessBilling     object\n",
      "PaymentMethod        object\n",
      "MonthlyCharges      float64\n",
      "TotalCharges         object\n",
      "Churn                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# import files & check out the details\n",
    "\n",
    "data = pd.read_csv('Telco_Customer_Churn.csv')\n",
    "print(data.shape)\n",
    "print(data.head())\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d03762b",
   "metadata": {},
   "source": [
    "# Table of contents for analysis\n",
    "\n",
    "In this analysis, we will first conduct \n",
    "\n",
    "    1. Feature engineeering\n",
    "    2. Pre-processing\n",
    "    3. StratifiedShuffle train-test-Spli\n",
    "    4. Get a baseline performance using Random Forest\n",
    "    5. Build a Single Hidden Layer Neural Network\n",
    "    6. Support vector machine\n",
    "    7. model evaluation & insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055bfd2f",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76ef1d4",
   "metadata": {},
   "source": [
    "### change datatype of \"TotalCharges\" from object to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fe96666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# change datatype of \"TotalCharges\" from object to float\n",
    "\n",
    "# find the missing values - by null\n",
    "print(data.TotalCharges.isnull().sum())\n",
    "\n",
    "# find the missing values - by empty string\n",
    "print(data.TotalCharges.str.isspace().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08189c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim the empty string\n",
    "data.TotalCharges = data.TotalCharges.str.strip()\n",
    "\n",
    "# change datatype\n",
    "data['TotalCharges'] = pd.to_numeric(data.TotalCharges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccea3d85",
   "metadata": {},
   "source": [
    "### checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "045665ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customerID           0\n",
      "gender               0\n",
      "SeniorCitizen        0\n",
      "Partner              0\n",
      "Dependents           0\n",
      "tenure               0\n",
      "PhoneService         0\n",
      "MultipleLines        0\n",
      "InternetService      0\n",
      "OnlineSecurity       0\n",
      "OnlineBackup         0\n",
      "DeviceProtection     0\n",
      "TechSupport          0\n",
      "StreamingTV          0\n",
      "StreamingMovies      0\n",
      "Contract             0\n",
      "PaperlessBilling     0\n",
      "PaymentMethod        0\n",
      "MonthlyCharges       0\n",
      "TotalCharges        11\n",
      "Churn                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# find the missing values - by null\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0566d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rorws with missing values\n",
    "data = data.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf0f970",
   "metadata": {},
   "source": [
    "### dropping meaningless column (e.g. customerID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "230157e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID          7032\n",
       "gender                 2\n",
       "SeniorCitizen          2\n",
       "Partner                2\n",
       "Dependents             2\n",
       "tenure                72\n",
       "PhoneService           2\n",
       "MultipleLines          3\n",
       "InternetService        3\n",
       "OnlineSecurity         3\n",
       "OnlineBackup           3\n",
       "DeviceProtection       3\n",
       "TechSupport            3\n",
       "StreamingTV            3\n",
       "StreamingMovies        3\n",
       "Contract               3\n",
       "PaperlessBilling       2\n",
       "PaymentMethod          4\n",
       "MonthlyCharges      1584\n",
       "TotalCharges        6530\n",
       "Churn                  2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for object features, filtering for meaningful variables (remove column with unique values e.g. customerID)\n",
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32d5d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop customerID before one-hot encoding\n",
    "data = data.drop(['customerID'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd533c2",
   "metadata": {},
   "source": [
    "### 1/0 transformation for target variable -- Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5196c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change from yes/no to 1/0 for target column\n",
    "data['Churn'] = data.Churn.apply(lambda x: 1 if x == 'Yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e3cb2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5163\n",
       "1    1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5db23c0",
   "metadata": {},
   "source": [
    "### One-hot encoding for categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d2e7b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     15\n",
       "int64       3\n",
       "float64     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing datatypes summary of all columns\n",
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5b283b",
   "metadata": {},
   "source": [
    "There are 16 categorical features which potentially needs one-hot encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81f9cb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting list of object column\n",
    "obj_col_list = data.dtypes[data.dtypes == np.object].index.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5dc64d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SeniorCitizen  tenure  MonthlyCharges  TotalCharges  Churn  gender_Male  \\\n",
      "0              0       1           29.85         29.85      0            0   \n",
      "1              0      34           56.95       1889.50      0            1   \n",
      "2              0       2           53.85        108.15      1            1   \n",
      "3              0      45           42.30       1840.75      0            1   \n",
      "4              0       2           70.70        151.65      1            0   \n",
      "\n",
      "   Partner_Yes  Dependents_Yes  PhoneService_Yes  \\\n",
      "0            1               0                 0   \n",
      "1            0               0                 1   \n",
      "2            0               0                 1   \n",
      "3            0               0                 0   \n",
      "4            0               0                 1   \n",
      "\n",
      "   MultipleLines_No phone service  ...  StreamingTV_No internet service  \\\n",
      "0                               1  ...                                0   \n",
      "1                               0  ...                                0   \n",
      "2                               0  ...                                0   \n",
      "3                               1  ...                                0   \n",
      "4                               0  ...                                0   \n",
      "\n",
      "   StreamingTV_Yes  StreamingMovies_No internet service  StreamingMovies_Yes  \\\n",
      "0                0                                    0                    0   \n",
      "1                0                                    0                    0   \n",
      "2                0                                    0                    0   \n",
      "3                0                                    0                    0   \n",
      "4                0                                    0                    0   \n",
      "\n",
      "   Contract_One year  Contract_Two year  PaperlessBilling_Yes  \\\n",
      "0                  0                  0                     1   \n",
      "1                  1                  0                     0   \n",
      "2                  0                  0                     1   \n",
      "3                  1                  0                     0   \n",
      "4                  0                  0                     1   \n",
      "\n",
      "   PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
      "0                                      0                               1   \n",
      "1                                      0                               0   \n",
      "2                                      0                               0   \n",
      "3                                      0                               0   \n",
      "4                                      0                               1   \n",
      "\n",
      "   PaymentMethod_Mailed check  \n",
      "0                           0  \n",
      "1                           1  \n",
      "2                           1  \n",
      "3                           0  \n",
      "4                           0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding\n",
    "data_oh = pd.get_dummies(data, columns = obj_col_list ,drop_first=True)\n",
    "print(data_oh.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eee63ac",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dcbaf7",
   "metadata": {},
   "source": [
    "For column not in 1/0 (i.e.  'tenure','MonthlyCharges','TotalCharges' ) , we conduct min-max scaling for these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50b2ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features columns\n",
    "cols_without_target =  ['Churn'] \n",
    "cols_with_target = ['Churn']\n",
    "\n",
    "# exclude column1, column2, ...\n",
    "feature_df = data_oh.loc[:, ~data_oh.columns.isin(cols_without_target)]\n",
    "target_df = data_oh.loc[:, data_oh.columns.isin(cols_with_target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49844b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm = MinMaxScaler()\n",
    "\n",
    "for column in ['tenure','MonthlyCharges','TotalCharges' ]:\n",
    "    feature_df[column] = mm.fit_transform(feature_df[[column]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75322a74",
   "metadata": {},
   "source": [
    "KNN & SVM are highly deviated by imbalanced dataset. We have to resample the dataset, making our target variable clalss in 50-50 ratio to have better evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bd43a8",
   "metadata": {},
   "source": [
    "## StratifiedShuffle train-test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "510c8107",
   "metadata": {},
   "outputs": [],
   "source": [
    "## performing train-test split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Get the split indexes\n",
    "strat_shuf_split = StratifiedShuffleSplit(n_splits=1, \n",
    "                                          test_size=0.3, \n",
    "                                          random_state=42)\n",
    "\n",
    "train_idx, test_idx = next(strat_shuf_split.split(feature_df, target_df))\n",
    "\n",
    "# Create the dataframes\n",
    "X_train = feature_df.loc[train_idx, :]\n",
    "y_train = target_df.loc[train_idx]\n",
    "\n",
    "X_test  = feature_df.loc[test_idx, :]\n",
    "y_test  = target_df.loc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89857c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### resampling to have the balanced dataset -- Churn: not churn = 50:50  from imblearn.over_sampling import SMOTE \n",
    "from imblearn.over_sampling import SMOTE \n",
    "sm = SMOTE(random_state=42)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f50f2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_value_ratio: Churn\n",
      "0        0.5\n",
      "1        0.5\n",
      "dtype: float64 \n",
      "\n",
      "y_test_value_ratio: Churn\n",
      "0        0.734123\n",
      "1        0.265877\n",
      "dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('y_train_value_ratio:', y_train.value_counts(normalize=True) , '\\n')\n",
    "print('y_test_value_ratio:', y_test.value_counts(normalize=True) , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1e7205",
   "metadata": {},
   "source": [
    "## Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a96dd3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "814cdb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.769\n",
      "roc-auc is 0.814\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9da4745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b84b85",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 30 variables, so we set the input shape to 30.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17dabf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9781b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 30-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (30,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a603f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                372       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 385\n",
      "Trainable params: 385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3570efc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "226/226 [==============================] - 2s 5ms/step - loss: 0.6608 - accuracy: 0.5982 - val_loss: 0.6945 - val_accuracy: 0.4919\n",
      "Epoch 2/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.6332 - accuracy: 0.6608 - val_loss: 0.6532 - val_accuracy: 0.6588\n",
      "Epoch 3/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.6133 - accuracy: 0.7298 - val_loss: 0.6272 - val_accuracy: 0.7085\n",
      "Epoch 4/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.5974 - accuracy: 0.7460 - val_loss: 0.6096 - val_accuracy: 0.7152\n",
      "Epoch 5/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.5840 - accuracy: 0.7518 - val_loss: 0.5964 - val_accuracy: 0.7161\n",
      "Epoch 6/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.5724 - accuracy: 0.7568 - val_loss: 0.5858 - val_accuracy: 0.7166\n",
      "Epoch 7/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.5624 - accuracy: 0.7608 - val_loss: 0.5776 - val_accuracy: 0.7199\n",
      "Epoch 8/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.5535 - accuracy: 0.7638 - val_loss: 0.5699 - val_accuracy: 0.7218\n",
      "Epoch 9/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.5457 - accuracy: 0.7656 - val_loss: 0.5636 - val_accuracy: 0.7218\n",
      "Epoch 10/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.5387 - accuracy: 0.7685 - val_loss: 0.5586 - val_accuracy: 0.7218\n",
      "Epoch 11/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.5324 - accuracy: 0.7694 - val_loss: 0.5538 - val_accuracy: 0.7218\n",
      "Epoch 12/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.5268 - accuracy: 0.7708 - val_loss: 0.5489 - val_accuracy: 0.7237\n",
      "Epoch 13/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.5217 - accuracy: 0.7716 - val_loss: 0.5458 - val_accuracy: 0.7246\n",
      "Epoch 14/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.5172 - accuracy: 0.7731 - val_loss: 0.5423 - val_accuracy: 0.7246\n",
      "Epoch 15/200\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.5131 - accuracy: 0.7734 - val_loss: 0.5387 - val_accuracy: 0.7265\n",
      "Epoch 16/200\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.5094 - accuracy: 0.7746 - val_loss: 0.5366 - val_accuracy: 0.7270\n",
      "Epoch 17/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.5061 - accuracy: 0.7759 - val_loss: 0.5341 - val_accuracy: 0.7280\n",
      "Epoch 18/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.5030 - accuracy: 0.7760 - val_loss: 0.5323 - val_accuracy: 0.7294\n",
      "Epoch 19/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.5003 - accuracy: 0.7761 - val_loss: 0.5307 - val_accuracy: 0.7299\n",
      "Epoch 20/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4977 - accuracy: 0.7764 - val_loss: 0.5291 - val_accuracy: 0.7308\n",
      "Epoch 21/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4955 - accuracy: 0.7770 - val_loss: 0.5276 - val_accuracy: 0.7327\n",
      "Epoch 22/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4934 - accuracy: 0.7767 - val_loss: 0.5262 - val_accuracy: 0.7341\n",
      "Epoch 23/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4914 - accuracy: 0.7773 - val_loss: 0.5245 - val_accuracy: 0.7346\n",
      "Epoch 24/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4897 - accuracy: 0.7768 - val_loss: 0.5233 - val_accuracy: 0.7370\n",
      "Epoch 25/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4880 - accuracy: 0.7773 - val_loss: 0.5225 - val_accuracy: 0.7374\n",
      "Epoch 26/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4865 - accuracy: 0.7778 - val_loss: 0.5218 - val_accuracy: 0.7384\n",
      "Epoch 27/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4851 - accuracy: 0.7784 - val_loss: 0.5211 - val_accuracy: 0.7379\n",
      "Epoch 28/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4838 - accuracy: 0.7785 - val_loss: 0.5202 - val_accuracy: 0.7393\n",
      "Epoch 29/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4826 - accuracy: 0.7797 - val_loss: 0.5198 - val_accuracy: 0.7393\n",
      "Epoch 30/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4815 - accuracy: 0.7799 - val_loss: 0.5194 - val_accuracy: 0.7384\n",
      "Epoch 31/200\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4804 - accuracy: 0.7800 - val_loss: 0.5188 - val_accuracy: 0.7389\n",
      "Epoch 32/200\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4794 - accuracy: 0.7802 - val_loss: 0.5185 - val_accuracy: 0.7393\n",
      "Epoch 33/200\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4785 - accuracy: 0.7806 - val_loss: 0.5181 - val_accuracy: 0.7408\n",
      "Epoch 34/200\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4776 - accuracy: 0.7813 - val_loss: 0.5179 - val_accuracy: 0.7408\n",
      "Epoch 35/200\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4768 - accuracy: 0.7813 - val_loss: 0.5176 - val_accuracy: 0.7398\n",
      "Epoch 36/200\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4760 - accuracy: 0.7809 - val_loss: 0.5173 - val_accuracy: 0.7398\n",
      "Epoch 37/200\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4752 - accuracy: 0.7818 - val_loss: 0.5167 - val_accuracy: 0.7398\n",
      "Epoch 38/200\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4745 - accuracy: 0.7817 - val_loss: 0.5165 - val_accuracy: 0.7403\n",
      "Epoch 39/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4738 - accuracy: 0.7824 - val_loss: 0.5157 - val_accuracy: 0.7393\n",
      "Epoch 40/200\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4732 - accuracy: 0.7818 - val_loss: 0.5154 - val_accuracy: 0.7398\n",
      "Epoch 41/200\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4725 - accuracy: 0.7821 - val_loss: 0.5153 - val_accuracy: 0.7403\n",
      "Epoch 42/200\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.4719 - accuracy: 0.7827 - val_loss: 0.5149 - val_accuracy: 0.7403\n",
      "Epoch 43/200\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4714 - accuracy: 0.7829 - val_loss: 0.5149 - val_accuracy: 0.7412\n",
      "Epoch 44/200\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4708 - accuracy: 0.7828 - val_loss: 0.5147 - val_accuracy: 0.7412\n",
      "Epoch 45/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4703 - accuracy: 0.7835 - val_loss: 0.5146 - val_accuracy: 0.7412\n",
      "Epoch 46/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4698 - accuracy: 0.7836 - val_loss: 0.5139 - val_accuracy: 0.7427\n",
      "Epoch 47/200\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4693 - accuracy: 0.7839 - val_loss: 0.5134 - val_accuracy: 0.7427\n",
      "Epoch 48/200\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4688 - accuracy: 0.7836 - val_loss: 0.5136 - val_accuracy: 0.7427\n",
      "Epoch 49/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4684 - accuracy: 0.7844 - val_loss: 0.5137 - val_accuracy: 0.7427\n",
      "Epoch 50/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4679 - accuracy: 0.7839 - val_loss: 0.5137 - val_accuracy: 0.7431\n",
      "Epoch 51/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4675 - accuracy: 0.7843 - val_loss: 0.5134 - val_accuracy: 0.7431\n",
      "Epoch 52/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4671 - accuracy: 0.7840 - val_loss: 0.5135 - val_accuracy: 0.7417\n",
      "Epoch 53/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4667 - accuracy: 0.7849 - val_loss: 0.5132 - val_accuracy: 0.7422\n",
      "Epoch 54/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4663 - accuracy: 0.7846 - val_loss: 0.5131 - val_accuracy: 0.7422\n",
      "Epoch 55/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4659 - accuracy: 0.7849 - val_loss: 0.5126 - val_accuracy: 0.7427\n",
      "Epoch 56/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4655 - accuracy: 0.7847 - val_loss: 0.5123 - val_accuracy: 0.7431\n",
      "Epoch 57/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4652 - accuracy: 0.7849 - val_loss: 0.5121 - val_accuracy: 0.7436\n",
      "Epoch 58/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4648 - accuracy: 0.7842 - val_loss: 0.5122 - val_accuracy: 0.7441\n",
      "Epoch 59/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4645 - accuracy: 0.7839 - val_loss: 0.5120 - val_accuracy: 0.7441\n",
      "Epoch 60/200\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4641 - accuracy: 0.7838 - val_loss: 0.5123 - val_accuracy: 0.7436\n",
      "Epoch 61/200\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4638 - accuracy: 0.7843 - val_loss: 0.5118 - val_accuracy: 0.7441\n",
      "Epoch 62/200\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.4635 - accuracy: 0.7846 - val_loss: 0.5117 - val_accuracy: 0.7441\n",
      "Epoch 63/200\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.4632 - accuracy: 0.7843 - val_loss: 0.5115 - val_accuracy: 0.7436\n",
      "Epoch 64/200\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4629 - accuracy: 0.7846 - val_loss: 0.5114 - val_accuracy: 0.7431\n",
      "Epoch 65/200\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.4626 - accuracy: 0.7851 - val_loss: 0.5111 - val_accuracy: 0.7436\n",
      "Epoch 66/200\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4623 - accuracy: 0.7857 - val_loss: 0.5109 - val_accuracy: 0.7431\n",
      "Epoch 67/200\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.4620 - accuracy: 0.7861 - val_loss: 0.5107 - val_accuracy: 0.7436\n",
      "Epoch 68/200\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.4618 - accuracy: 0.7856 - val_loss: 0.5106 - val_accuracy: 0.7445\n",
      "Epoch 69/200\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.4615 - accuracy: 0.7856 - val_loss: 0.5103 - val_accuracy: 0.7445\n",
      "Epoch 70/200\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.4612 - accuracy: 0.7850 - val_loss: 0.5101 - val_accuracy: 0.7441\n",
      "Epoch 71/200\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.4610 - accuracy: 0.7854 - val_loss: 0.5100 - val_accuracy: 0.7455\n",
      "Epoch 72/200\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.4607 - accuracy: 0.7857 - val_loss: 0.5100 - val_accuracy: 0.7455\n",
      "Epoch 73/200\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4605 - accuracy: 0.7857 - val_loss: 0.5103 - val_accuracy: 0.7450\n",
      "Epoch 74/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4602 - accuracy: 0.7854 - val_loss: 0.5106 - val_accuracy: 0.7450\n",
      "Epoch 75/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4600 - accuracy: 0.7862 - val_loss: 0.5099 - val_accuracy: 0.7455\n",
      "Epoch 76/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4598 - accuracy: 0.7860 - val_loss: 0.5099 - val_accuracy: 0.7469\n",
      "Epoch 77/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4595 - accuracy: 0.7861 - val_loss: 0.5097 - val_accuracy: 0.7479\n",
      "Epoch 78/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4593 - accuracy: 0.7868 - val_loss: 0.5097 - val_accuracy: 0.7488\n",
      "Epoch 79/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4591 - accuracy: 0.7875 - val_loss: 0.5094 - val_accuracy: 0.7488\n",
      "Epoch 80/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4589 - accuracy: 0.7872 - val_loss: 0.5095 - val_accuracy: 0.7488\n",
      "Epoch 81/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4587 - accuracy: 0.7879 - val_loss: 0.5099 - val_accuracy: 0.7479\n",
      "Epoch 82/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4585 - accuracy: 0.7876 - val_loss: 0.5096 - val_accuracy: 0.7483\n",
      "Epoch 83/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4583 - accuracy: 0.7880 - val_loss: 0.5091 - val_accuracy: 0.7483\n",
      "Epoch 84/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4581 - accuracy: 0.7880 - val_loss: 0.5091 - val_accuracy: 0.7483\n",
      "Epoch 85/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4579 - accuracy: 0.7883 - val_loss: 0.5092 - val_accuracy: 0.7483\n",
      "Epoch 86/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4577 - accuracy: 0.7886 - val_loss: 0.5088 - val_accuracy: 0.7483\n",
      "Epoch 87/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4575 - accuracy: 0.7883 - val_loss: 0.5089 - val_accuracy: 0.7483\n",
      "Epoch 88/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4573 - accuracy: 0.7880 - val_loss: 0.5089 - val_accuracy: 0.7488\n",
      "Epoch 89/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4571 - accuracy: 0.7878 - val_loss: 0.5088 - val_accuracy: 0.7488\n",
      "Epoch 90/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4569 - accuracy: 0.7880 - val_loss: 0.5086 - val_accuracy: 0.7493\n",
      "Epoch 91/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4568 - accuracy: 0.7880 - val_loss: 0.5084 - val_accuracy: 0.7502\n",
      "Epoch 92/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4566 - accuracy: 0.7880 - val_loss: 0.5085 - val_accuracy: 0.7502\n",
      "Epoch 93/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4564 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7507\n",
      "Epoch 94/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4563 - accuracy: 0.7883 - val_loss: 0.5083 - val_accuracy: 0.7502\n",
      "Epoch 95/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4561 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7507\n",
      "Epoch 96/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4559 - accuracy: 0.7880 - val_loss: 0.5085 - val_accuracy: 0.7502\n",
      "Epoch 97/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4558 - accuracy: 0.7880 - val_loss: 0.5082 - val_accuracy: 0.7502\n",
      "Epoch 98/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4556 - accuracy: 0.7883 - val_loss: 0.5083 - val_accuracy: 0.7493\n",
      "Epoch 99/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4554 - accuracy: 0.7886 - val_loss: 0.5079 - val_accuracy: 0.7493\n",
      "Epoch 100/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4553 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7483\n",
      "Epoch 101/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4552 - accuracy: 0.7889 - val_loss: 0.5079 - val_accuracy: 0.7488\n",
      "Epoch 102/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4550 - accuracy: 0.7885 - val_loss: 0.5078 - val_accuracy: 0.7479\n",
      "Epoch 103/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4549 - accuracy: 0.7885 - val_loss: 0.5079 - val_accuracy: 0.7479\n",
      "Epoch 104/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4547 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7479\n",
      "Epoch 105/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4546 - accuracy: 0.7883 - val_loss: 0.5075 - val_accuracy: 0.7479\n",
      "Epoch 106/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4544 - accuracy: 0.7883 - val_loss: 0.5069 - val_accuracy: 0.7479\n",
      "Epoch 107/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4543 - accuracy: 0.7885 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
      "Epoch 108/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4542 - accuracy: 0.7890 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 109/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4540 - accuracy: 0.7890 - val_loss: 0.5070 - val_accuracy: 0.7474\n",
      "Epoch 110/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4539 - accuracy: 0.7897 - val_loss: 0.5074 - val_accuracy: 0.7469\n",
      "Epoch 111/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4538 - accuracy: 0.7892 - val_loss: 0.5071 - val_accuracy: 0.7469\n",
      "Epoch 112/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4536 - accuracy: 0.7889 - val_loss: 0.5071 - val_accuracy: 0.7474\n",
      "Epoch 113/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4535 - accuracy: 0.7890 - val_loss: 0.5075 - val_accuracy: 0.7474\n",
      "Epoch 114/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4534 - accuracy: 0.7897 - val_loss: 0.5070 - val_accuracy: 0.7483\n",
      "Epoch 115/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4533 - accuracy: 0.7898 - val_loss: 0.5073 - val_accuracy: 0.7479\n",
      "Epoch 116/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4532 - accuracy: 0.7894 - val_loss: 0.5074 - val_accuracy: 0.7483\n",
      "Epoch 117/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4531 - accuracy: 0.7901 - val_loss: 0.5071 - val_accuracy: 0.7483\n",
      "Epoch 118/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4529 - accuracy: 0.7898 - val_loss: 0.5069 - val_accuracy: 0.7488\n",
      "Epoch 119/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4528 - accuracy: 0.7898 - val_loss: 0.5069 - val_accuracy: 0.7488\n",
      "Epoch 120/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4527 - accuracy: 0.7900 - val_loss: 0.5068 - val_accuracy: 0.7488\n",
      "Epoch 121/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4526 - accuracy: 0.7897 - val_loss: 0.5066 - val_accuracy: 0.7488\n",
      "Epoch 122/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4525 - accuracy: 0.7898 - val_loss: 0.5066 - val_accuracy: 0.7488\n",
      "Epoch 123/200\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7901 - val_loss: 0.5067 - val_accuracy: 0.7493\n",
      "Epoch 124/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4523 - accuracy: 0.7897 - val_loss: 0.5069 - val_accuracy: 0.7493\n",
      "Epoch 125/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4522 - accuracy: 0.7896 - val_loss: 0.5068 - val_accuracy: 0.7488\n",
      "Epoch 126/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4521 - accuracy: 0.7896 - val_loss: 0.5064 - val_accuracy: 0.7488\n",
      "Epoch 127/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4520 - accuracy: 0.7897 - val_loss: 0.5064 - val_accuracy: 0.7488\n",
      "Epoch 128/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4519 - accuracy: 0.7903 - val_loss: 0.5064 - val_accuracy: 0.7493\n",
      "Epoch 129/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4518 - accuracy: 0.7900 - val_loss: 0.5065 - val_accuracy: 0.7493\n",
      "Epoch 130/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4516 - accuracy: 0.7901 - val_loss: 0.5063 - val_accuracy: 0.7493\n",
      "Epoch 131/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4516 - accuracy: 0.7903 - val_loss: 0.5066 - val_accuracy: 0.7483\n",
      "Epoch 132/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4515 - accuracy: 0.7903 - val_loss: 0.5066 - val_accuracy: 0.7474\n",
      "Epoch 133/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4514 - accuracy: 0.7901 - val_loss: 0.5065 - val_accuracy: 0.7469\n",
      "Epoch 134/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4513 - accuracy: 0.7903 - val_loss: 0.5062 - val_accuracy: 0.7474\n",
      "Epoch 135/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4512 - accuracy: 0.7904 - val_loss: 0.5063 - val_accuracy: 0.7474\n",
      "Epoch 136/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4511 - accuracy: 0.7897 - val_loss: 0.5060 - val_accuracy: 0.7474\n",
      "Epoch 137/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4510 - accuracy: 0.7907 - val_loss: 0.5061 - val_accuracy: 0.7469\n",
      "Epoch 138/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4509 - accuracy: 0.7901 - val_loss: 0.5061 - val_accuracy: 0.7464\n",
      "Epoch 139/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4508 - accuracy: 0.7904 - val_loss: 0.5063 - val_accuracy: 0.7464\n",
      "Epoch 140/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4507 - accuracy: 0.7903 - val_loss: 0.5064 - val_accuracy: 0.7464\n",
      "Epoch 141/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4506 - accuracy: 0.7901 - val_loss: 0.5061 - val_accuracy: 0.7464\n",
      "Epoch 142/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4505 - accuracy: 0.7900 - val_loss: 0.5061 - val_accuracy: 0.7464\n",
      "Epoch 143/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4505 - accuracy: 0.7903 - val_loss: 0.5059 - val_accuracy: 0.7464\n",
      "Epoch 144/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4504 - accuracy: 0.7904 - val_loss: 0.5057 - val_accuracy: 0.7464\n",
      "Epoch 145/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4503 - accuracy: 0.7903 - val_loss: 0.5058 - val_accuracy: 0.7464\n",
      "Epoch 146/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4502 - accuracy: 0.7901 - val_loss: 0.5056 - val_accuracy: 0.7464\n",
      "Epoch 147/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4501 - accuracy: 0.7905 - val_loss: 0.5057 - val_accuracy: 0.7464\n",
      "Epoch 148/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4500 - accuracy: 0.7904 - val_loss: 0.5053 - val_accuracy: 0.7464\n",
      "Epoch 149/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4500 - accuracy: 0.7904 - val_loss: 0.5055 - val_accuracy: 0.7460\n",
      "Epoch 150/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4499 - accuracy: 0.7905 - val_loss: 0.5059 - val_accuracy: 0.7455\n",
      "Epoch 151/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4498 - accuracy: 0.7910 - val_loss: 0.5059 - val_accuracy: 0.7455\n",
      "Epoch 152/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4497 - accuracy: 0.7908 - val_loss: 0.5060 - val_accuracy: 0.7455\n",
      "Epoch 153/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4496 - accuracy: 0.7908 - val_loss: 0.5061 - val_accuracy: 0.7450\n",
      "Epoch 154/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4496 - accuracy: 0.7908 - val_loss: 0.5058 - val_accuracy: 0.7455\n",
      "Epoch 155/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4495 - accuracy: 0.7911 - val_loss: 0.5057 - val_accuracy: 0.7455\n",
      "Epoch 156/200\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7910 - val_loss: 0.5058 - val_accuracy: 0.7460\n",
      "Epoch 157/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4493 - accuracy: 0.7911 - val_loss: 0.5057 - val_accuracy: 0.7460\n",
      "Epoch 158/200\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7910 - val_loss: 0.5054 - val_accuracy: 0.7464\n",
      "Epoch 159/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4492 - accuracy: 0.7908 - val_loss: 0.5055 - val_accuracy: 0.7460\n",
      "Epoch 160/200\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7911 - val_loss: 0.5056 - val_accuracy: 0.7455\n",
      "Epoch 161/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4490 - accuracy: 0.7908 - val_loss: 0.5054 - val_accuracy: 0.7455\n",
      "Epoch 162/200\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7914 - val_loss: 0.5048 - val_accuracy: 0.7460\n",
      "Epoch 163/200\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7914 - val_loss: 0.5046 - val_accuracy: 0.7460\n",
      "Epoch 164/200\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7908 - val_loss: 0.5048 - val_accuracy: 0.7460\n",
      "Epoch 165/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4488 - accuracy: 0.7908 - val_loss: 0.5050 - val_accuracy: 0.7460\n",
      "Epoch 166/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4487 - accuracy: 0.7911 - val_loss: 0.5049 - val_accuracy: 0.7455\n",
      "Epoch 167/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4486 - accuracy: 0.7912 - val_loss: 0.5047 - val_accuracy: 0.7455\n",
      "Epoch 168/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4485 - accuracy: 0.7916 - val_loss: 0.5051 - val_accuracy: 0.7445\n",
      "Epoch 169/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4485 - accuracy: 0.7912 - val_loss: 0.5054 - val_accuracy: 0.7445\n",
      "Epoch 170/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4484 - accuracy: 0.7912 - val_loss: 0.5049 - val_accuracy: 0.7441\n",
      "Epoch 171/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4483 - accuracy: 0.7914 - val_loss: 0.5047 - val_accuracy: 0.7441\n",
      "Epoch 172/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4483 - accuracy: 0.7912 - val_loss: 0.5049 - val_accuracy: 0.7441\n",
      "Epoch 173/200\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7912 - val_loss: 0.5048 - val_accuracy: 0.7441\n",
      "Epoch 174/200\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4481 - accuracy: 0.7911 - val_loss: 0.5047 - val_accuracy: 0.7445\n",
      "Epoch 175/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4481 - accuracy: 0.7911 - val_loss: 0.5048 - val_accuracy: 0.7445\n",
      "Epoch 176/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4480 - accuracy: 0.7912 - val_loss: 0.5049 - val_accuracy: 0.7445\n",
      "Epoch 177/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4480 - accuracy: 0.7916 - val_loss: 0.5051 - val_accuracy: 0.7445\n",
      "Epoch 178/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4479 - accuracy: 0.7911 - val_loss: 0.5050 - val_accuracy: 0.7445\n",
      "Epoch 179/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4478 - accuracy: 0.7916 - val_loss: 0.5053 - val_accuracy: 0.7445\n",
      "Epoch 180/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4478 - accuracy: 0.7910 - val_loss: 0.5053 - val_accuracy: 0.7445\n",
      "Epoch 181/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4477 - accuracy: 0.7914 - val_loss: 0.5049 - val_accuracy: 0.7445\n",
      "Epoch 182/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4476 - accuracy: 0.7912 - val_loss: 0.5047 - val_accuracy: 0.7445\n",
      "Epoch 183/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4476 - accuracy: 0.7912 - val_loss: 0.5048 - val_accuracy: 0.7445\n",
      "Epoch 184/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4475 - accuracy: 0.7915 - val_loss: 0.5047 - val_accuracy: 0.7445\n",
      "Epoch 185/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4475 - accuracy: 0.7908 - val_loss: 0.5051 - val_accuracy: 0.7441\n",
      "Epoch 186/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4474 - accuracy: 0.7914 - val_loss: 0.5052 - val_accuracy: 0.7441\n",
      "Epoch 187/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4473 - accuracy: 0.7915 - val_loss: 0.5051 - val_accuracy: 0.7436\n",
      "Epoch 188/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4473 - accuracy: 0.7919 - val_loss: 0.5050 - val_accuracy: 0.7436\n",
      "Epoch 189/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4472 - accuracy: 0.7918 - val_loss: 0.5048 - val_accuracy: 0.7441\n",
      "Epoch 190/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4472 - accuracy: 0.7912 - val_loss: 0.5048 - val_accuracy: 0.7441\n",
      "Epoch 191/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4471 - accuracy: 0.7911 - val_loss: 0.5048 - val_accuracy: 0.7441\n",
      "Epoch 192/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4470 - accuracy: 0.7910 - val_loss: 0.5049 - val_accuracy: 0.7445\n",
      "Epoch 193/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4470 - accuracy: 0.7914 - val_loss: 0.5050 - val_accuracy: 0.7450\n",
      "Epoch 194/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4469 - accuracy: 0.7916 - val_loss: 0.5048 - val_accuracy: 0.7445\n",
      "Epoch 195/200\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4469 - accuracy: 0.7918 - val_loss: 0.5043 - val_accuracy: 0.7441\n",
      "Epoch 196/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4468 - accuracy: 0.7915 - val_loss: 0.5043 - val_accuracy: 0.7445\n",
      "Epoch 197/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4467 - accuracy: 0.7918 - val_loss: 0.5041 - val_accuracy: 0.7445\n",
      "Epoch 198/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4467 - accuracy: 0.7910 - val_loss: 0.5042 - val_accuracy: 0.7445\n",
      "Epoch 199/200\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4466 - accuracy: 0.7918 - val_loss: 0.5040 - val_accuracy: 0.7450\n",
      "Epoch 200/200\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4466 - accuracy: 0.7908 - val_loss: 0.5043 - val_accuracy: 0.7445\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f5f1d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 2ms/step\n",
      "66/66 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = (model_1.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
    "\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa7acbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "123f8dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3567536 ],\n",
       "       [0.6405168 ],\n",
       "       [0.0815747 ],\n",
       "       [0.08999131],\n",
       "       [0.08092818],\n",
       "       [0.39340782],\n",
       "       [0.5448318 ],\n",
       "       [0.30865255],\n",
       "       [0.07647114],\n",
       "       [0.07840337]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fe05aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.745\n",
      "roc-auc is 0.828\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c288c7",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546367c6",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de811a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f67da2",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b4984d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20ae2a2ac40>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4d47ad",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f30b79ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4465 - accuracy: 0.7916 - val_loss: 0.5044 - val_accuracy: 0.7445\n",
      "Epoch 2/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4465 - accuracy: 0.7915 - val_loss: 0.5043 - val_accuracy: 0.7450\n",
      "Epoch 3/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4464 - accuracy: 0.7915 - val_loss: 0.5044 - val_accuracy: 0.7450\n",
      "Epoch 4/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4464 - accuracy: 0.7919 - val_loss: 0.5044 - val_accuracy: 0.7450\n",
      "Epoch 5/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4463 - accuracy: 0.7918 - val_loss: 0.5045 - val_accuracy: 0.7450\n",
      "Epoch 6/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4462 - accuracy: 0.7921 - val_loss: 0.5045 - val_accuracy: 0.7450\n",
      "Epoch 7/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4462 - accuracy: 0.7914 - val_loss: 0.5045 - val_accuracy: 0.7450\n",
      "Epoch 8/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4461 - accuracy: 0.7921 - val_loss: 0.5045 - val_accuracy: 0.7450\n",
      "Epoch 9/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4461 - accuracy: 0.7915 - val_loss: 0.5044 - val_accuracy: 0.7445\n",
      "Epoch 10/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4460 - accuracy: 0.7918 - val_loss: 0.5043 - val_accuracy: 0.7445\n",
      "Epoch 11/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4460 - accuracy: 0.7916 - val_loss: 0.5042 - val_accuracy: 0.7450\n",
      "Epoch 12/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4459 - accuracy: 0.7919 - val_loss: 0.5038 - val_accuracy: 0.7455\n",
      "Epoch 13/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4459 - accuracy: 0.7914 - val_loss: 0.5040 - val_accuracy: 0.7450\n",
      "Epoch 14/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4458 - accuracy: 0.7916 - val_loss: 0.5044 - val_accuracy: 0.7450\n",
      "Epoch 15/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4458 - accuracy: 0.7918 - val_loss: 0.5041 - val_accuracy: 0.7450\n",
      "Epoch 16/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4457 - accuracy: 0.7916 - val_loss: 0.5039 - val_accuracy: 0.7450\n",
      "Epoch 17/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4457 - accuracy: 0.7914 - val_loss: 0.5041 - val_accuracy: 0.7450\n",
      "Epoch 18/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4456 - accuracy: 0.7921 - val_loss: 0.5040 - val_accuracy: 0.7441\n",
      "Epoch 19/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4455 - accuracy: 0.7915 - val_loss: 0.5043 - val_accuracy: 0.7436\n",
      "Epoch 20/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4455 - accuracy: 0.7925 - val_loss: 0.5040 - val_accuracy: 0.7436\n",
      "Epoch 21/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4454 - accuracy: 0.7916 - val_loss: 0.5040 - val_accuracy: 0.7436\n",
      "Epoch 22/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4454 - accuracy: 0.7916 - val_loss: 0.5041 - val_accuracy: 0.7431\n",
      "Epoch 23/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4453 - accuracy: 0.7915 - val_loss: 0.5040 - val_accuracy: 0.7431\n",
      "Epoch 24/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4453 - accuracy: 0.7916 - val_loss: 0.5039 - val_accuracy: 0.7436\n",
      "Epoch 25/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4452 - accuracy: 0.7923 - val_loss: 0.5035 - val_accuracy: 0.7431\n",
      "Epoch 26/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4452 - accuracy: 0.7919 - val_loss: 0.5034 - val_accuracy: 0.7431\n",
      "Epoch 27/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4451 - accuracy: 0.7919 - val_loss: 0.5035 - val_accuracy: 0.7436\n",
      "Epoch 28/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4451 - accuracy: 0.7918 - val_loss: 0.5035 - val_accuracy: 0.7436\n",
      "Epoch 29/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4450 - accuracy: 0.7919 - val_loss: 0.5035 - val_accuracy: 0.7436\n",
      "Epoch 30/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4450 - accuracy: 0.7915 - val_loss: 0.5034 - val_accuracy: 0.7436\n",
      "Epoch 31/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4449 - accuracy: 0.7919 - val_loss: 0.5035 - val_accuracy: 0.7436\n",
      "Epoch 32/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4449 - accuracy: 0.7919 - val_loss: 0.5039 - val_accuracy: 0.7436\n",
      "Epoch 33/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4448 - accuracy: 0.7922 - val_loss: 0.5038 - val_accuracy: 0.7436\n",
      "Epoch 34/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4448 - accuracy: 0.7921 - val_loss: 0.5038 - val_accuracy: 0.7431\n",
      "Epoch 35/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4447 - accuracy: 0.7921 - val_loss: 0.5037 - val_accuracy: 0.7431\n",
      "Epoch 36/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4447 - accuracy: 0.7918 - val_loss: 0.5036 - val_accuracy: 0.7431\n",
      "Epoch 37/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4446 - accuracy: 0.7925 - val_loss: 0.5037 - val_accuracy: 0.7431\n",
      "Epoch 38/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4446 - accuracy: 0.7922 - val_loss: 0.5037 - val_accuracy: 0.7436\n",
      "Epoch 39/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4445 - accuracy: 0.7919 - val_loss: 0.5036 - val_accuracy: 0.7436\n",
      "Epoch 40/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4445 - accuracy: 0.7923 - val_loss: 0.5032 - val_accuracy: 0.7431\n",
      "Epoch 41/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4444 - accuracy: 0.7922 - val_loss: 0.5031 - val_accuracy: 0.7431\n",
      "Epoch 42/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4444 - accuracy: 0.7922 - val_loss: 0.5032 - val_accuracy: 0.7431\n",
      "Epoch 43/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4443 - accuracy: 0.7921 - val_loss: 0.5031 - val_accuracy: 0.7431\n",
      "Epoch 44/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4443 - accuracy: 0.7921 - val_loss: 0.5034 - val_accuracy: 0.7431\n",
      "Epoch 45/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4442 - accuracy: 0.7921 - val_loss: 0.5033 - val_accuracy: 0.7431\n",
      "Epoch 46/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4442 - accuracy: 0.7923 - val_loss: 0.5032 - val_accuracy: 0.7431\n",
      "Epoch 47/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4441 - accuracy: 0.7923 - val_loss: 0.5032 - val_accuracy: 0.7427\n",
      "Epoch 48/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4441 - accuracy: 0.7923 - val_loss: 0.5032 - val_accuracy: 0.7422\n",
      "Epoch 49/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4441 - accuracy: 0.7923 - val_loss: 0.5033 - val_accuracy: 0.7422\n",
      "Epoch 50/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4440 - accuracy: 0.7926 - val_loss: 0.5035 - val_accuracy: 0.7422\n",
      "Epoch 51/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4440 - accuracy: 0.7923 - val_loss: 0.5035 - val_accuracy: 0.7422\n",
      "Epoch 52/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4439 - accuracy: 0.7921 - val_loss: 0.5029 - val_accuracy: 0.7427\n",
      "Epoch 53/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4439 - accuracy: 0.7923 - val_loss: 0.5029 - val_accuracy: 0.7422\n",
      "Epoch 54/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4438 - accuracy: 0.7922 - val_loss: 0.5029 - val_accuracy: 0.7422\n",
      "Epoch 55/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4438 - accuracy: 0.7928 - val_loss: 0.5029 - val_accuracy: 0.7422\n",
      "Epoch 56/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4437 - accuracy: 0.7926 - val_loss: 0.5028 - val_accuracy: 0.7422\n",
      "Epoch 57/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4437 - accuracy: 0.7922 - val_loss: 0.5027 - val_accuracy: 0.7422\n",
      "Epoch 58/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4436 - accuracy: 0.7926 - val_loss: 0.5029 - val_accuracy: 0.7422\n",
      "Epoch 59/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4436 - accuracy: 0.7923 - val_loss: 0.5031 - val_accuracy: 0.7422\n",
      "Epoch 60/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4435 - accuracy: 0.7926 - val_loss: 0.5033 - val_accuracy: 0.7422\n",
      "Epoch 61/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4435 - accuracy: 0.7925 - val_loss: 0.5031 - val_accuracy: 0.7422\n",
      "Epoch 62/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4434 - accuracy: 0.7923 - val_loss: 0.5028 - val_accuracy: 0.7422\n",
      "Epoch 63/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4434 - accuracy: 0.7925 - val_loss: 0.5028 - val_accuracy: 0.7422\n",
      "Epoch 64/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4433 - accuracy: 0.7928 - val_loss: 0.5029 - val_accuracy: 0.7422\n",
      "Epoch 65/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4433 - accuracy: 0.7928 - val_loss: 0.5029 - val_accuracy: 0.7422\n",
      "Epoch 66/1000\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.4432 - accuracy: 0.7923 - val_loss: 0.5025 - val_accuracy: 0.7427\n",
      "Epoch 67/1000\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.4432 - accuracy: 0.7926 - val_loss: 0.5027 - val_accuracy: 0.7427\n",
      "Epoch 68/1000\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.4432 - accuracy: 0.7922 - val_loss: 0.5023 - val_accuracy: 0.7427\n",
      "Epoch 69/1000\n",
      "226/226 [==============================] - 3s 11ms/step - loss: 0.4431 - accuracy: 0.7926 - val_loss: 0.5023 - val_accuracy: 0.7427\n",
      "Epoch 70/1000\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.4431 - accuracy: 0.7921 - val_loss: 0.5024 - val_accuracy: 0.7427\n",
      "Epoch 71/1000\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.4430 - accuracy: 0.7922 - val_loss: 0.5026 - val_accuracy: 0.7422\n",
      "Epoch 72/1000\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.4430 - accuracy: 0.7925 - val_loss: 0.5021 - val_accuracy: 0.7422\n",
      "Epoch 73/1000\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.4429 - accuracy: 0.7923 - val_loss: 0.5019 - val_accuracy: 0.7422\n",
      "Epoch 74/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4429 - accuracy: 0.7926 - val_loss: 0.5022 - val_accuracy: 0.7422\n",
      "Epoch 75/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4428 - accuracy: 0.7926 - val_loss: 0.5022 - val_accuracy: 0.7422\n",
      "Epoch 76/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4428 - accuracy: 0.7928 - val_loss: 0.5024 - val_accuracy: 0.7422\n",
      "Epoch 77/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4427 - accuracy: 0.7928 - val_loss: 0.5023 - val_accuracy: 0.7422\n",
      "Epoch 78/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4427 - accuracy: 0.7925 - val_loss: 0.5024 - val_accuracy: 0.7431\n",
      "Epoch 79/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4427 - accuracy: 0.7930 - val_loss: 0.5025 - val_accuracy: 0.7431\n",
      "Epoch 80/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4426 - accuracy: 0.7928 - val_loss: 0.5024 - val_accuracy: 0.7431\n",
      "Epoch 81/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4426 - accuracy: 0.7928 - val_loss: 0.5021 - val_accuracy: 0.7431\n",
      "Epoch 82/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4425 - accuracy: 0.7933 - val_loss: 0.5024 - val_accuracy: 0.7431\n",
      "Epoch 83/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4425 - accuracy: 0.7930 - val_loss: 0.5023 - val_accuracy: 0.7431\n",
      "Epoch 84/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4424 - accuracy: 0.7922 - val_loss: 0.5022 - val_accuracy: 0.7431\n",
      "Epoch 85/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4424 - accuracy: 0.7932 - val_loss: 0.5022 - val_accuracy: 0.7431\n",
      "Epoch 86/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4423 - accuracy: 0.7932 - val_loss: 0.5024 - val_accuracy: 0.7431\n",
      "Epoch 87/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4423 - accuracy: 0.7926 - val_loss: 0.5024 - val_accuracy: 0.7431\n",
      "Epoch 88/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4422 - accuracy: 0.7923 - val_loss: 0.5025 - val_accuracy: 0.7431\n",
      "Epoch 89/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4422 - accuracy: 0.7926 - val_loss: 0.5027 - val_accuracy: 0.7431\n",
      "Epoch 90/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4422 - accuracy: 0.7928 - val_loss: 0.5023 - val_accuracy: 0.7431\n",
      "Epoch 91/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4421 - accuracy: 0.7921 - val_loss: 0.5022 - val_accuracy: 0.7431\n",
      "Epoch 92/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4421 - accuracy: 0.7921 - val_loss: 0.5021 - val_accuracy: 0.7431\n",
      "Epoch 93/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4420 - accuracy: 0.7928 - val_loss: 0.5018 - val_accuracy: 0.7431\n",
      "Epoch 94/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4420 - accuracy: 0.7928 - val_loss: 0.5019 - val_accuracy: 0.7431\n",
      "Epoch 95/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4419 - accuracy: 0.7926 - val_loss: 0.5022 - val_accuracy: 0.7431\n",
      "Epoch 96/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4419 - accuracy: 0.7926 - val_loss: 0.5020 - val_accuracy: 0.7431\n",
      "Epoch 97/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4418 - accuracy: 0.7925 - val_loss: 0.5020 - val_accuracy: 0.7431\n",
      "Epoch 98/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4418 - accuracy: 0.7929 - val_loss: 0.5022 - val_accuracy: 0.7427\n",
      "Epoch 99/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4418 - accuracy: 0.7928 - val_loss: 0.5021 - val_accuracy: 0.7427\n",
      "Epoch 100/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4417 - accuracy: 0.7928 - val_loss: 0.5020 - val_accuracy: 0.7427\n",
      "Epoch 101/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4417 - accuracy: 0.7928 - val_loss: 0.5020 - val_accuracy: 0.7427\n",
      "Epoch 102/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4416 - accuracy: 0.7925 - val_loss: 0.5018 - val_accuracy: 0.7427\n",
      "Epoch 103/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4416 - accuracy: 0.7929 - val_loss: 0.5016 - val_accuracy: 0.7427\n",
      "Epoch 104/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4415 - accuracy: 0.7929 - val_loss: 0.5020 - val_accuracy: 0.7427\n",
      "Epoch 105/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4415 - accuracy: 0.7925 - val_loss: 0.5022 - val_accuracy: 0.7427\n",
      "Epoch 106/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4414 - accuracy: 0.7926 - val_loss: 0.5024 - val_accuracy: 0.7427\n",
      "Epoch 107/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4414 - accuracy: 0.7930 - val_loss: 0.5023 - val_accuracy: 0.7427\n",
      "Epoch 108/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4414 - accuracy: 0.7928 - val_loss: 0.5021 - val_accuracy: 0.7427\n",
      "Epoch 109/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4413 - accuracy: 0.7932 - val_loss: 0.5022 - val_accuracy: 0.7427\n",
      "Epoch 110/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4413 - accuracy: 0.7930 - val_loss: 0.5020 - val_accuracy: 0.7427\n",
      "Epoch 111/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4412 - accuracy: 0.7929 - val_loss: 0.5020 - val_accuracy: 0.7427\n",
      "Epoch 112/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4412 - accuracy: 0.7930 - val_loss: 0.5019 - val_accuracy: 0.7427\n",
      "Epoch 113/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4411 - accuracy: 0.7930 - val_loss: 0.5021 - val_accuracy: 0.7427\n",
      "Epoch 114/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4411 - accuracy: 0.7929 - val_loss: 0.5018 - val_accuracy: 0.7422\n",
      "Epoch 115/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4410 - accuracy: 0.7928 - val_loss: 0.5018 - val_accuracy: 0.7422\n",
      "Epoch 116/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4410 - accuracy: 0.7928 - val_loss: 0.5015 - val_accuracy: 0.7422\n",
      "Epoch 117/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4410 - accuracy: 0.7926 - val_loss: 0.5014 - val_accuracy: 0.7417\n",
      "Epoch 118/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4409 - accuracy: 0.7930 - val_loss: 0.5014 - val_accuracy: 0.7417\n",
      "Epoch 119/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4409 - accuracy: 0.7928 - val_loss: 0.5015 - val_accuracy: 0.7417\n",
      "Epoch 120/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4408 - accuracy: 0.7928 - val_loss: 0.5016 - val_accuracy: 0.7412\n",
      "Epoch 121/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4408 - accuracy: 0.7930 - val_loss: 0.5019 - val_accuracy: 0.7417\n",
      "Epoch 122/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4407 - accuracy: 0.7929 - val_loss: 0.5017 - val_accuracy: 0.7417\n",
      "Epoch 123/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4407 - accuracy: 0.7933 - val_loss: 0.5018 - val_accuracy: 0.7412\n",
      "Epoch 124/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4406 - accuracy: 0.7929 - val_loss: 0.5016 - val_accuracy: 0.7412\n",
      "Epoch 125/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4406 - accuracy: 0.7926 - val_loss: 0.5016 - val_accuracy: 0.7412\n",
      "Epoch 126/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4406 - accuracy: 0.7926 - val_loss: 0.5013 - val_accuracy: 0.7417\n",
      "Epoch 127/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4405 - accuracy: 0.7932 - val_loss: 0.5017 - val_accuracy: 0.7417\n",
      "Epoch 128/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4405 - accuracy: 0.7932 - val_loss: 0.5017 - val_accuracy: 0.7417\n",
      "Epoch 129/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4404 - accuracy: 0.7925 - val_loss: 0.5015 - val_accuracy: 0.7417\n",
      "Epoch 130/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4404 - accuracy: 0.7930 - val_loss: 0.5013 - val_accuracy: 0.7422\n",
      "Epoch 131/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4403 - accuracy: 0.7930 - val_loss: 0.5014 - val_accuracy: 0.7422\n",
      "Epoch 132/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4403 - accuracy: 0.7929 - val_loss: 0.5013 - val_accuracy: 0.7422\n",
      "Epoch 133/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4402 - accuracy: 0.7932 - val_loss: 0.5016 - val_accuracy: 0.7422\n",
      "Epoch 134/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4402 - accuracy: 0.7928 - val_loss: 0.5015 - val_accuracy: 0.7422\n",
      "Epoch 135/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4402 - accuracy: 0.7928 - val_loss: 0.5014 - val_accuracy: 0.7422\n",
      "Epoch 136/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4401 - accuracy: 0.7930 - val_loss: 0.5016 - val_accuracy: 0.7422\n",
      "Epoch 137/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4401 - accuracy: 0.7936 - val_loss: 0.5013 - val_accuracy: 0.7427\n",
      "Epoch 138/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4400 - accuracy: 0.7929 - val_loss: 0.5013 - val_accuracy: 0.7422\n",
      "Epoch 139/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4400 - accuracy: 0.7933 - val_loss: 0.5013 - val_accuracy: 0.7422\n",
      "Epoch 140/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4399 - accuracy: 0.7930 - val_loss: 0.5011 - val_accuracy: 0.7431\n",
      "Epoch 141/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4399 - accuracy: 0.7928 - val_loss: 0.5012 - val_accuracy: 0.7436\n",
      "Epoch 142/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4399 - accuracy: 0.7928 - val_loss: 0.5010 - val_accuracy: 0.7436\n",
      "Epoch 143/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4398 - accuracy: 0.7932 - val_loss: 0.5010 - val_accuracy: 0.7441\n",
      "Epoch 144/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4398 - accuracy: 0.7928 - val_loss: 0.5011 - val_accuracy: 0.7436\n",
      "Epoch 145/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4397 - accuracy: 0.7936 - val_loss: 0.5007 - val_accuracy: 0.7445\n",
      "Epoch 146/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4397 - accuracy: 0.7929 - val_loss: 0.5008 - val_accuracy: 0.7445\n",
      "Epoch 147/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4396 - accuracy: 0.7930 - val_loss: 0.5009 - val_accuracy: 0.7445\n",
      "Epoch 148/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4396 - accuracy: 0.7930 - val_loss: 0.5009 - val_accuracy: 0.7445\n",
      "Epoch 149/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4395 - accuracy: 0.7928 - val_loss: 0.5011 - val_accuracy: 0.7441\n",
      "Epoch 150/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4395 - accuracy: 0.7933 - val_loss: 0.5007 - val_accuracy: 0.7445\n",
      "Epoch 151/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4395 - accuracy: 0.7933 - val_loss: 0.5008 - val_accuracy: 0.7445\n",
      "Epoch 152/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4394 - accuracy: 0.7928 - val_loss: 0.5008 - val_accuracy: 0.7445\n",
      "Epoch 153/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4394 - accuracy: 0.7932 - val_loss: 0.5009 - val_accuracy: 0.7441\n",
      "Epoch 154/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4393 - accuracy: 0.7926 - val_loss: 0.5010 - val_accuracy: 0.7441\n",
      "Epoch 155/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4393 - accuracy: 0.7934 - val_loss: 0.5009 - val_accuracy: 0.7441\n",
      "Epoch 156/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4393 - accuracy: 0.7936 - val_loss: 0.5007 - val_accuracy: 0.7441\n",
      "Epoch 157/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4392 - accuracy: 0.7926 - val_loss: 0.5008 - val_accuracy: 0.7441\n",
      "Epoch 158/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4392 - accuracy: 0.7922 - val_loss: 0.5008 - val_accuracy: 0.7441\n",
      "Epoch 159/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4391 - accuracy: 0.7923 - val_loss: 0.5011 - val_accuracy: 0.7441\n",
      "Epoch 160/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4391 - accuracy: 0.7932 - val_loss: 0.5011 - val_accuracy: 0.7441\n",
      "Epoch 161/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4390 - accuracy: 0.7929 - val_loss: 0.5009 - val_accuracy: 0.7441\n",
      "Epoch 162/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4390 - accuracy: 0.7928 - val_loss: 0.5008 - val_accuracy: 0.7441\n",
      "Epoch 163/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4389 - accuracy: 0.7934 - val_loss: 0.5004 - val_accuracy: 0.7436\n",
      "Epoch 164/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4389 - accuracy: 0.7930 - val_loss: 0.5007 - val_accuracy: 0.7445\n",
      "Epoch 165/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4389 - accuracy: 0.7929 - val_loss: 0.5005 - val_accuracy: 0.7441\n",
      "Epoch 166/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4388 - accuracy: 0.7930 - val_loss: 0.5005 - val_accuracy: 0.7436\n",
      "Epoch 167/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4388 - accuracy: 0.7932 - val_loss: 0.5007 - val_accuracy: 0.7436\n",
      "Epoch 168/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4387 - accuracy: 0.7934 - val_loss: 0.5005 - val_accuracy: 0.7436\n",
      "Epoch 169/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4387 - accuracy: 0.7926 - val_loss: 0.5007 - val_accuracy: 0.7431\n",
      "Epoch 170/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4387 - accuracy: 0.7936 - val_loss: 0.5003 - val_accuracy: 0.7436\n",
      "Epoch 171/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4386 - accuracy: 0.7926 - val_loss: 0.5004 - val_accuracy: 0.7441\n",
      "Epoch 172/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4386 - accuracy: 0.7930 - val_loss: 0.5005 - val_accuracy: 0.7436\n",
      "Epoch 173/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4385 - accuracy: 0.7932 - val_loss: 0.5003 - val_accuracy: 0.7436\n",
      "Epoch 174/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4385 - accuracy: 0.7933 - val_loss: 0.5002 - val_accuracy: 0.7436\n",
      "Epoch 175/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4384 - accuracy: 0.7932 - val_loss: 0.4999 - val_accuracy: 0.7441\n",
      "Epoch 176/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4384 - accuracy: 0.7932 - val_loss: 0.4999 - val_accuracy: 0.7441\n",
      "Epoch 177/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4384 - accuracy: 0.7932 - val_loss: 0.5001 - val_accuracy: 0.7441\n",
      "Epoch 178/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4383 - accuracy: 0.7934 - val_loss: 0.5003 - val_accuracy: 0.7436\n",
      "Epoch 179/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4383 - accuracy: 0.7932 - val_loss: 0.5006 - val_accuracy: 0.7436\n",
      "Epoch 180/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4382 - accuracy: 0.7936 - val_loss: 0.5003 - val_accuracy: 0.7436\n",
      "Epoch 181/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4382 - accuracy: 0.7928 - val_loss: 0.5002 - val_accuracy: 0.7436\n",
      "Epoch 182/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4381 - accuracy: 0.7934 - val_loss: 0.5001 - val_accuracy: 0.7436\n",
      "Epoch 183/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4381 - accuracy: 0.7926 - val_loss: 0.5001 - val_accuracy: 0.7436\n",
      "Epoch 184/1000\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.4381 - accuracy: 0.7930 - val_loss: 0.5002 - val_accuracy: 0.7436\n",
      "Epoch 185/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4380 - accuracy: 0.7933 - val_loss: 0.5003 - val_accuracy: 0.7436\n",
      "Epoch 186/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4380 - accuracy: 0.7930 - val_loss: 0.5003 - val_accuracy: 0.7436\n",
      "Epoch 187/1000\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.4379 - accuracy: 0.7933 - val_loss: 0.5006 - val_accuracy: 0.7436\n",
      "Epoch 188/1000\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.4379 - accuracy: 0.7933 - val_loss: 0.5003 - val_accuracy: 0.7441\n",
      "Epoch 189/1000\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.4378 - accuracy: 0.7940 - val_loss: 0.5000 - val_accuracy: 0.7441\n",
      "Epoch 190/1000\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.4378 - accuracy: 0.7932 - val_loss: 0.5000 - val_accuracy: 0.7441\n",
      "Epoch 191/1000\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.4378 - accuracy: 0.7936 - val_loss: 0.5003 - val_accuracy: 0.7441\n",
      "Epoch 192/1000\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.4377 - accuracy: 0.7940 - val_loss: 0.4999 - val_accuracy: 0.7450\n",
      "Epoch 193/1000\n",
      "226/226 [==============================] - 3s 13ms/step - loss: 0.4377 - accuracy: 0.7932 - val_loss: 0.5003 - val_accuracy: 0.7441\n",
      "Epoch 194/1000\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.4376 - accuracy: 0.7939 - val_loss: 0.5003 - val_accuracy: 0.7441\n",
      "Epoch 195/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4376 - accuracy: 0.7936 - val_loss: 0.5004 - val_accuracy: 0.7441\n",
      "Epoch 196/1000\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.4376 - accuracy: 0.7937 - val_loss: 0.5004 - val_accuracy: 0.7441\n",
      "Epoch 197/1000\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.4375 - accuracy: 0.7941 - val_loss: 0.5003 - val_accuracy: 0.7445\n",
      "Epoch 198/1000\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.4375 - accuracy: 0.7936 - val_loss: 0.5001 - val_accuracy: 0.7450\n",
      "Epoch 199/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4374 - accuracy: 0.7943 - val_loss: 0.5000 - val_accuracy: 0.7450\n",
      "Epoch 200/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4374 - accuracy: 0.7933 - val_loss: 0.5001 - val_accuracy: 0.7450\n",
      "Epoch 201/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4373 - accuracy: 0.7945 - val_loss: 0.5002 - val_accuracy: 0.7450\n",
      "Epoch 202/1000\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.4373 - accuracy: 0.7947 - val_loss: 0.5001 - val_accuracy: 0.7450\n",
      "Epoch 203/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4373 - accuracy: 0.7941 - val_loss: 0.5003 - val_accuracy: 0.7445\n",
      "Epoch 204/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4372 - accuracy: 0.7939 - val_loss: 0.5003 - val_accuracy: 0.7445\n",
      "Epoch 205/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4372 - accuracy: 0.7943 - val_loss: 0.5005 - val_accuracy: 0.7445\n",
      "Epoch 206/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4371 - accuracy: 0.7944 - val_loss: 0.5000 - val_accuracy: 0.7445\n",
      "Epoch 207/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4371 - accuracy: 0.7939 - val_loss: 0.4999 - val_accuracy: 0.7450\n",
      "Epoch 208/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4370 - accuracy: 0.7941 - val_loss: 0.4997 - val_accuracy: 0.7460\n",
      "Epoch 209/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4370 - accuracy: 0.7940 - val_loss: 0.4998 - val_accuracy: 0.7455\n",
      "Epoch 210/1000\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.4370 - accuracy: 0.7944 - val_loss: 0.5001 - val_accuracy: 0.7450\n",
      "Epoch 211/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4369 - accuracy: 0.7943 - val_loss: 0.4999 - val_accuracy: 0.7455\n",
      "Epoch 212/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4369 - accuracy: 0.7939 - val_loss: 0.4997 - val_accuracy: 0.7455\n",
      "Epoch 213/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4368 - accuracy: 0.7940 - val_loss: 0.4999 - val_accuracy: 0.7455\n",
      "Epoch 214/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4368 - accuracy: 0.7941 - val_loss: 0.4999 - val_accuracy: 0.7455\n",
      "Epoch 215/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4368 - accuracy: 0.7939 - val_loss: 0.4999 - val_accuracy: 0.7455\n",
      "Epoch 216/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4367 - accuracy: 0.7941 - val_loss: 0.4997 - val_accuracy: 0.7455\n",
      "Epoch 217/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4367 - accuracy: 0.7943 - val_loss: 0.4999 - val_accuracy: 0.7455\n",
      "Epoch 218/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4366 - accuracy: 0.7945 - val_loss: 0.4997 - val_accuracy: 0.7460\n",
      "Epoch 219/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4366 - accuracy: 0.7948 - val_loss: 0.5001 - val_accuracy: 0.7450\n",
      "Epoch 220/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4366 - accuracy: 0.7944 - val_loss: 0.5001 - val_accuracy: 0.7450\n",
      "Epoch 221/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4365 - accuracy: 0.7943 - val_loss: 0.4998 - val_accuracy: 0.7460\n",
      "Epoch 222/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4365 - accuracy: 0.7948 - val_loss: 0.5000 - val_accuracy: 0.7450\n",
      "Epoch 223/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4364 - accuracy: 0.7944 - val_loss: 0.4996 - val_accuracy: 0.7464\n",
      "Epoch 224/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4364 - accuracy: 0.7944 - val_loss: 0.4992 - val_accuracy: 0.7469\n",
      "Epoch 225/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4363 - accuracy: 0.7943 - val_loss: 0.4992 - val_accuracy: 0.7469\n",
      "Epoch 226/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4363 - accuracy: 0.7944 - val_loss: 0.4991 - val_accuracy: 0.7469\n",
      "Epoch 227/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4363 - accuracy: 0.7943 - val_loss: 0.4990 - val_accuracy: 0.7469\n",
      "Epoch 228/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4362 - accuracy: 0.7948 - val_loss: 0.4994 - val_accuracy: 0.7464\n",
      "Epoch 229/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4362 - accuracy: 0.7947 - val_loss: 0.4993 - val_accuracy: 0.7464\n",
      "Epoch 230/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4361 - accuracy: 0.7951 - val_loss: 0.4992 - val_accuracy: 0.7474\n",
      "Epoch 231/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4361 - accuracy: 0.7948 - val_loss: 0.4992 - val_accuracy: 0.7474\n",
      "Epoch 232/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4361 - accuracy: 0.7945 - val_loss: 0.4996 - val_accuracy: 0.7464\n",
      "Epoch 233/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4360 - accuracy: 0.7944 - val_loss: 0.4993 - val_accuracy: 0.7469\n",
      "Epoch 234/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4360 - accuracy: 0.7944 - val_loss: 0.4992 - val_accuracy: 0.7474\n",
      "Epoch 235/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4359 - accuracy: 0.7948 - val_loss: 0.4990 - val_accuracy: 0.7474\n",
      "Epoch 236/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4359 - accuracy: 0.7943 - val_loss: 0.4991 - val_accuracy: 0.7474\n",
      "Epoch 237/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4359 - accuracy: 0.7948 - val_loss: 0.4991 - val_accuracy: 0.7479\n",
      "Epoch 238/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4358 - accuracy: 0.7947 - val_loss: 0.4990 - val_accuracy: 0.7479\n",
      "Epoch 239/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4358 - accuracy: 0.7947 - val_loss: 0.4991 - val_accuracy: 0.7474\n",
      "Epoch 240/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4357 - accuracy: 0.7948 - val_loss: 0.4992 - val_accuracy: 0.7474\n",
      "Epoch 241/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4357 - accuracy: 0.7945 - val_loss: 0.4991 - val_accuracy: 0.7474\n",
      "Epoch 242/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4356 - accuracy: 0.7943 - val_loss: 0.4991 - val_accuracy: 0.7479\n",
      "Epoch 243/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4356 - accuracy: 0.7947 - val_loss: 0.4991 - val_accuracy: 0.7479\n",
      "Epoch 244/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4356 - accuracy: 0.7950 - val_loss: 0.4993 - val_accuracy: 0.7474\n",
      "Epoch 245/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4355 - accuracy: 0.7948 - val_loss: 0.4992 - val_accuracy: 0.7474\n",
      "Epoch 246/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4355 - accuracy: 0.7951 - val_loss: 0.4993 - val_accuracy: 0.7479\n",
      "Epoch 247/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4354 - accuracy: 0.7944 - val_loss: 0.4990 - val_accuracy: 0.7479\n",
      "Epoch 248/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4354 - accuracy: 0.7954 - val_loss: 0.4989 - val_accuracy: 0.7479\n",
      "Epoch 249/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4354 - accuracy: 0.7950 - val_loss: 0.4988 - val_accuracy: 0.7479\n",
      "Epoch 250/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4353 - accuracy: 0.7952 - val_loss: 0.4990 - val_accuracy: 0.7479\n",
      "Epoch 251/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4353 - accuracy: 0.7950 - val_loss: 0.4992 - val_accuracy: 0.7474\n",
      "Epoch 252/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4352 - accuracy: 0.7947 - val_loss: 0.4988 - val_accuracy: 0.7479\n",
      "Epoch 253/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4352 - accuracy: 0.7950 - val_loss: 0.4991 - val_accuracy: 0.7474\n",
      "Epoch 254/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4351 - accuracy: 0.7948 - val_loss: 0.4987 - val_accuracy: 0.7469\n",
      "Epoch 255/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4351 - accuracy: 0.7950 - val_loss: 0.4986 - val_accuracy: 0.7469\n",
      "Epoch 256/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4351 - accuracy: 0.7957 - val_loss: 0.4991 - val_accuracy: 0.7474\n",
      "Epoch 257/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4350 - accuracy: 0.7948 - val_loss: 0.4992 - val_accuracy: 0.7474\n",
      "Epoch 258/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4350 - accuracy: 0.7943 - val_loss: 0.4993 - val_accuracy: 0.7474\n",
      "Epoch 259/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4350 - accuracy: 0.7947 - val_loss: 0.4991 - val_accuracy: 0.7474\n",
      "Epoch 260/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4349 - accuracy: 0.7948 - val_loss: 0.4989 - val_accuracy: 0.7469\n",
      "Epoch 261/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4349 - accuracy: 0.7948 - val_loss: 0.4991 - val_accuracy: 0.7474\n",
      "Epoch 262/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4348 - accuracy: 0.7948 - val_loss: 0.4991 - val_accuracy: 0.7474\n",
      "Epoch 263/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.4990 - val_accuracy: 0.7474\n",
      "Epoch 264/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4348 - accuracy: 0.7944 - val_loss: 0.4988 - val_accuracy: 0.7469\n",
      "Epoch 265/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4347 - accuracy: 0.7952 - val_loss: 0.4988 - val_accuracy: 0.7474\n",
      "Epoch 266/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4347 - accuracy: 0.7951 - val_loss: 0.4989 - val_accuracy: 0.7474\n",
      "Epoch 267/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4346 - accuracy: 0.7955 - val_loss: 0.4989 - val_accuracy: 0.7469\n",
      "Epoch 268/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4346 - accuracy: 0.7944 - val_loss: 0.4988 - val_accuracy: 0.7469\n",
      "Epoch 269/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.4985 - val_accuracy: 0.7469\n",
      "Epoch 270/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4345 - accuracy: 0.7947 - val_loss: 0.4989 - val_accuracy: 0.7474\n",
      "Epoch 271/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.4987 - val_accuracy: 0.7469\n",
      "Epoch 272/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4344 - accuracy: 0.7950 - val_loss: 0.4983 - val_accuracy: 0.7469\n",
      "Epoch 273/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4344 - accuracy: 0.7951 - val_loss: 0.4985 - val_accuracy: 0.7469\n",
      "Epoch 274/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4344 - accuracy: 0.7952 - val_loss: 0.4984 - val_accuracy: 0.7469\n",
      "Epoch 275/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4343 - accuracy: 0.7955 - val_loss: 0.4983 - val_accuracy: 0.7469\n",
      "Epoch 276/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4343 - accuracy: 0.7954 - val_loss: 0.4984 - val_accuracy: 0.7469\n",
      "Epoch 277/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4342 - accuracy: 0.7948 - val_loss: 0.4982 - val_accuracy: 0.7479\n",
      "Epoch 278/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4342 - accuracy: 0.7954 - val_loss: 0.4979 - val_accuracy: 0.7479\n",
      "Epoch 279/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4342 - accuracy: 0.7955 - val_loss: 0.4983 - val_accuracy: 0.7469\n",
      "Epoch 280/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4341 - accuracy: 0.7957 - val_loss: 0.4983 - val_accuracy: 0.7479\n",
      "Epoch 281/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4341 - accuracy: 0.7948 - val_loss: 0.4979 - val_accuracy: 0.7479\n",
      "Epoch 282/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4340 - accuracy: 0.7957 - val_loss: 0.4984 - val_accuracy: 0.7469\n",
      "Epoch 283/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4340 - accuracy: 0.7950 - val_loss: 0.4985 - val_accuracy: 0.7474\n",
      "Epoch 284/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4340 - accuracy: 0.7952 - val_loss: 0.4983 - val_accuracy: 0.7479\n",
      "Epoch 285/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4339 - accuracy: 0.7958 - val_loss: 0.4983 - val_accuracy: 0.7479\n",
      "Epoch 286/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4339 - accuracy: 0.7959 - val_loss: 0.4985 - val_accuracy: 0.7479\n",
      "Epoch 287/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4338 - accuracy: 0.7958 - val_loss: 0.4986 - val_accuracy: 0.7474\n",
      "Epoch 288/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4338 - accuracy: 0.7955 - val_loss: 0.4985 - val_accuracy: 0.7479\n",
      "Epoch 289/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4338 - accuracy: 0.7952 - val_loss: 0.4984 - val_accuracy: 0.7483\n",
      "Epoch 290/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4337 - accuracy: 0.7958 - val_loss: 0.4987 - val_accuracy: 0.7474\n",
      "Epoch 291/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4337 - accuracy: 0.7952 - val_loss: 0.4985 - val_accuracy: 0.7479\n",
      "Epoch 292/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4336 - accuracy: 0.7951 - val_loss: 0.4988 - val_accuracy: 0.7479\n",
      "Epoch 293/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4336 - accuracy: 0.7957 - val_loss: 0.4987 - val_accuracy: 0.7479\n",
      "Epoch 294/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4336 - accuracy: 0.7954 - val_loss: 0.4986 - val_accuracy: 0.7479\n",
      "Epoch 295/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4335 - accuracy: 0.7955 - val_loss: 0.4986 - val_accuracy: 0.7483\n",
      "Epoch 296/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4335 - accuracy: 0.7957 - val_loss: 0.4983 - val_accuracy: 0.7488\n",
      "Epoch 297/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4334 - accuracy: 0.7955 - val_loss: 0.4981 - val_accuracy: 0.7493\n",
      "Epoch 298/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4334 - accuracy: 0.7957 - val_loss: 0.4982 - val_accuracy: 0.7488\n",
      "Epoch 299/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4334 - accuracy: 0.7957 - val_loss: 0.4985 - val_accuracy: 0.7483\n",
      "Epoch 300/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4333 - accuracy: 0.7958 - val_loss: 0.4983 - val_accuracy: 0.7493\n",
      "Epoch 301/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4333 - accuracy: 0.7957 - val_loss: 0.4981 - val_accuracy: 0.7498\n",
      "Epoch 302/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4332 - accuracy: 0.7963 - val_loss: 0.4979 - val_accuracy: 0.7498\n",
      "Epoch 303/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4332 - accuracy: 0.7957 - val_loss: 0.4981 - val_accuracy: 0.7493\n",
      "Epoch 304/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4332 - accuracy: 0.7958 - val_loss: 0.4980 - val_accuracy: 0.7498\n",
      "Epoch 305/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4331 - accuracy: 0.7966 - val_loss: 0.4979 - val_accuracy: 0.7498\n",
      "Epoch 306/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4331 - accuracy: 0.7961 - val_loss: 0.4977 - val_accuracy: 0.7498\n",
      "Epoch 307/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4330 - accuracy: 0.7957 - val_loss: 0.4978 - val_accuracy: 0.7498\n",
      "Epoch 308/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4330 - accuracy: 0.7952 - val_loss: 0.4980 - val_accuracy: 0.7498\n",
      "Epoch 309/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4330 - accuracy: 0.7957 - val_loss: 0.4979 - val_accuracy: 0.7502\n",
      "Epoch 310/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4329 - accuracy: 0.7951 - val_loss: 0.4977 - val_accuracy: 0.7502\n",
      "Epoch 311/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4329 - accuracy: 0.7959 - val_loss: 0.4976 - val_accuracy: 0.7502\n",
      "Epoch 312/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4328 - accuracy: 0.7957 - val_loss: 0.4979 - val_accuracy: 0.7502\n",
      "Epoch 313/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4328 - accuracy: 0.7954 - val_loss: 0.4979 - val_accuracy: 0.7498\n",
      "Epoch 314/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4328 - accuracy: 0.7957 - val_loss: 0.4979 - val_accuracy: 0.7498\n",
      "Epoch 315/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4327 - accuracy: 0.7957 - val_loss: 0.4981 - val_accuracy: 0.7498\n",
      "Epoch 316/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4327 - accuracy: 0.7952 - val_loss: 0.4978 - val_accuracy: 0.7498\n",
      "Epoch 317/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4327 - accuracy: 0.7962 - val_loss: 0.4978 - val_accuracy: 0.7502\n",
      "Epoch 318/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4326 - accuracy: 0.7955 - val_loss: 0.4978 - val_accuracy: 0.7502\n",
      "Epoch 319/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4326 - accuracy: 0.7957 - val_loss: 0.4975 - val_accuracy: 0.7507\n",
      "Epoch 320/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4325 - accuracy: 0.7959 - val_loss: 0.4976 - val_accuracy: 0.7507\n",
      "Epoch 321/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4325 - accuracy: 0.7963 - val_loss: 0.4979 - val_accuracy: 0.7502\n",
      "Epoch 322/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4325 - accuracy: 0.7955 - val_loss: 0.4978 - val_accuracy: 0.7502\n",
      "Epoch 323/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4324 - accuracy: 0.7958 - val_loss: 0.4980 - val_accuracy: 0.7502\n",
      "Epoch 324/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4324 - accuracy: 0.7962 - val_loss: 0.4984 - val_accuracy: 0.7498\n",
      "Epoch 325/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4323 - accuracy: 0.7954 - val_loss: 0.4982 - val_accuracy: 0.7502\n",
      "Epoch 326/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4323 - accuracy: 0.7959 - val_loss: 0.4978 - val_accuracy: 0.7507\n",
      "Epoch 327/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4323 - accuracy: 0.7959 - val_loss: 0.4974 - val_accuracy: 0.7502\n",
      "Epoch 328/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4322 - accuracy: 0.7959 - val_loss: 0.4974 - val_accuracy: 0.7502\n",
      "Epoch 329/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4322 - accuracy: 0.7952 - val_loss: 0.4973 - val_accuracy: 0.7498\n",
      "Epoch 330/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4321 - accuracy: 0.7962 - val_loss: 0.4973 - val_accuracy: 0.7502\n",
      "Epoch 331/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4321 - accuracy: 0.7962 - val_loss: 0.4973 - val_accuracy: 0.7502\n",
      "Epoch 332/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4321 - accuracy: 0.7968 - val_loss: 0.4978 - val_accuracy: 0.7502\n",
      "Epoch 333/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4320 - accuracy: 0.7972 - val_loss: 0.4977 - val_accuracy: 0.7502\n",
      "Epoch 334/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4320 - accuracy: 0.7959 - val_loss: 0.4977 - val_accuracy: 0.7498\n",
      "Epoch 335/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4320 - accuracy: 0.7969 - val_loss: 0.4977 - val_accuracy: 0.7502\n",
      "Epoch 336/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4319 - accuracy: 0.7957 - val_loss: 0.4976 - val_accuracy: 0.7502\n",
      "Epoch 337/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4319 - accuracy: 0.7961 - val_loss: 0.4977 - val_accuracy: 0.7498\n",
      "Epoch 338/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4318 - accuracy: 0.7957 - val_loss: 0.4974 - val_accuracy: 0.7502\n",
      "Epoch 339/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4318 - accuracy: 0.7955 - val_loss: 0.4973 - val_accuracy: 0.7493\n",
      "Epoch 340/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4318 - accuracy: 0.7955 - val_loss: 0.4974 - val_accuracy: 0.7493\n",
      "Epoch 341/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4317 - accuracy: 0.7972 - val_loss: 0.4975 - val_accuracy: 0.7488\n",
      "Epoch 342/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4317 - accuracy: 0.7969 - val_loss: 0.4977 - val_accuracy: 0.7493\n",
      "Epoch 343/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4317 - accuracy: 0.7963 - val_loss: 0.4975 - val_accuracy: 0.7493\n",
      "Epoch 344/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4316 - accuracy: 0.7963 - val_loss: 0.4976 - val_accuracy: 0.7493\n",
      "Epoch 345/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4316 - accuracy: 0.7963 - val_loss: 0.4974 - val_accuracy: 0.7493\n",
      "Epoch 346/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4315 - accuracy: 0.7966 - val_loss: 0.4977 - val_accuracy: 0.7493\n",
      "Epoch 347/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4315 - accuracy: 0.7970 - val_loss: 0.4977 - val_accuracy: 0.7493\n",
      "Epoch 348/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4315 - accuracy: 0.7976 - val_loss: 0.4977 - val_accuracy: 0.7488\n",
      "Epoch 349/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4314 - accuracy: 0.7969 - val_loss: 0.4975 - val_accuracy: 0.7488\n",
      "Epoch 350/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4314 - accuracy: 0.7977 - val_loss: 0.4975 - val_accuracy: 0.7488\n",
      "Epoch 351/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4313 - accuracy: 0.7979 - val_loss: 0.4976 - val_accuracy: 0.7488\n",
      "Epoch 352/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4313 - accuracy: 0.7968 - val_loss: 0.4977 - val_accuracy: 0.7488\n",
      "Epoch 353/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4313 - accuracy: 0.7977 - val_loss: 0.4976 - val_accuracy: 0.7488\n",
      "Epoch 354/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4312 - accuracy: 0.7972 - val_loss: 0.4977 - val_accuracy: 0.7488\n",
      "Epoch 355/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4312 - accuracy: 0.7968 - val_loss: 0.4973 - val_accuracy: 0.7483\n",
      "Epoch 356/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4312 - accuracy: 0.7961 - val_loss: 0.4973 - val_accuracy: 0.7488\n",
      "Epoch 357/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4311 - accuracy: 0.7977 - val_loss: 0.4974 - val_accuracy: 0.7488\n",
      "Epoch 358/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4311 - accuracy: 0.7969 - val_loss: 0.4972 - val_accuracy: 0.7488\n",
      "Epoch 359/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4310 - accuracy: 0.7970 - val_loss: 0.4972 - val_accuracy: 0.7488\n",
      "Epoch 360/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4310 - accuracy: 0.7969 - val_loss: 0.4973 - val_accuracy: 0.7488\n",
      "Epoch 361/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4310 - accuracy: 0.7975 - val_loss: 0.4971 - val_accuracy: 0.7488\n",
      "Epoch 362/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4309 - accuracy: 0.7984 - val_loss: 0.4972 - val_accuracy: 0.7488\n",
      "Epoch 363/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4309 - accuracy: 0.7972 - val_loss: 0.4970 - val_accuracy: 0.7488\n",
      "Epoch 364/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4309 - accuracy: 0.7979 - val_loss: 0.4972 - val_accuracy: 0.7488\n",
      "Epoch 365/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4308 - accuracy: 0.7975 - val_loss: 0.4970 - val_accuracy: 0.7488\n",
      "Epoch 366/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4308 - accuracy: 0.7968 - val_loss: 0.4969 - val_accuracy: 0.7493\n",
      "Epoch 367/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4307 - accuracy: 0.7977 - val_loss: 0.4971 - val_accuracy: 0.7488\n",
      "Epoch 368/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4307 - accuracy: 0.7975 - val_loss: 0.4970 - val_accuracy: 0.7488\n",
      "Epoch 369/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4307 - accuracy: 0.7976 - val_loss: 0.4973 - val_accuracy: 0.7488\n",
      "Epoch 370/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4306 - accuracy: 0.7976 - val_loss: 0.4974 - val_accuracy: 0.7488\n",
      "Epoch 371/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4306 - accuracy: 0.7979 - val_loss: 0.4970 - val_accuracy: 0.7493\n",
      "Epoch 372/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4306 - accuracy: 0.7975 - val_loss: 0.4967 - val_accuracy: 0.7493\n",
      "Epoch 373/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4305 - accuracy: 0.7983 - val_loss: 0.4970 - val_accuracy: 0.7488\n",
      "Epoch 374/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4305 - accuracy: 0.7981 - val_loss: 0.4972 - val_accuracy: 0.7488\n",
      "Epoch 375/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4304 - accuracy: 0.7972 - val_loss: 0.4973 - val_accuracy: 0.7488\n",
      "Epoch 376/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4304 - accuracy: 0.7979 - val_loss: 0.4970 - val_accuracy: 0.7488\n",
      "Epoch 377/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4304 - accuracy: 0.7983 - val_loss: 0.4971 - val_accuracy: 0.7488\n",
      "Epoch 378/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4303 - accuracy: 0.7983 - val_loss: 0.4971 - val_accuracy: 0.7488\n",
      "Epoch 379/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4303 - accuracy: 0.7975 - val_loss: 0.4971 - val_accuracy: 0.7488\n",
      "Epoch 380/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4303 - accuracy: 0.7980 - val_loss: 0.4970 - val_accuracy: 0.7483\n",
      "Epoch 381/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4302 - accuracy: 0.7973 - val_loss: 0.4971 - val_accuracy: 0.7483\n",
      "Epoch 382/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4302 - accuracy: 0.7980 - val_loss: 0.4973 - val_accuracy: 0.7483\n",
      "Epoch 383/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4301 - accuracy: 0.7980 - val_loss: 0.4971 - val_accuracy: 0.7483\n",
      "Epoch 384/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4301 - accuracy: 0.7986 - val_loss: 0.4969 - val_accuracy: 0.7488\n",
      "Epoch 385/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4301 - accuracy: 0.7983 - val_loss: 0.4969 - val_accuracy: 0.7483\n",
      "Epoch 386/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4300 - accuracy: 0.7984 - val_loss: 0.4967 - val_accuracy: 0.7483\n",
      "Epoch 387/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4300 - accuracy: 0.7976 - val_loss: 0.4968 - val_accuracy: 0.7488\n",
      "Epoch 388/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4299 - accuracy: 0.7984 - val_loss: 0.4971 - val_accuracy: 0.7483\n",
      "Epoch 389/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4299 - accuracy: 0.7986 - val_loss: 0.4971 - val_accuracy: 0.7474\n",
      "Epoch 390/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4299 - accuracy: 0.7986 - val_loss: 0.4970 - val_accuracy: 0.7479\n",
      "Epoch 391/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4298 - accuracy: 0.7983 - val_loss: 0.4967 - val_accuracy: 0.7479\n",
      "Epoch 392/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4298 - accuracy: 0.7988 - val_loss: 0.4966 - val_accuracy: 0.7479\n",
      "Epoch 393/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4298 - accuracy: 0.7984 - val_loss: 0.4964 - val_accuracy: 0.7479\n",
      "Epoch 394/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4297 - accuracy: 0.7991 - val_loss: 0.4966 - val_accuracy: 0.7479\n",
      "Epoch 395/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4297 - accuracy: 0.7986 - val_loss: 0.4968 - val_accuracy: 0.7479\n",
      "Epoch 396/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4297 - accuracy: 0.7987 - val_loss: 0.4967 - val_accuracy: 0.7479\n",
      "Epoch 397/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4296 - accuracy: 0.7987 - val_loss: 0.4965 - val_accuracy: 0.7479\n",
      "Epoch 398/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4296 - accuracy: 0.7987 - val_loss: 0.4969 - val_accuracy: 0.7479\n",
      "Epoch 399/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4295 - accuracy: 0.7987 - val_loss: 0.4967 - val_accuracy: 0.7483\n",
      "Epoch 400/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4295 - accuracy: 0.7988 - val_loss: 0.4965 - val_accuracy: 0.7483\n",
      "Epoch 401/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.4962 - val_accuracy: 0.7483\n",
      "Epoch 402/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4294 - accuracy: 0.7990 - val_loss: 0.4964 - val_accuracy: 0.7483\n",
      "Epoch 403/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4294 - accuracy: 0.7988 - val_loss: 0.4965 - val_accuracy: 0.7483\n",
      "Epoch 404/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4294 - accuracy: 0.7990 - val_loss: 0.4964 - val_accuracy: 0.7483\n",
      "Epoch 405/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4293 - accuracy: 0.7988 - val_loss: 0.4959 - val_accuracy: 0.7483\n",
      "Epoch 406/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4293 - accuracy: 0.7988 - val_loss: 0.4959 - val_accuracy: 0.7483\n",
      "Epoch 407/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4292 - accuracy: 0.7986 - val_loss: 0.4962 - val_accuracy: 0.7483\n",
      "Epoch 408/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4292 - accuracy: 0.7988 - val_loss: 0.4966 - val_accuracy: 0.7479\n",
      "Epoch 409/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4292 - accuracy: 0.7991 - val_loss: 0.4970 - val_accuracy: 0.7483\n",
      "Epoch 410/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4291 - accuracy: 0.7993 - val_loss: 0.4967 - val_accuracy: 0.7483\n",
      "Epoch 411/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4291 - accuracy: 0.7981 - val_loss: 0.4968 - val_accuracy: 0.7483\n",
      "Epoch 412/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4291 - accuracy: 0.7987 - val_loss: 0.4965 - val_accuracy: 0.7488\n",
      "Epoch 413/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4290 - accuracy: 0.7986 - val_loss: 0.4961 - val_accuracy: 0.7488\n",
      "Epoch 414/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4290 - accuracy: 0.7993 - val_loss: 0.4962 - val_accuracy: 0.7488\n",
      "Epoch 415/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4290 - accuracy: 0.7988 - val_loss: 0.4965 - val_accuracy: 0.7488\n",
      "Epoch 416/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4289 - accuracy: 0.7986 - val_loss: 0.4964 - val_accuracy: 0.7488\n",
      "Epoch 417/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4289 - accuracy: 0.7983 - val_loss: 0.4961 - val_accuracy: 0.7488\n",
      "Epoch 418/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4288 - accuracy: 0.7988 - val_loss: 0.4963 - val_accuracy: 0.7488\n",
      "Epoch 419/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4288 - accuracy: 0.7993 - val_loss: 0.4964 - val_accuracy: 0.7488\n",
      "Epoch 420/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4288 - accuracy: 0.7983 - val_loss: 0.4963 - val_accuracy: 0.7488\n",
      "Epoch 421/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4287 - accuracy: 0.7988 - val_loss: 0.4961 - val_accuracy: 0.7488\n",
      "Epoch 422/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4287 - accuracy: 0.7988 - val_loss: 0.4963 - val_accuracy: 0.7488\n",
      "Epoch 423/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4287 - accuracy: 0.7991 - val_loss: 0.4963 - val_accuracy: 0.7488\n",
      "Epoch 424/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4286 - accuracy: 0.7990 - val_loss: 0.4963 - val_accuracy: 0.7488\n",
      "Epoch 425/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4286 - accuracy: 0.7990 - val_loss: 0.4961 - val_accuracy: 0.7488\n",
      "Epoch 426/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4286 - accuracy: 0.7994 - val_loss: 0.4965 - val_accuracy: 0.7488\n",
      "Epoch 427/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4285 - accuracy: 0.7990 - val_loss: 0.4962 - val_accuracy: 0.7488\n",
      "Epoch 428/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4285 - accuracy: 0.7995 - val_loss: 0.4962 - val_accuracy: 0.7488\n",
      "Epoch 429/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4284 - accuracy: 0.7990 - val_loss: 0.4965 - val_accuracy: 0.7483\n",
      "Epoch 430/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4284 - accuracy: 0.7991 - val_loss: 0.4963 - val_accuracy: 0.7483\n",
      "Epoch 431/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4284 - accuracy: 0.7991 - val_loss: 0.4964 - val_accuracy: 0.7483\n",
      "Epoch 432/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4283 - accuracy: 0.7993 - val_loss: 0.4965 - val_accuracy: 0.7483\n",
      "Epoch 433/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4283 - accuracy: 0.7993 - val_loss: 0.4963 - val_accuracy: 0.7479\n",
      "Epoch 434/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4283 - accuracy: 0.7990 - val_loss: 0.4964 - val_accuracy: 0.7483\n",
      "Epoch 435/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4282 - accuracy: 0.7991 - val_loss: 0.4965 - val_accuracy: 0.7483\n",
      "Epoch 436/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4282 - accuracy: 0.7990 - val_loss: 0.4963 - val_accuracy: 0.7479\n",
      "Epoch 437/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4281 - accuracy: 0.7986 - val_loss: 0.4962 - val_accuracy: 0.7479\n",
      "Epoch 438/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4281 - accuracy: 0.7991 - val_loss: 0.4962 - val_accuracy: 0.7483\n",
      "Epoch 439/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4281 - accuracy: 0.7987 - val_loss: 0.4960 - val_accuracy: 0.7483\n",
      "Epoch 440/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4280 - accuracy: 0.7997 - val_loss: 0.4960 - val_accuracy: 0.7483\n",
      "Epoch 441/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4280 - accuracy: 0.7998 - val_loss: 0.4964 - val_accuracy: 0.7483\n",
      "Epoch 442/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4280 - accuracy: 0.7997 - val_loss: 0.4962 - val_accuracy: 0.7483\n",
      "Epoch 443/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7990 - val_loss: 0.4961 - val_accuracy: 0.7483\n",
      "Epoch 444/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4279 - accuracy: 0.7994 - val_loss: 0.4962 - val_accuracy: 0.7483\n",
      "Epoch 445/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7997 - val_loss: 0.4962 - val_accuracy: 0.7483\n",
      "Epoch 446/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4278 - accuracy: 0.7995 - val_loss: 0.4962 - val_accuracy: 0.7483\n",
      "Epoch 447/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4278 - accuracy: 0.7997 - val_loss: 0.4961 - val_accuracy: 0.7483\n",
      "Epoch 448/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4277 - accuracy: 0.7998 - val_loss: 0.4961 - val_accuracy: 0.7483\n",
      "Epoch 449/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7999 - val_loss: 0.4959 - val_accuracy: 0.7483\n",
      "Epoch 450/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4277 - accuracy: 0.7994 - val_loss: 0.4958 - val_accuracy: 0.7483\n",
      "Epoch 451/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8001 - val_loss: 0.4958 - val_accuracy: 0.7483\n",
      "Epoch 452/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4276 - accuracy: 0.7990 - val_loss: 0.4958 - val_accuracy: 0.7483\n",
      "Epoch 453/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7997 - val_loss: 0.4958 - val_accuracy: 0.7483\n",
      "Epoch 454/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4275 - accuracy: 0.7993 - val_loss: 0.4958 - val_accuracy: 0.7483\n",
      "Epoch 455/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7997 - val_loss: 0.4959 - val_accuracy: 0.7483\n",
      "Epoch 456/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4274 - accuracy: 0.7999 - val_loss: 0.4959 - val_accuracy: 0.7483\n",
      "Epoch 457/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4274 - accuracy: 0.7997 - val_loss: 0.4959 - val_accuracy: 0.7483\n",
      "Epoch 458/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4274 - accuracy: 0.7994 - val_loss: 0.4958 - val_accuracy: 0.7483\n",
      "Epoch 459/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7997 - val_loss: 0.4957 - val_accuracy: 0.7479\n",
      "Epoch 460/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4273 - accuracy: 0.7998 - val_loss: 0.4961 - val_accuracy: 0.7483\n",
      "Epoch 461/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4273 - accuracy: 0.7994 - val_loss: 0.4960 - val_accuracy: 0.7479\n",
      "Epoch 462/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4272 - accuracy: 0.7997 - val_loss: 0.4959 - val_accuracy: 0.7479\n",
      "Epoch 463/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7997 - val_loss: 0.4958 - val_accuracy: 0.7479\n",
      "Epoch 464/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8001 - val_loss: 0.4956 - val_accuracy: 0.7479\n",
      "Epoch 465/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7998 - val_loss: 0.4956 - val_accuracy: 0.7479\n",
      "Epoch 466/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4271 - accuracy: 0.8001 - val_loss: 0.4960 - val_accuracy: 0.7479\n",
      "Epoch 467/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7999 - val_loss: 0.4961 - val_accuracy: 0.7479\n",
      "Epoch 468/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7995 - val_loss: 0.4960 - val_accuracy: 0.7479\n",
      "Epoch 469/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7997 - val_loss: 0.4958 - val_accuracy: 0.7479\n",
      "Epoch 470/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8002 - val_loss: 0.4955 - val_accuracy: 0.7479\n",
      "Epoch 471/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4269 - accuracy: 0.8004 - val_loss: 0.4959 - val_accuracy: 0.7479\n",
      "Epoch 472/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7998 - val_loss: 0.4958 - val_accuracy: 0.7479\n",
      "Epoch 473/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8001 - val_loss: 0.4959 - val_accuracy: 0.7479\n",
      "Epoch 474/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8004 - val_loss: 0.4953 - val_accuracy: 0.7483\n",
      "Epoch 475/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4268 - accuracy: 0.8001 - val_loss: 0.4951 - val_accuracy: 0.7483\n",
      "Epoch 476/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4267 - accuracy: 0.7998 - val_loss: 0.4956 - val_accuracy: 0.7479\n",
      "Epoch 477/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7997 - val_loss: 0.4957 - val_accuracy: 0.7479\n",
      "Epoch 478/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4266 - accuracy: 0.7995 - val_loss: 0.4958 - val_accuracy: 0.7469\n",
      "Epoch 479/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8002 - val_loss: 0.4958 - val_accuracy: 0.7474\n",
      "Epoch 480/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4266 - accuracy: 0.7999 - val_loss: 0.4956 - val_accuracy: 0.7479\n",
      "Epoch 481/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4265 - accuracy: 0.8002 - val_loss: 0.4958 - val_accuracy: 0.7474\n",
      "Epoch 482/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8004 - val_loss: 0.4959 - val_accuracy: 0.7474\n",
      "Epoch 483/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8002 - val_loss: 0.4958 - val_accuracy: 0.7474\n",
      "Epoch 484/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4264 - accuracy: 0.8002 - val_loss: 0.4959 - val_accuracy: 0.7474\n",
      "Epoch 485/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4264 - accuracy: 0.8009 - val_loss: 0.4956 - val_accuracy: 0.7474\n",
      "Epoch 486/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4264 - accuracy: 0.8008 - val_loss: 0.4958 - val_accuracy: 0.7474\n",
      "Epoch 487/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4263 - accuracy: 0.8005 - val_loss: 0.4959 - val_accuracy: 0.7469\n",
      "Epoch 488/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4263 - accuracy: 0.8009 - val_loss: 0.4959 - val_accuracy: 0.7469\n",
      "Epoch 489/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4262 - accuracy: 0.8008 - val_loss: 0.4955 - val_accuracy: 0.7483\n",
      "Epoch 490/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4262 - accuracy: 0.8005 - val_loss: 0.4955 - val_accuracy: 0.7483\n",
      "Epoch 491/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4262 - accuracy: 0.8002 - val_loss: 0.4955 - val_accuracy: 0.7479\n",
      "Epoch 492/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4261 - accuracy: 0.7999 - val_loss: 0.4956 - val_accuracy: 0.7474\n",
      "Epoch 493/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4261 - accuracy: 0.8008 - val_loss: 0.4955 - val_accuracy: 0.7474\n",
      "Epoch 494/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4261 - accuracy: 0.8013 - val_loss: 0.4956 - val_accuracy: 0.7474\n",
      "Epoch 495/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4260 - accuracy: 0.8012 - val_loss: 0.4959 - val_accuracy: 0.7474\n",
      "Epoch 496/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4260 - accuracy: 0.8006 - val_loss: 0.4959 - val_accuracy: 0.7469\n",
      "Epoch 497/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4260 - accuracy: 0.8006 - val_loss: 0.4957 - val_accuracy: 0.7469\n",
      "Epoch 498/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4259 - accuracy: 0.8005 - val_loss: 0.4956 - val_accuracy: 0.7469\n",
      "Epoch 499/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4259 - accuracy: 0.8009 - val_loss: 0.4960 - val_accuracy: 0.7469\n",
      "Epoch 500/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4259 - accuracy: 0.8011 - val_loss: 0.4959 - val_accuracy: 0.7469\n",
      "Epoch 501/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4258 - accuracy: 0.8006 - val_loss: 0.4958 - val_accuracy: 0.7469\n",
      "Epoch 502/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4258 - accuracy: 0.8016 - val_loss: 0.4956 - val_accuracy: 0.7469\n",
      "Epoch 503/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4257 - accuracy: 0.8019 - val_loss: 0.4957 - val_accuracy: 0.7469\n",
      "Epoch 504/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4257 - accuracy: 0.8011 - val_loss: 0.4954 - val_accuracy: 0.7474\n",
      "Epoch 505/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4257 - accuracy: 0.8009 - val_loss: 0.4955 - val_accuracy: 0.7474\n",
      "Epoch 506/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4256 - accuracy: 0.8016 - val_loss: 0.4957 - val_accuracy: 0.7469\n",
      "Epoch 507/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4256 - accuracy: 0.8019 - val_loss: 0.4954 - val_accuracy: 0.7474\n",
      "Epoch 508/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4256 - accuracy: 0.8015 - val_loss: 0.4953 - val_accuracy: 0.7479\n",
      "Epoch 509/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4255 - accuracy: 0.8016 - val_loss: 0.4954 - val_accuracy: 0.7469\n",
      "Epoch 510/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4255 - accuracy: 0.8011 - val_loss: 0.4957 - val_accuracy: 0.7474\n",
      "Epoch 511/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4255 - accuracy: 0.8013 - val_loss: 0.4954 - val_accuracy: 0.7479\n",
      "Epoch 512/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4254 - accuracy: 0.8019 - val_loss: 0.4956 - val_accuracy: 0.7479\n",
      "Epoch 513/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4254 - accuracy: 0.8015 - val_loss: 0.4956 - val_accuracy: 0.7479\n",
      "Epoch 514/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4254 - accuracy: 0.8012 - val_loss: 0.4956 - val_accuracy: 0.7479\n",
      "Epoch 515/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4253 - accuracy: 0.8016 - val_loss: 0.4954 - val_accuracy: 0.7479\n",
      "Epoch 516/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4253 - accuracy: 0.8013 - val_loss: 0.4953 - val_accuracy: 0.7479\n",
      "Epoch 517/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4252 - accuracy: 0.8015 - val_loss: 0.4950 - val_accuracy: 0.7474\n",
      "Epoch 518/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4252 - accuracy: 0.8016 - val_loss: 0.4951 - val_accuracy: 0.7474\n",
      "Epoch 519/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4252 - accuracy: 0.8013 - val_loss: 0.4952 - val_accuracy: 0.7474\n",
      "Epoch 520/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4251 - accuracy: 0.8030 - val_loss: 0.4952 - val_accuracy: 0.7474\n",
      "Epoch 521/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4251 - accuracy: 0.8016 - val_loss: 0.4953 - val_accuracy: 0.7474\n",
      "Epoch 522/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4251 - accuracy: 0.8011 - val_loss: 0.4952 - val_accuracy: 0.7474\n",
      "Epoch 523/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4250 - accuracy: 0.8016 - val_loss: 0.4952 - val_accuracy: 0.7474\n",
      "Epoch 524/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4250 - accuracy: 0.8015 - val_loss: 0.4954 - val_accuracy: 0.7474\n",
      "Epoch 525/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4249 - accuracy: 0.8026 - val_loss: 0.4955 - val_accuracy: 0.7479\n",
      "Epoch 526/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4249 - accuracy: 0.8020 - val_loss: 0.4949 - val_accuracy: 0.7474\n",
      "Epoch 527/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4249 - accuracy: 0.8016 - val_loss: 0.4949 - val_accuracy: 0.7474\n",
      "Epoch 528/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4248 - accuracy: 0.8013 - val_loss: 0.4951 - val_accuracy: 0.7474\n",
      "Epoch 529/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4248 - accuracy: 0.8016 - val_loss: 0.4952 - val_accuracy: 0.7474\n",
      "Epoch 530/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4248 - accuracy: 0.8015 - val_loss: 0.4950 - val_accuracy: 0.7474\n",
      "Epoch 531/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4247 - accuracy: 0.8016 - val_loss: 0.4952 - val_accuracy: 0.7474\n",
      "Epoch 532/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4247 - accuracy: 0.8023 - val_loss: 0.4949 - val_accuracy: 0.7474\n",
      "Epoch 533/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4247 - accuracy: 0.8019 - val_loss: 0.4950 - val_accuracy: 0.7474\n",
      "Epoch 534/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4246 - accuracy: 0.8023 - val_loss: 0.4949 - val_accuracy: 0.7474\n",
      "Epoch 535/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4246 - accuracy: 0.8019 - val_loss: 0.4950 - val_accuracy: 0.7474\n",
      "Epoch 536/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4246 - accuracy: 0.8017 - val_loss: 0.4949 - val_accuracy: 0.7474\n",
      "Epoch 537/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4245 - accuracy: 0.8023 - val_loss: 0.4952 - val_accuracy: 0.7469\n",
      "Epoch 538/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4245 - accuracy: 0.8024 - val_loss: 0.4949 - val_accuracy: 0.7474\n",
      "Epoch 539/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4245 - accuracy: 0.8017 - val_loss: 0.4952 - val_accuracy: 0.7469\n",
      "Epoch 540/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4244 - accuracy: 0.8027 - val_loss: 0.4952 - val_accuracy: 0.7469\n",
      "Epoch 541/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4244 - accuracy: 0.8023 - val_loss: 0.4958 - val_accuracy: 0.7469\n",
      "Epoch 542/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4243 - accuracy: 0.8019 - val_loss: 0.4954 - val_accuracy: 0.7464\n",
      "Epoch 543/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4243 - accuracy: 0.8020 - val_loss: 0.4956 - val_accuracy: 0.7464\n",
      "Epoch 544/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4243 - accuracy: 0.8022 - val_loss: 0.4957 - val_accuracy: 0.7455\n",
      "Epoch 545/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4242 - accuracy: 0.8023 - val_loss: 0.4955 - val_accuracy: 0.7464\n",
      "Epoch 546/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4242 - accuracy: 0.8022 - val_loss: 0.4952 - val_accuracy: 0.7469\n",
      "Epoch 547/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4242 - accuracy: 0.8023 - val_loss: 0.4949 - val_accuracy: 0.7469\n",
      "Epoch 548/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4241 - accuracy: 0.8020 - val_loss: 0.4945 - val_accuracy: 0.7474\n",
      "Epoch 549/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4241 - accuracy: 0.8022 - val_loss: 0.4946 - val_accuracy: 0.7474\n",
      "Epoch 550/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4241 - accuracy: 0.8022 - val_loss: 0.4951 - val_accuracy: 0.7469\n",
      "Epoch 551/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4240 - accuracy: 0.8027 - val_loss: 0.4955 - val_accuracy: 0.7455\n",
      "Epoch 552/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4240 - accuracy: 0.8027 - val_loss: 0.4952 - val_accuracy: 0.7464\n",
      "Epoch 553/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4239 - accuracy: 0.8024 - val_loss: 0.4951 - val_accuracy: 0.7469\n",
      "Epoch 554/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4239 - accuracy: 0.8023 - val_loss: 0.4949 - val_accuracy: 0.7474\n",
      "Epoch 555/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4239 - accuracy: 0.8022 - val_loss: 0.4952 - val_accuracy: 0.7460\n",
      "Epoch 556/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4238 - accuracy: 0.8027 - val_loss: 0.4952 - val_accuracy: 0.7469\n",
      "Epoch 557/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4238 - accuracy: 0.8026 - val_loss: 0.4951 - val_accuracy: 0.7474\n",
      "Epoch 558/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4238 - accuracy: 0.8027 - val_loss: 0.4951 - val_accuracy: 0.7469\n",
      "Epoch 559/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4237 - accuracy: 0.8024 - val_loss: 0.4948 - val_accuracy: 0.7474\n",
      "Epoch 560/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4237 - accuracy: 0.8029 - val_loss: 0.4946 - val_accuracy: 0.7469\n",
      "Epoch 561/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4236 - accuracy: 0.8029 - val_loss: 0.4949 - val_accuracy: 0.7479\n",
      "Epoch 562/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4236 - accuracy: 0.8030 - val_loss: 0.4948 - val_accuracy: 0.7479\n",
      "Epoch 563/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4236 - accuracy: 0.8027 - val_loss: 0.4948 - val_accuracy: 0.7479\n",
      "Epoch 564/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4236 - accuracy: 0.8026 - val_loss: 0.4947 - val_accuracy: 0.7474\n",
      "Epoch 565/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4235 - accuracy: 0.8033 - val_loss: 0.4946 - val_accuracy: 0.7479\n",
      "Epoch 566/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4235 - accuracy: 0.8031 - val_loss: 0.4947 - val_accuracy: 0.7479\n",
      "Epoch 567/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4234 - accuracy: 0.8030 - val_loss: 0.4947 - val_accuracy: 0.7474\n",
      "Epoch 568/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4234 - accuracy: 0.8030 - val_loss: 0.4947 - val_accuracy: 0.7479\n",
      "Epoch 569/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4234 - accuracy: 0.8030 - val_loss: 0.4947 - val_accuracy: 0.7479\n",
      "Epoch 570/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4233 - accuracy: 0.8030 - val_loss: 0.4947 - val_accuracy: 0.7479\n",
      "Epoch 571/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4233 - accuracy: 0.8033 - val_loss: 0.4949 - val_accuracy: 0.7474\n",
      "Epoch 572/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4233 - accuracy: 0.8037 - val_loss: 0.4946 - val_accuracy: 0.7460\n",
      "Epoch 573/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4232 - accuracy: 0.8040 - val_loss: 0.4947 - val_accuracy: 0.7464\n",
      "Epoch 574/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4232 - accuracy: 0.8035 - val_loss: 0.4947 - val_accuracy: 0.7464\n",
      "Epoch 575/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4232 - accuracy: 0.8031 - val_loss: 0.4948 - val_accuracy: 0.7464\n",
      "Epoch 576/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4231 - accuracy: 0.8035 - val_loss: 0.4950 - val_accuracy: 0.7464\n",
      "Epoch 577/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4231 - accuracy: 0.8031 - val_loss: 0.4952 - val_accuracy: 0.7469\n",
      "Epoch 578/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4230 - accuracy: 0.8034 - val_loss: 0.4949 - val_accuracy: 0.7464\n",
      "Epoch 579/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4230 - accuracy: 0.8030 - val_loss: 0.4946 - val_accuracy: 0.7479\n",
      "Epoch 580/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4230 - accuracy: 0.8040 - val_loss: 0.4946 - val_accuracy: 0.7464\n",
      "Epoch 581/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4229 - accuracy: 0.8037 - val_loss: 0.4945 - val_accuracy: 0.7469\n",
      "Epoch 582/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4229 - accuracy: 0.8037 - val_loss: 0.4946 - val_accuracy: 0.7464\n",
      "Epoch 583/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4229 - accuracy: 0.8037 - val_loss: 0.4947 - val_accuracy: 0.7464\n",
      "Epoch 584/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4228 - accuracy: 0.8040 - val_loss: 0.4946 - val_accuracy: 0.7464\n",
      "Epoch 585/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4228 - accuracy: 0.8029 - val_loss: 0.4943 - val_accuracy: 0.7474\n",
      "Epoch 586/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4228 - accuracy: 0.8040 - val_loss: 0.4944 - val_accuracy: 0.7460\n",
      "Epoch 587/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4227 - accuracy: 0.8037 - val_loss: 0.4946 - val_accuracy: 0.7479\n",
      "Epoch 588/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4227 - accuracy: 0.8042 - val_loss: 0.4946 - val_accuracy: 0.7479\n",
      "Epoch 589/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4227 - accuracy: 0.8038 - val_loss: 0.4946 - val_accuracy: 0.7464\n",
      "Epoch 590/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4226 - accuracy: 0.8048 - val_loss: 0.4952 - val_accuracy: 0.7464\n",
      "Epoch 591/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4226 - accuracy: 0.8038 - val_loss: 0.4950 - val_accuracy: 0.7464\n",
      "Epoch 592/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4225 - accuracy: 0.8046 - val_loss: 0.4952 - val_accuracy: 0.7464\n",
      "Epoch 593/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4225 - accuracy: 0.8038 - val_loss: 0.4952 - val_accuracy: 0.7464\n",
      "Epoch 594/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4225 - accuracy: 0.8038 - val_loss: 0.4947 - val_accuracy: 0.7479\n",
      "Epoch 595/1000\n",
      "226/226 [==============================] - 3s 14ms/step - loss: 0.4224 - accuracy: 0.8037 - val_loss: 0.4944 - val_accuracy: 0.7460\n",
      "Epoch 596/1000\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.4224 - accuracy: 0.8038 - val_loss: 0.4945 - val_accuracy: 0.7460\n",
      "Epoch 597/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4224 - accuracy: 0.8031 - val_loss: 0.4943 - val_accuracy: 0.7460\n",
      "Epoch 598/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4223 - accuracy: 0.8037 - val_loss: 0.4944 - val_accuracy: 0.7460\n",
      "Epoch 599/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4223 - accuracy: 0.8042 - val_loss: 0.4944 - val_accuracy: 0.7455\n",
      "Epoch 600/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4223 - accuracy: 0.8041 - val_loss: 0.4943 - val_accuracy: 0.7460\n",
      "Epoch 601/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4222 - accuracy: 0.8044 - val_loss: 0.4946 - val_accuracy: 0.7464\n",
      "Epoch 602/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4222 - accuracy: 0.8037 - val_loss: 0.4945 - val_accuracy: 0.7460\n",
      "Epoch 603/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4222 - accuracy: 0.8042 - val_loss: 0.4945 - val_accuracy: 0.7460\n",
      "Epoch 604/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4221 - accuracy: 0.8040 - val_loss: 0.4944 - val_accuracy: 0.7460\n",
      "Epoch 605/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4221 - accuracy: 0.8037 - val_loss: 0.4947 - val_accuracy: 0.7460\n",
      "Epoch 606/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4220 - accuracy: 0.8045 - val_loss: 0.4948 - val_accuracy: 0.7460\n",
      "Epoch 607/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4220 - accuracy: 0.8035 - val_loss: 0.4947 - val_accuracy: 0.7464\n",
      "Epoch 608/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4220 - accuracy: 0.8042 - val_loss: 0.4946 - val_accuracy: 0.7479\n",
      "Epoch 609/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4219 - accuracy: 0.8044 - val_loss: 0.4944 - val_accuracy: 0.7464\n",
      "Epoch 610/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4219 - accuracy: 0.8048 - val_loss: 0.4943 - val_accuracy: 0.7464\n",
      "Epoch 611/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4219 - accuracy: 0.8045 - val_loss: 0.4945 - val_accuracy: 0.7469\n",
      "Epoch 612/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4218 - accuracy: 0.8042 - val_loss: 0.4946 - val_accuracy: 0.7460\n",
      "Epoch 613/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4218 - accuracy: 0.8044 - val_loss: 0.4948 - val_accuracy: 0.7464\n",
      "Epoch 614/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4218 - accuracy: 0.8046 - val_loss: 0.4949 - val_accuracy: 0.7460\n",
      "Epoch 615/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4217 - accuracy: 0.8035 - val_loss: 0.4951 - val_accuracy: 0.7469\n",
      "Epoch 616/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4217 - accuracy: 0.8041 - val_loss: 0.4948 - val_accuracy: 0.7469\n",
      "Epoch 617/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4217 - accuracy: 0.8049 - val_loss: 0.4947 - val_accuracy: 0.7464\n",
      "Epoch 618/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4216 - accuracy: 0.8044 - val_loss: 0.4943 - val_accuracy: 0.7460\n",
      "Epoch 619/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4216 - accuracy: 0.8049 - val_loss: 0.4943 - val_accuracy: 0.7460\n",
      "Epoch 620/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4215 - accuracy: 0.8045 - val_loss: 0.4942 - val_accuracy: 0.7469\n",
      "Epoch 621/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4215 - accuracy: 0.8045 - val_loss: 0.4944 - val_accuracy: 0.7460\n",
      "Epoch 622/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4215 - accuracy: 0.8041 - val_loss: 0.4947 - val_accuracy: 0.7464\n",
      "Epoch 623/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4214 - accuracy: 0.8038 - val_loss: 0.4948 - val_accuracy: 0.7464\n",
      "Epoch 624/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4214 - accuracy: 0.8044 - val_loss: 0.4947 - val_accuracy: 0.7474\n",
      "Epoch 625/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4214 - accuracy: 0.8048 - val_loss: 0.4947 - val_accuracy: 0.7474\n",
      "Epoch 626/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4213 - accuracy: 0.8046 - val_loss: 0.4944 - val_accuracy: 0.7469\n",
      "Epoch 627/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4213 - accuracy: 0.8041 - val_loss: 0.4947 - val_accuracy: 0.7469\n",
      "Epoch 628/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4213 - accuracy: 0.8052 - val_loss: 0.4949 - val_accuracy: 0.7479\n",
      "Epoch 629/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4212 - accuracy: 0.8046 - val_loss: 0.4950 - val_accuracy: 0.7474\n",
      "Epoch 630/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4212 - accuracy: 0.8045 - val_loss: 0.4946 - val_accuracy: 0.7469\n",
      "Epoch 631/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4212 - accuracy: 0.8051 - val_loss: 0.4945 - val_accuracy: 0.7469\n",
      "Epoch 632/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4211 - accuracy: 0.8046 - val_loss: 0.4943 - val_accuracy: 0.7464\n",
      "Epoch 633/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4211 - accuracy: 0.8051 - val_loss: 0.4944 - val_accuracy: 0.7464\n",
      "Epoch 634/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4211 - accuracy: 0.8045 - val_loss: 0.4943 - val_accuracy: 0.7469\n",
      "Epoch 635/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4210 - accuracy: 0.8049 - val_loss: 0.4944 - val_accuracy: 0.7464\n",
      "Epoch 636/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4210 - accuracy: 0.8053 - val_loss: 0.4944 - val_accuracy: 0.7469\n",
      "Epoch 637/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4210 - accuracy: 0.8045 - val_loss: 0.4945 - val_accuracy: 0.7464\n",
      "Epoch 638/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4209 - accuracy: 0.8045 - val_loss: 0.4947 - val_accuracy: 0.7469\n",
      "Epoch 639/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4209 - accuracy: 0.8055 - val_loss: 0.4948 - val_accuracy: 0.7474\n",
      "Epoch 640/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4208 - accuracy: 0.8055 - val_loss: 0.4951 - val_accuracy: 0.7479\n",
      "Epoch 641/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4208 - accuracy: 0.8056 - val_loss: 0.4949 - val_accuracy: 0.7479\n",
      "Epoch 642/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4208 - accuracy: 0.8049 - val_loss: 0.4945 - val_accuracy: 0.7474\n",
      "Epoch 643/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4207 - accuracy: 0.8053 - val_loss: 0.4944 - val_accuracy: 0.7464\n",
      "Epoch 644/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4207 - accuracy: 0.8048 - val_loss: 0.4943 - val_accuracy: 0.7474\n",
      "Epoch 645/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4207 - accuracy: 0.8049 - val_loss: 0.4941 - val_accuracy: 0.7474\n",
      "Epoch 646/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4206 - accuracy: 0.8056 - val_loss: 0.4941 - val_accuracy: 0.7474\n",
      "Epoch 647/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4206 - accuracy: 0.8051 - val_loss: 0.4942 - val_accuracy: 0.7474\n",
      "Epoch 648/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4206 - accuracy: 0.8055 - val_loss: 0.4945 - val_accuracy: 0.7479\n",
      "Epoch 649/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4205 - accuracy: 0.8051 - val_loss: 0.4943 - val_accuracy: 0.7464\n",
      "Epoch 650/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4205 - accuracy: 0.8046 - val_loss: 0.4942 - val_accuracy: 0.7464\n",
      "Epoch 651/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4205 - accuracy: 0.8052 - val_loss: 0.4944 - val_accuracy: 0.7464\n",
      "Epoch 652/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4204 - accuracy: 0.8044 - val_loss: 0.4944 - val_accuracy: 0.7474\n",
      "Epoch 653/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4204 - accuracy: 0.8051 - val_loss: 0.4946 - val_accuracy: 0.7474\n",
      "Epoch 654/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4204 - accuracy: 0.8051 - val_loss: 0.4946 - val_accuracy: 0.7474\n",
      "Epoch 655/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4203 - accuracy: 0.8048 - val_loss: 0.4946 - val_accuracy: 0.7460\n",
      "Epoch 656/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4203 - accuracy: 0.8051 - val_loss: 0.4943 - val_accuracy: 0.7474\n",
      "Epoch 657/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4203 - accuracy: 0.8055 - val_loss: 0.4945 - val_accuracy: 0.7474\n",
      "Epoch 658/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4202 - accuracy: 0.8055 - val_loss: 0.4941 - val_accuracy: 0.7474\n",
      "Epoch 659/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4202 - accuracy: 0.8053 - val_loss: 0.4941 - val_accuracy: 0.7469\n",
      "Epoch 660/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4201 - accuracy: 0.8052 - val_loss: 0.4942 - val_accuracy: 0.7460\n",
      "Epoch 661/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4201 - accuracy: 0.8053 - val_loss: 0.4941 - val_accuracy: 0.7474\n",
      "Epoch 662/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4201 - accuracy: 0.8049 - val_loss: 0.4941 - val_accuracy: 0.7464\n",
      "Epoch 663/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4200 - accuracy: 0.8052 - val_loss: 0.4942 - val_accuracy: 0.7469\n",
      "Epoch 664/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4200 - accuracy: 0.8055 - val_loss: 0.4943 - val_accuracy: 0.7464\n",
      "Epoch 665/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4200 - accuracy: 0.8053 - val_loss: 0.4946 - val_accuracy: 0.7479\n",
      "Epoch 666/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4199 - accuracy: 0.8055 - val_loss: 0.4946 - val_accuracy: 0.7479\n",
      "Epoch 667/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4199 - accuracy: 0.8048 - val_loss: 0.4942 - val_accuracy: 0.7469\n",
      "Epoch 668/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4199 - accuracy: 0.8059 - val_loss: 0.4942 - val_accuracy: 0.7474\n",
      "Epoch 669/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4198 - accuracy: 0.8052 - val_loss: 0.4943 - val_accuracy: 0.7464\n",
      "Epoch 670/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4198 - accuracy: 0.8056 - val_loss: 0.4941 - val_accuracy: 0.7474\n",
      "Epoch 671/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4198 - accuracy: 0.8053 - val_loss: 0.4939 - val_accuracy: 0.7469\n",
      "Epoch 672/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4197 - accuracy: 0.8055 - val_loss: 0.4941 - val_accuracy: 0.7469\n",
      "Epoch 673/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4197 - accuracy: 0.8058 - val_loss: 0.4944 - val_accuracy: 0.7479\n",
      "Epoch 674/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4197 - accuracy: 0.8055 - val_loss: 0.4943 - val_accuracy: 0.7469\n",
      "Epoch 675/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4196 - accuracy: 0.8060 - val_loss: 0.4941 - val_accuracy: 0.7469\n",
      "Epoch 676/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4196 - accuracy: 0.8049 - val_loss: 0.4940 - val_accuracy: 0.7474\n",
      "Epoch 677/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4196 - accuracy: 0.8053 - val_loss: 0.4942 - val_accuracy: 0.7474\n",
      "Epoch 678/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4195 - accuracy: 0.8058 - val_loss: 0.4941 - val_accuracy: 0.7479\n",
      "Epoch 679/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4195 - accuracy: 0.8046 - val_loss: 0.4942 - val_accuracy: 0.7474\n",
      "Epoch 680/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4194 - accuracy: 0.8055 - val_loss: 0.4943 - val_accuracy: 0.7479\n",
      "Epoch 681/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4194 - accuracy: 0.8058 - val_loss: 0.4942 - val_accuracy: 0.7479\n",
      "Epoch 682/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4194 - accuracy: 0.8058 - val_loss: 0.4940 - val_accuracy: 0.7479\n",
      "Epoch 683/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4193 - accuracy: 0.8055 - val_loss: 0.4940 - val_accuracy: 0.7479\n",
      "Epoch 684/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4193 - accuracy: 0.8063 - val_loss: 0.4940 - val_accuracy: 0.7464\n",
      "Epoch 685/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4193 - accuracy: 0.8059 - val_loss: 0.4938 - val_accuracy: 0.7464\n",
      "Epoch 686/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4192 - accuracy: 0.8062 - val_loss: 0.4939 - val_accuracy: 0.7464\n",
      "Epoch 687/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4192 - accuracy: 0.8048 - val_loss: 0.4941 - val_accuracy: 0.7474\n",
      "Epoch 688/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4192 - accuracy: 0.8059 - val_loss: 0.4945 - val_accuracy: 0.7479\n",
      "Epoch 689/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4191 - accuracy: 0.8058 - val_loss: 0.4940 - val_accuracy: 0.7464\n",
      "Epoch 690/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4191 - accuracy: 0.8055 - val_loss: 0.4941 - val_accuracy: 0.7479\n",
      "Epoch 691/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4191 - accuracy: 0.8056 - val_loss: 0.4941 - val_accuracy: 0.7479\n",
      "Epoch 692/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4190 - accuracy: 0.8059 - val_loss: 0.4938 - val_accuracy: 0.7479\n",
      "Epoch 693/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4190 - accuracy: 0.8060 - val_loss: 0.4939 - val_accuracy: 0.7474\n",
      "Epoch 694/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4190 - accuracy: 0.8055 - val_loss: 0.4938 - val_accuracy: 0.7479\n",
      "Epoch 695/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4189 - accuracy: 0.8059 - val_loss: 0.4938 - val_accuracy: 0.7488\n",
      "Epoch 696/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4189 - accuracy: 0.8052 - val_loss: 0.4940 - val_accuracy: 0.7483\n",
      "Epoch 697/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4189 - accuracy: 0.8060 - val_loss: 0.4941 - val_accuracy: 0.7483\n",
      "Epoch 698/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4188 - accuracy: 0.8059 - val_loss: 0.4940 - val_accuracy: 0.7479\n",
      "Epoch 699/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4188 - accuracy: 0.8056 - val_loss: 0.4940 - val_accuracy: 0.7479\n",
      "Epoch 700/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4187 - accuracy: 0.8052 - val_loss: 0.4944 - val_accuracy: 0.7483\n",
      "Epoch 701/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4187 - accuracy: 0.8053 - val_loss: 0.4946 - val_accuracy: 0.7469\n",
      "Epoch 702/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4187 - accuracy: 0.8063 - val_loss: 0.4940 - val_accuracy: 0.7483\n",
      "Epoch 703/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4186 - accuracy: 0.8058 - val_loss: 0.4939 - val_accuracy: 0.7479\n",
      "Epoch 704/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4186 - accuracy: 0.8053 - val_loss: 0.4938 - val_accuracy: 0.7483\n",
      "Epoch 705/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4186 - accuracy: 0.8052 - val_loss: 0.4941 - val_accuracy: 0.7483\n",
      "Epoch 706/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4186 - accuracy: 0.8056 - val_loss: 0.4941 - val_accuracy: 0.7483\n",
      "Epoch 707/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4185 - accuracy: 0.8060 - val_loss: 0.4943 - val_accuracy: 0.7483\n",
      "Epoch 708/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4185 - accuracy: 0.8056 - val_loss: 0.4940 - val_accuracy: 0.7479\n",
      "Epoch 709/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4184 - accuracy: 0.8055 - val_loss: 0.4939 - val_accuracy: 0.7479\n",
      "Epoch 710/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4184 - accuracy: 0.8059 - val_loss: 0.4937 - val_accuracy: 0.7474\n",
      "Epoch 711/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4184 - accuracy: 0.8058 - val_loss: 0.4937 - val_accuracy: 0.7469\n",
      "Epoch 712/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4183 - accuracy: 0.8055 - val_loss: 0.4934 - val_accuracy: 0.7479\n",
      "Epoch 713/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4183 - accuracy: 0.8056 - val_loss: 0.4939 - val_accuracy: 0.7474\n",
      "Epoch 714/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4183 - accuracy: 0.8059 - val_loss: 0.4940 - val_accuracy: 0.7474\n",
      "Epoch 715/1000\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.4182 - accuracy: 0.8059 - val_loss: 0.4941 - val_accuracy: 0.7469\n",
      "Epoch 716/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4182 - accuracy: 0.8052 - val_loss: 0.4939 - val_accuracy: 0.7483\n",
      "Epoch 717/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4182 - accuracy: 0.8060 - val_loss: 0.4936 - val_accuracy: 0.7488\n",
      "Epoch 718/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8055 - val_loss: 0.4937 - val_accuracy: 0.7488\n",
      "Epoch 719/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8060 - val_loss: 0.4940 - val_accuracy: 0.7483\n",
      "Epoch 720/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8055 - val_loss: 0.4937 - val_accuracy: 0.7488\n",
      "Epoch 721/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8060 - val_loss: 0.4940 - val_accuracy: 0.7479\n",
      "Epoch 722/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4180 - accuracy: 0.8053 - val_loss: 0.4940 - val_accuracy: 0.7474\n",
      "Epoch 723/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4180 - accuracy: 0.8058 - val_loss: 0.4939 - val_accuracy: 0.7469\n",
      "Epoch 724/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4179 - accuracy: 0.8058 - val_loss: 0.4935 - val_accuracy: 0.7488\n",
      "Epoch 725/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4179 - accuracy: 0.8058 - val_loss: 0.4938 - val_accuracy: 0.7488\n",
      "Epoch 726/1000\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.4179 - accuracy: 0.8055 - val_loss: 0.4941 - val_accuracy: 0.7469\n",
      "Epoch 727/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4178 - accuracy: 0.8069 - val_loss: 0.4941 - val_accuracy: 0.7479\n",
      "Epoch 728/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4178 - accuracy: 0.8059 - val_loss: 0.4942 - val_accuracy: 0.7483\n",
      "Epoch 729/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4177 - accuracy: 0.8066 - val_loss: 0.4943 - val_accuracy: 0.7483\n",
      "Epoch 730/1000\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.4177 - accuracy: 0.8060 - val_loss: 0.4943 - val_accuracy: 0.7479\n",
      "Epoch 731/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4177 - accuracy: 0.8058 - val_loss: 0.4942 - val_accuracy: 0.7483\n",
      "Epoch 732/1000\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.4176 - accuracy: 0.8063 - val_loss: 0.4939 - val_accuracy: 0.7469\n",
      "Epoch 733/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4176 - accuracy: 0.8059 - val_loss: 0.4937 - val_accuracy: 0.7474\n",
      "Epoch 734/1000\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.4176 - accuracy: 0.8059 - val_loss: 0.4936 - val_accuracy: 0.7493\n",
      "Epoch 735/1000\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.4175 - accuracy: 0.8058 - val_loss: 0.4938 - val_accuracy: 0.7483\n",
      "Epoch 736/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4175 - accuracy: 0.8066 - val_loss: 0.4937 - val_accuracy: 0.7488\n",
      "Epoch 737/1000\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8060 - val_loss: 0.4936 - val_accuracy: 0.7488\n",
      "Epoch 738/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4174 - accuracy: 0.8055 - val_loss: 0.4938 - val_accuracy: 0.7493\n",
      "Epoch 739/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4174 - accuracy: 0.8059 - val_loss: 0.4938 - val_accuracy: 0.7488\n",
      "Epoch 740/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4174 - accuracy: 0.8056 - val_loss: 0.4940 - val_accuracy: 0.7488\n",
      "Epoch 741/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4173 - accuracy: 0.8052 - val_loss: 0.4942 - val_accuracy: 0.7483\n",
      "Epoch 742/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4173 - accuracy: 0.8062 - val_loss: 0.4943 - val_accuracy: 0.7483\n",
      "Epoch 743/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4173 - accuracy: 0.8055 - val_loss: 0.4940 - val_accuracy: 0.7483\n",
      "Epoch 744/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4172 - accuracy: 0.8053 - val_loss: 0.4940 - val_accuracy: 0.7474\n",
      "Epoch 745/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4172 - accuracy: 0.8058 - val_loss: 0.4941 - val_accuracy: 0.7479\n",
      "Epoch 746/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4172 - accuracy: 0.8056 - val_loss: 0.4939 - val_accuracy: 0.7479\n",
      "Epoch 747/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4171 - accuracy: 0.8055 - val_loss: 0.4935 - val_accuracy: 0.7479\n",
      "Epoch 748/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4171 - accuracy: 0.8060 - val_loss: 0.4936 - val_accuracy: 0.7474\n",
      "Epoch 749/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4171 - accuracy: 0.8060 - val_loss: 0.4937 - val_accuracy: 0.7479\n",
      "Epoch 750/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4170 - accuracy: 0.8062 - val_loss: 0.4937 - val_accuracy: 0.7483\n",
      "Epoch 751/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4170 - accuracy: 0.8055 - val_loss: 0.4939 - val_accuracy: 0.7483\n",
      "Epoch 752/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4170 - accuracy: 0.8052 - val_loss: 0.4941 - val_accuracy: 0.7488\n",
      "Epoch 753/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4169 - accuracy: 0.8056 - val_loss: 0.4940 - val_accuracy: 0.7479\n",
      "Epoch 754/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4169 - accuracy: 0.8059 - val_loss: 0.4939 - val_accuracy: 0.7479\n",
      "Epoch 755/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4169 - accuracy: 0.8070 - val_loss: 0.4938 - val_accuracy: 0.7474\n",
      "Epoch 756/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4168 - accuracy: 0.8058 - val_loss: 0.4939 - val_accuracy: 0.7483\n",
      "Epoch 757/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4168 - accuracy: 0.8051 - val_loss: 0.4939 - val_accuracy: 0.7483\n",
      "Epoch 758/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4168 - accuracy: 0.8064 - val_loss: 0.4939 - val_accuracy: 0.7474\n",
      "Epoch 759/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4167 - accuracy: 0.8066 - val_loss: 0.4936 - val_accuracy: 0.7483\n",
      "Epoch 760/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4167 - accuracy: 0.8063 - val_loss: 0.4935 - val_accuracy: 0.7488\n",
      "Epoch 761/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4167 - accuracy: 0.8055 - val_loss: 0.4936 - val_accuracy: 0.7483\n",
      "Epoch 762/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4166 - accuracy: 0.8056 - val_loss: 0.4936 - val_accuracy: 0.7479\n",
      "Epoch 763/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4166 - accuracy: 0.8055 - val_loss: 0.4937 - val_accuracy: 0.7483\n",
      "Epoch 764/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4166 - accuracy: 0.8060 - val_loss: 0.4936 - val_accuracy: 0.7483\n",
      "Epoch 765/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4165 - accuracy: 0.8063 - val_loss: 0.4937 - val_accuracy: 0.7483\n",
      "Epoch 766/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4165 - accuracy: 0.8056 - val_loss: 0.4937 - val_accuracy: 0.7483\n",
      "Epoch 767/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4165 - accuracy: 0.8055 - val_loss: 0.4939 - val_accuracy: 0.7488\n",
      "Epoch 768/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4164 - accuracy: 0.8052 - val_loss: 0.4940 - val_accuracy: 0.7479\n",
      "Epoch 769/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4164 - accuracy: 0.8058 - val_loss: 0.4938 - val_accuracy: 0.7479\n",
      "Epoch 770/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4164 - accuracy: 0.8052 - val_loss: 0.4938 - val_accuracy: 0.7483\n",
      "Epoch 771/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4163 - accuracy: 0.8063 - val_loss: 0.4937 - val_accuracy: 0.7479\n",
      "Epoch 772/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4163 - accuracy: 0.8060 - val_loss: 0.4938 - val_accuracy: 0.7483\n",
      "Epoch 773/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4163 - accuracy: 0.8062 - val_loss: 0.4937 - val_accuracy: 0.7479\n",
      "Epoch 774/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4162 - accuracy: 0.8063 - val_loss: 0.4937 - val_accuracy: 0.7483\n",
      "Epoch 775/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4162 - accuracy: 0.8053 - val_loss: 0.4936 - val_accuracy: 0.7479\n",
      "Epoch 776/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4162 - accuracy: 0.8060 - val_loss: 0.4938 - val_accuracy: 0.7483\n",
      "Epoch 777/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4161 - accuracy: 0.8062 - val_loss: 0.4938 - val_accuracy: 0.7483\n",
      "Epoch 778/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4161 - accuracy: 0.8063 - val_loss: 0.4937 - val_accuracy: 0.7483\n",
      "Epoch 779/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4161 - accuracy: 0.8062 - val_loss: 0.4934 - val_accuracy: 0.7493\n",
      "Epoch 780/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4160 - accuracy: 0.8055 - val_loss: 0.4934 - val_accuracy: 0.7493\n",
      "Epoch 781/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4160 - accuracy: 0.8062 - val_loss: 0.4933 - val_accuracy: 0.7493\n",
      "Epoch 782/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4160 - accuracy: 0.8063 - val_loss: 0.4936 - val_accuracy: 0.7488\n",
      "Epoch 783/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4159 - accuracy: 0.8064 - val_loss: 0.4937 - val_accuracy: 0.7488\n",
      "Epoch 784/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4159 - accuracy: 0.8059 - val_loss: 0.4939 - val_accuracy: 0.7479\n",
      "Epoch 785/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4159 - accuracy: 0.8060 - val_loss: 0.4936 - val_accuracy: 0.7493\n",
      "Epoch 786/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4158 - accuracy: 0.8060 - val_loss: 0.4936 - val_accuracy: 0.7488\n",
      "Epoch 787/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4158 - accuracy: 0.8056 - val_loss: 0.4940 - val_accuracy: 0.7488\n",
      "Epoch 788/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4158 - accuracy: 0.8060 - val_loss: 0.4940 - val_accuracy: 0.7488\n",
      "Epoch 789/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4157 - accuracy: 0.8062 - val_loss: 0.4940 - val_accuracy: 0.7469\n",
      "Epoch 790/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4157 - accuracy: 0.8063 - val_loss: 0.4938 - val_accuracy: 0.7493\n",
      "Epoch 791/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4157 - accuracy: 0.8064 - val_loss: 0.4939 - val_accuracy: 0.7488\n",
      "Epoch 792/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4156 - accuracy: 0.8066 - val_loss: 0.4940 - val_accuracy: 0.7488\n",
      "Epoch 793/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4156 - accuracy: 0.8060 - val_loss: 0.4939 - val_accuracy: 0.7488\n",
      "Epoch 794/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4156 - accuracy: 0.8067 - val_loss: 0.4939 - val_accuracy: 0.7488\n",
      "Epoch 795/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4155 - accuracy: 0.8062 - val_loss: 0.4941 - val_accuracy: 0.7488\n",
      "Epoch 796/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4155 - accuracy: 0.8066 - val_loss: 0.4939 - val_accuracy: 0.7488\n",
      "Epoch 797/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4155 - accuracy: 0.8064 - val_loss: 0.4937 - val_accuracy: 0.7479\n",
      "Epoch 798/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4154 - accuracy: 0.8069 - val_loss: 0.4936 - val_accuracy: 0.7493\n",
      "Epoch 799/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4154 - accuracy: 0.8064 - val_loss: 0.4935 - val_accuracy: 0.7498\n",
      "Epoch 800/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4154 - accuracy: 0.8064 - val_loss: 0.4933 - val_accuracy: 0.7498\n",
      "Epoch 801/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4153 - accuracy: 0.8066 - val_loss: 0.4933 - val_accuracy: 0.7498\n",
      "Epoch 802/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4153 - accuracy: 0.8062 - val_loss: 0.4936 - val_accuracy: 0.7493\n",
      "Epoch 803/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4153 - accuracy: 0.8069 - val_loss: 0.4938 - val_accuracy: 0.7493\n",
      "Epoch 804/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4152 - accuracy: 0.8064 - val_loss: 0.4936 - val_accuracy: 0.7493\n",
      "Epoch 805/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4152 - accuracy: 0.8058 - val_loss: 0.4935 - val_accuracy: 0.7498\n",
      "Epoch 806/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4152 - accuracy: 0.8070 - val_loss: 0.4932 - val_accuracy: 0.7502\n",
      "Epoch 807/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4151 - accuracy: 0.8069 - val_loss: 0.4929 - val_accuracy: 0.7507\n",
      "Epoch 808/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4151 - accuracy: 0.8067 - val_loss: 0.4929 - val_accuracy: 0.7498\n",
      "Epoch 809/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4150 - accuracy: 0.8062 - val_loss: 0.4929 - val_accuracy: 0.7493\n",
      "Epoch 810/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4150 - accuracy: 0.8066 - val_loss: 0.4933 - val_accuracy: 0.7502\n",
      "Epoch 811/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4150 - accuracy: 0.8073 - val_loss: 0.4936 - val_accuracy: 0.7493\n",
      "Epoch 812/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4150 - accuracy: 0.8062 - val_loss: 0.4933 - val_accuracy: 0.7498\n",
      "Epoch 813/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4149 - accuracy: 0.8067 - val_loss: 0.4934 - val_accuracy: 0.7493\n",
      "Epoch 814/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4149 - accuracy: 0.8062 - val_loss: 0.4934 - val_accuracy: 0.7502\n",
      "Epoch 815/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4149 - accuracy: 0.8066 - val_loss: 0.4933 - val_accuracy: 0.7502\n",
      "Epoch 816/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4148 - accuracy: 0.8066 - val_loss: 0.4936 - val_accuracy: 0.7498\n",
      "Epoch 817/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4148 - accuracy: 0.8064 - val_loss: 0.4935 - val_accuracy: 0.7498\n",
      "Epoch 818/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4148 - accuracy: 0.8066 - val_loss: 0.4938 - val_accuracy: 0.7493\n",
      "Epoch 819/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4147 - accuracy: 0.8066 - val_loss: 0.4937 - val_accuracy: 0.7498\n",
      "Epoch 820/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4147 - accuracy: 0.8070 - val_loss: 0.4937 - val_accuracy: 0.7498\n",
      "Epoch 821/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4147 - accuracy: 0.8071 - val_loss: 0.4936 - val_accuracy: 0.7498\n",
      "Epoch 822/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4146 - accuracy: 0.8069 - val_loss: 0.4938 - val_accuracy: 0.7498\n",
      "Epoch 823/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4146 - accuracy: 0.8067 - val_loss: 0.4936 - val_accuracy: 0.7502\n",
      "Epoch 824/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4146 - accuracy: 0.8073 - val_loss: 0.4934 - val_accuracy: 0.7502\n",
      "Epoch 825/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4146 - accuracy: 0.8069 - val_loss: 0.4934 - val_accuracy: 0.7502\n",
      "Epoch 826/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4145 - accuracy: 0.8076 - val_loss: 0.4936 - val_accuracy: 0.7498\n",
      "Epoch 827/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4145 - accuracy: 0.8073 - val_loss: 0.4935 - val_accuracy: 0.7498\n",
      "Epoch 828/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4144 - accuracy: 0.8063 - val_loss: 0.4938 - val_accuracy: 0.7493\n",
      "Epoch 829/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4144 - accuracy: 0.8067 - val_loss: 0.4936 - val_accuracy: 0.7502\n",
      "Epoch 830/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4144 - accuracy: 0.8071 - val_loss: 0.4936 - val_accuracy: 0.7498\n",
      "Epoch 831/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4144 - accuracy: 0.8067 - val_loss: 0.4936 - val_accuracy: 0.7507\n",
      "Epoch 832/1000\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.4143 - accuracy: 0.8058 - val_loss: 0.4932 - val_accuracy: 0.7507\n",
      "Epoch 833/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4143 - accuracy: 0.8080 - val_loss: 0.4933 - val_accuracy: 0.7507\n",
      "Epoch 834/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4142 - accuracy: 0.8064 - val_loss: 0.4931 - val_accuracy: 0.7507\n",
      "Epoch 835/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4142 - accuracy: 0.8069 - val_loss: 0.4932 - val_accuracy: 0.7507\n",
      "Epoch 836/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4142 - accuracy: 0.8067 - val_loss: 0.4932 - val_accuracy: 0.7507\n",
      "Epoch 837/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4142 - accuracy: 0.8071 - val_loss: 0.4932 - val_accuracy: 0.7507\n",
      "Epoch 838/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4141 - accuracy: 0.8074 - val_loss: 0.4932 - val_accuracy: 0.7512\n",
      "Epoch 839/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4141 - accuracy: 0.8078 - val_loss: 0.4937 - val_accuracy: 0.7502\n",
      "Epoch 840/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4141 - accuracy: 0.8069 - val_loss: 0.4935 - val_accuracy: 0.7507\n",
      "Epoch 841/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4140 - accuracy: 0.8071 - val_loss: 0.4938 - val_accuracy: 0.7512\n",
      "Epoch 842/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4140 - accuracy: 0.8073 - val_loss: 0.4939 - val_accuracy: 0.7502\n",
      "Epoch 843/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4140 - accuracy: 0.8066 - val_loss: 0.4938 - val_accuracy: 0.7512\n",
      "Epoch 844/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4139 - accuracy: 0.8063 - val_loss: 0.4937 - val_accuracy: 0.7512\n",
      "Epoch 845/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4139 - accuracy: 0.8070 - val_loss: 0.4936 - val_accuracy: 0.7517\n",
      "Epoch 846/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4139 - accuracy: 0.8070 - val_loss: 0.4935 - val_accuracy: 0.7512\n",
      "Epoch 847/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4138 - accuracy: 0.8076 - val_loss: 0.4938 - val_accuracy: 0.7517\n",
      "Epoch 848/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4138 - accuracy: 0.8074 - val_loss: 0.4937 - val_accuracy: 0.7512\n",
      "Epoch 849/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4138 - accuracy: 0.8074 - val_loss: 0.4936 - val_accuracy: 0.7502\n",
      "Epoch 850/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4137 - accuracy: 0.8070 - val_loss: 0.4939 - val_accuracy: 0.7507\n",
      "Epoch 851/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4137 - accuracy: 0.8071 - val_loss: 0.4939 - val_accuracy: 0.7507\n",
      "Epoch 852/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4137 - accuracy: 0.8066 - val_loss: 0.4937 - val_accuracy: 0.7502\n",
      "Epoch 853/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4136 - accuracy: 0.8066 - val_loss: 0.4936 - val_accuracy: 0.7512\n",
      "Epoch 854/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4136 - accuracy: 0.8073 - val_loss: 0.4934 - val_accuracy: 0.7512\n",
      "Epoch 855/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4136 - accuracy: 0.8081 - val_loss: 0.4935 - val_accuracy: 0.7512\n",
      "Epoch 856/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4135 - accuracy: 0.8076 - val_loss: 0.4935 - val_accuracy: 0.7517\n",
      "Epoch 857/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4135 - accuracy: 0.8067 - val_loss: 0.4934 - val_accuracy: 0.7512\n",
      "Epoch 858/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4135 - accuracy: 0.8076 - val_loss: 0.4931 - val_accuracy: 0.7521\n",
      "Epoch 859/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4134 - accuracy: 0.8074 - val_loss: 0.4934 - val_accuracy: 0.7507\n",
      "Epoch 860/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4134 - accuracy: 0.8071 - val_loss: 0.4935 - val_accuracy: 0.7512\n",
      "Epoch 861/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4134 - accuracy: 0.8064 - val_loss: 0.4934 - val_accuracy: 0.7517\n",
      "Epoch 862/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4134 - accuracy: 0.8070 - val_loss: 0.4934 - val_accuracy: 0.7517\n",
      "Epoch 863/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4133 - accuracy: 0.8074 - val_loss: 0.4933 - val_accuracy: 0.7517\n",
      "Epoch 864/1000\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.4133 - accuracy: 0.8076 - val_loss: 0.4932 - val_accuracy: 0.7517\n",
      "Epoch 865/1000\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4132 - accuracy: 0.8078 - val_loss: 0.4936 - val_accuracy: 0.7517\n",
      "Epoch 866/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4132 - accuracy: 0.8074 - val_loss: 0.4934 - val_accuracy: 0.7517\n",
      "Epoch 867/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4132 - accuracy: 0.8087 - val_loss: 0.4937 - val_accuracy: 0.7507\n",
      "Epoch 868/1000\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.4132 - accuracy: 0.8069 - val_loss: 0.4937 - val_accuracy: 0.7507\n",
      "Epoch 869/1000\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.4131 - accuracy: 0.8066 - val_loss: 0.4932 - val_accuracy: 0.7517\n",
      "Epoch 870/1000\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.4131 - accuracy: 0.8074 - val_loss: 0.4933 - val_accuracy: 0.7517\n",
      "Epoch 871/1000\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.4131 - accuracy: 0.8074 - val_loss: 0.4933 - val_accuracy: 0.7521\n",
      "Epoch 872/1000\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.4130 - accuracy: 0.8084 - val_loss: 0.4934 - val_accuracy: 0.7512\n",
      "Epoch 873/1000\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.4130 - accuracy: 0.8081 - val_loss: 0.4931 - val_accuracy: 0.7531\n",
      "Epoch 874/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4130 - accuracy: 0.8076 - val_loss: 0.4933 - val_accuracy: 0.7512\n",
      "Epoch 875/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4129 - accuracy: 0.8081 - val_loss: 0.4934 - val_accuracy: 0.7517\n",
      "Epoch 876/1000\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4129 - accuracy: 0.8078 - val_loss: 0.4935 - val_accuracy: 0.7507\n",
      "Epoch 877/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4129 - accuracy: 0.8074 - val_loss: 0.4937 - val_accuracy: 0.7512\n",
      "Epoch 878/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4128 - accuracy: 0.8076 - val_loss: 0.4940 - val_accuracy: 0.7507\n",
      "Epoch 879/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4128 - accuracy: 0.8070 - val_loss: 0.4939 - val_accuracy: 0.7507\n",
      "Epoch 880/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4128 - accuracy: 0.8073 - val_loss: 0.4938 - val_accuracy: 0.7517\n",
      "Epoch 881/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4127 - accuracy: 0.8074 - val_loss: 0.4936 - val_accuracy: 0.7512\n",
      "Epoch 882/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4127 - accuracy: 0.8071 - val_loss: 0.4935 - val_accuracy: 0.7517\n",
      "Epoch 883/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4127 - accuracy: 0.8076 - val_loss: 0.4933 - val_accuracy: 0.7517\n",
      "Epoch 884/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4126 - accuracy: 0.8080 - val_loss: 0.4930 - val_accuracy: 0.7512\n",
      "Epoch 885/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4126 - accuracy: 0.8076 - val_loss: 0.4930 - val_accuracy: 0.7517\n",
      "Epoch 886/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4126 - accuracy: 0.8082 - val_loss: 0.4935 - val_accuracy: 0.7512\n",
      "Epoch 887/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4126 - accuracy: 0.8077 - val_loss: 0.4933 - val_accuracy: 0.7512\n",
      "Epoch 888/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4125 - accuracy: 0.8078 - val_loss: 0.4933 - val_accuracy: 0.7517\n",
      "Epoch 889/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4125 - accuracy: 0.8084 - val_loss: 0.4933 - val_accuracy: 0.7517\n",
      "Epoch 890/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4125 - accuracy: 0.8074 - val_loss: 0.4934 - val_accuracy: 0.7517\n",
      "Epoch 891/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4124 - accuracy: 0.8077 - val_loss: 0.4934 - val_accuracy: 0.7517\n",
      "Epoch 892/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4124 - accuracy: 0.8078 - val_loss: 0.4930 - val_accuracy: 0.7521\n",
      "Epoch 893/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4124 - accuracy: 0.8076 - val_loss: 0.4930 - val_accuracy: 0.7521\n",
      "Epoch 894/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4123 - accuracy: 0.8080 - val_loss: 0.4934 - val_accuracy: 0.7521\n",
      "Epoch 895/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4123 - accuracy: 0.8084 - val_loss: 0.4933 - val_accuracy: 0.7517\n",
      "Epoch 896/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4123 - accuracy: 0.8076 - val_loss: 0.4935 - val_accuracy: 0.7517\n",
      "Epoch 897/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4122 - accuracy: 0.8081 - val_loss: 0.4935 - val_accuracy: 0.7526\n",
      "Epoch 898/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4122 - accuracy: 0.8074 - val_loss: 0.4935 - val_accuracy: 0.7512\n",
      "Epoch 899/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4122 - accuracy: 0.8073 - val_loss: 0.4934 - val_accuracy: 0.7521\n",
      "Epoch 900/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4122 - accuracy: 0.8081 - val_loss: 0.4934 - val_accuracy: 0.7517\n",
      "Epoch 901/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4121 - accuracy: 0.8081 - val_loss: 0.4930 - val_accuracy: 0.7521\n",
      "Epoch 902/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4121 - accuracy: 0.8077 - val_loss: 0.4933 - val_accuracy: 0.7517\n",
      "Epoch 903/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4120 - accuracy: 0.8078 - val_loss: 0.4932 - val_accuracy: 0.7521\n",
      "Epoch 904/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4120 - accuracy: 0.8076 - val_loss: 0.4937 - val_accuracy: 0.7517\n",
      "Epoch 905/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4120 - accuracy: 0.8084 - val_loss: 0.4937 - val_accuracy: 0.7517\n",
      "Epoch 906/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4120 - accuracy: 0.8080 - val_loss: 0.4936 - val_accuracy: 0.7517\n",
      "Epoch 907/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4119 - accuracy: 0.8080 - val_loss: 0.4937 - val_accuracy: 0.7517\n",
      "Epoch 908/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4119 - accuracy: 0.8085 - val_loss: 0.4939 - val_accuracy: 0.7512\n",
      "Epoch 909/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4119 - accuracy: 0.8076 - val_loss: 0.4938 - val_accuracy: 0.7512\n",
      "Epoch 910/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4118 - accuracy: 0.8084 - val_loss: 0.4937 - val_accuracy: 0.7517\n",
      "Epoch 911/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4118 - accuracy: 0.8082 - val_loss: 0.4934 - val_accuracy: 0.7521\n",
      "Epoch 912/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4118 - accuracy: 0.8087 - val_loss: 0.4934 - val_accuracy: 0.7526\n",
      "Epoch 913/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4117 - accuracy: 0.8089 - val_loss: 0.4933 - val_accuracy: 0.7526\n",
      "Epoch 914/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4117 - accuracy: 0.8080 - val_loss: 0.4934 - val_accuracy: 0.7526\n",
      "Epoch 915/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4117 - accuracy: 0.8074 - val_loss: 0.4937 - val_accuracy: 0.7512\n",
      "Epoch 916/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4116 - accuracy: 0.8081 - val_loss: 0.4936 - val_accuracy: 0.7521\n",
      "Epoch 917/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4116 - accuracy: 0.8089 - val_loss: 0.4935 - val_accuracy: 0.7517\n",
      "Epoch 918/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4116 - accuracy: 0.8088 - val_loss: 0.4932 - val_accuracy: 0.7526\n",
      "Epoch 919/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4116 - accuracy: 0.8082 - val_loss: 0.4936 - val_accuracy: 0.7517\n",
      "Epoch 920/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4115 - accuracy: 0.8087 - val_loss: 0.4934 - val_accuracy: 0.7526\n",
      "Epoch 921/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4115 - accuracy: 0.8091 - val_loss: 0.4934 - val_accuracy: 0.7526\n",
      "Epoch 922/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4115 - accuracy: 0.8091 - val_loss: 0.4931 - val_accuracy: 0.7531\n",
      "Epoch 923/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4114 - accuracy: 0.8084 - val_loss: 0.4932 - val_accuracy: 0.7517\n",
      "Epoch 924/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4114 - accuracy: 0.8087 - val_loss: 0.4932 - val_accuracy: 0.7517\n",
      "Epoch 925/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4114 - accuracy: 0.8080 - val_loss: 0.4935 - val_accuracy: 0.7521\n",
      "Epoch 926/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4113 - accuracy: 0.8088 - val_loss: 0.4936 - val_accuracy: 0.7521\n",
      "Epoch 927/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4113 - accuracy: 0.8080 - val_loss: 0.4935 - val_accuracy: 0.7526\n",
      "Epoch 928/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4113 - accuracy: 0.8084 - val_loss: 0.4932 - val_accuracy: 0.7526\n",
      "Epoch 929/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4113 - accuracy: 0.8081 - val_loss: 0.4935 - val_accuracy: 0.7531\n",
      "Epoch 930/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4112 - accuracy: 0.8088 - val_loss: 0.4938 - val_accuracy: 0.7531\n",
      "Epoch 931/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4112 - accuracy: 0.8087 - val_loss: 0.4934 - val_accuracy: 0.7531\n",
      "Epoch 932/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4111 - accuracy: 0.8089 - val_loss: 0.4933 - val_accuracy: 0.7531\n",
      "Epoch 933/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4111 - accuracy: 0.8085 - val_loss: 0.4936 - val_accuracy: 0.7517\n",
      "Epoch 934/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4111 - accuracy: 0.8088 - val_loss: 0.4934 - val_accuracy: 0.7521\n",
      "Epoch 935/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8081 - val_loss: 0.4937 - val_accuracy: 0.7526\n",
      "Epoch 936/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8082 - val_loss: 0.4938 - val_accuracy: 0.7531\n",
      "Epoch 937/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8087 - val_loss: 0.4938 - val_accuracy: 0.7531\n",
      "Epoch 938/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4110 - accuracy: 0.8087 - val_loss: 0.4940 - val_accuracy: 0.7521\n",
      "Epoch 939/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8091 - val_loss: 0.4934 - val_accuracy: 0.7526\n",
      "Epoch 940/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4109 - accuracy: 0.8088 - val_loss: 0.4932 - val_accuracy: 0.7521\n",
      "Epoch 941/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4109 - accuracy: 0.8089 - val_loss: 0.4936 - val_accuracy: 0.7517\n",
      "Epoch 942/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4108 - accuracy: 0.8089 - val_loss: 0.4937 - val_accuracy: 0.7517\n",
      "Epoch 943/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4108 - accuracy: 0.8087 - val_loss: 0.4938 - val_accuracy: 0.7526\n",
      "Epoch 944/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4108 - accuracy: 0.8091 - val_loss: 0.4930 - val_accuracy: 0.7526\n",
      "Epoch 945/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4107 - accuracy: 0.8082 - val_loss: 0.4932 - val_accuracy: 0.7526\n",
      "Epoch 946/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4107 - accuracy: 0.8094 - val_loss: 0.4930 - val_accuracy: 0.7526\n",
      "Epoch 947/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4107 - accuracy: 0.8089 - val_loss: 0.4929 - val_accuracy: 0.7526\n",
      "Epoch 948/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8088 - val_loss: 0.4932 - val_accuracy: 0.7531\n",
      "Epoch 949/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4106 - accuracy: 0.8091 - val_loss: 0.4932 - val_accuracy: 0.7521\n",
      "Epoch 950/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4106 - accuracy: 0.8085 - val_loss: 0.4935 - val_accuracy: 0.7526\n",
      "Epoch 951/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4106 - accuracy: 0.8098 - val_loss: 0.4931 - val_accuracy: 0.7521\n",
      "Epoch 952/1000\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4105 - accuracy: 0.8091 - val_loss: 0.4933 - val_accuracy: 0.7526\n",
      "Epoch 953/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4105 - accuracy: 0.8094 - val_loss: 0.4934 - val_accuracy: 0.7521\n",
      "Epoch 954/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4105 - accuracy: 0.8087 - val_loss: 0.4935 - val_accuracy: 0.7521\n",
      "Epoch 955/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4104 - accuracy: 0.8082 - val_loss: 0.4933 - val_accuracy: 0.7531\n",
      "Epoch 956/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8091 - val_loss: 0.4934 - val_accuracy: 0.7521\n",
      "Epoch 957/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4104 - accuracy: 0.8091 - val_loss: 0.4932 - val_accuracy: 0.7517\n",
      "Epoch 958/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4103 - accuracy: 0.8087 - val_loss: 0.4935 - val_accuracy: 0.7517\n",
      "Epoch 959/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4103 - accuracy: 0.8089 - val_loss: 0.4938 - val_accuracy: 0.7521\n",
      "Epoch 960/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4103 - accuracy: 0.8094 - val_loss: 0.4936 - val_accuracy: 0.7521\n",
      "Epoch 961/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4102 - accuracy: 0.8085 - val_loss: 0.4936 - val_accuracy: 0.7517\n",
      "Epoch 962/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8100 - val_loss: 0.4930 - val_accuracy: 0.7521\n",
      "Epoch 963/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4102 - accuracy: 0.8099 - val_loss: 0.4932 - val_accuracy: 0.7521\n",
      "Epoch 964/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8094 - val_loss: 0.4932 - val_accuracy: 0.7526\n",
      "Epoch 965/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8092 - val_loss: 0.4930 - val_accuracy: 0.7521\n",
      "Epoch 966/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8089 - val_loss: 0.4931 - val_accuracy: 0.7517\n",
      "Epoch 967/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4101 - accuracy: 0.8091 - val_loss: 0.4932 - val_accuracy: 0.7512\n",
      "Epoch 968/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4100 - accuracy: 0.8092 - val_loss: 0.4934 - val_accuracy: 0.7521\n",
      "Epoch 969/1000\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4100 - accuracy: 0.8091 - val_loss: 0.4938 - val_accuracy: 0.7521\n",
      "Epoch 970/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4100 - accuracy: 0.8094 - val_loss: 0.4937 - val_accuracy: 0.7512\n",
      "Epoch 971/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4099 - accuracy: 0.8106 - val_loss: 0.4937 - val_accuracy: 0.7512\n",
      "Epoch 972/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8094 - val_loss: 0.4937 - val_accuracy: 0.7517\n",
      "Epoch 973/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8098 - val_loss: 0.4936 - val_accuracy: 0.7512\n",
      "Epoch 974/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4099 - accuracy: 0.8098 - val_loss: 0.4934 - val_accuracy: 0.7521\n",
      "Epoch 975/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8091 - val_loss: 0.4936 - val_accuracy: 0.7512\n",
      "Epoch 976/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8096 - val_loss: 0.4931 - val_accuracy: 0.7517\n",
      "Epoch 977/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8092 - val_loss: 0.4936 - val_accuracy: 0.7512\n",
      "Epoch 978/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8098 - val_loss: 0.4935 - val_accuracy: 0.7521\n",
      "Epoch 979/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8096 - val_loss: 0.4933 - val_accuracy: 0.7517\n",
      "Epoch 980/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8092 - val_loss: 0.4936 - val_accuracy: 0.7517\n",
      "Epoch 981/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8094 - val_loss: 0.4933 - val_accuracy: 0.7512\n",
      "Epoch 982/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8091 - val_loss: 0.4932 - val_accuracy: 0.7512\n",
      "Epoch 983/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8096 - val_loss: 0.4935 - val_accuracy: 0.7517\n",
      "Epoch 984/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8094 - val_loss: 0.4933 - val_accuracy: 0.7507\n",
      "Epoch 985/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8091 - val_loss: 0.4933 - val_accuracy: 0.7507\n",
      "Epoch 986/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8094 - val_loss: 0.4933 - val_accuracy: 0.7507\n",
      "Epoch 987/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8096 - val_loss: 0.4940 - val_accuracy: 0.7512\n",
      "Epoch 988/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8098 - val_loss: 0.4941 - val_accuracy: 0.7517\n",
      "Epoch 989/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8098 - val_loss: 0.4939 - val_accuracy: 0.7507\n",
      "Epoch 990/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8096 - val_loss: 0.4937 - val_accuracy: 0.7507\n",
      "Epoch 991/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8095 - val_loss: 0.4935 - val_accuracy: 0.7507\n",
      "Epoch 992/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8105 - val_loss: 0.4933 - val_accuracy: 0.7507\n",
      "Epoch 993/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8098 - val_loss: 0.4937 - val_accuracy: 0.7507\n",
      "Epoch 994/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8091 - val_loss: 0.4937 - val_accuracy: 0.7512\n",
      "Epoch 995/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4092 - accuracy: 0.8091 - val_loss: 0.4936 - val_accuracy: 0.7507\n",
      "Epoch 996/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4092 - accuracy: 0.8100 - val_loss: 0.4938 - val_accuracy: 0.7507\n",
      "Epoch 997/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4092 - accuracy: 0.8099 - val_loss: 0.4938 - val_accuracy: 0.7512\n",
      "Epoch 998/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8092 - val_loss: 0.4936 - val_accuracy: 0.7507\n",
      "Epoch 999/1000\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4091 - accuracy: 0.8098 - val_loss: 0.4931 - val_accuracy: 0.7507\n",
      "Epoch 1000/1000\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8094 - val_loss: 0.4931 - val_accuracy: 0.7507\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34cc57ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 1ms/step\n",
      "66/66 [==============================] - 0s 1ms/step\n",
      "\n",
      "accuracy is 0.751\n",
      "roc-auc is 0.830\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class_nn_1 = (model_1.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
    "\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dfa065ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20ae277e8b0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f2cb0",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss is NOT going down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa35f74b",
   "metadata": {},
   "source": [
    "## Build 2 Hidden Layers Neural Network\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb772a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.7525 - accuracy: 0.5361 - val_loss: 0.7175 - val_accuracy: 0.5834\n",
      "Epoch 2/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.6393 - val_loss: 0.6184 - val_accuracy: 0.6507\n",
      "Epoch 3/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.6862 - val_loss: 0.5728 - val_accuracy: 0.6739\n",
      "Epoch 4/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7165 - val_loss: 0.5499 - val_accuracy: 0.6820\n",
      "Epoch 5/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7351 - val_loss: 0.5376 - val_accuracy: 0.6872\n",
      "Epoch 6/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7476 - val_loss: 0.5305 - val_accuracy: 0.6905\n",
      "Epoch 7/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7543 - val_loss: 0.5271 - val_accuracy: 0.6934\n",
      "Epoch 8/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7582 - val_loss: 0.5243 - val_accuracy: 0.6986\n",
      "Epoch 9/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7618 - val_loss: 0.5235 - val_accuracy: 0.6991\n",
      "Epoch 10/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7644 - val_loss: 0.5232 - val_accuracy: 0.7028\n",
      "Epoch 11/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7672 - val_loss: 0.5225 - val_accuracy: 0.7038\n",
      "Epoch 12/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7694 - val_loss: 0.5208 - val_accuracy: 0.7076\n",
      "Epoch 13/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4800 - accuracy: 0.7719 - val_loss: 0.5196 - val_accuracy: 0.7118\n",
      "Epoch 14/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4770 - accuracy: 0.7726 - val_loss: 0.5187 - val_accuracy: 0.7147\n",
      "Epoch 15/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4744 - accuracy: 0.7742 - val_loss: 0.5171 - val_accuracy: 0.7204\n",
      "Epoch 16/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7755 - val_loss: 0.5174 - val_accuracy: 0.7213\n",
      "Epoch 17/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4700 - accuracy: 0.7759 - val_loss: 0.5162 - val_accuracy: 0.7237\n",
      "Epoch 18/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7768 - val_loss: 0.5144 - val_accuracy: 0.7251\n",
      "Epoch 19/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7773 - val_loss: 0.5151 - val_accuracy: 0.7261\n",
      "Epoch 20/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4648 - accuracy: 0.7784 - val_loss: 0.5143 - val_accuracy: 0.7270\n",
      "Epoch 21/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4633 - accuracy: 0.7796 - val_loss: 0.5142 - val_accuracy: 0.7275\n",
      "Epoch 22/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7802 - val_loss: 0.5137 - val_accuracy: 0.7284\n",
      "Epoch 23/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4606 - accuracy: 0.7809 - val_loss: 0.5126 - val_accuracy: 0.7294\n",
      "Epoch 24/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4593 - accuracy: 0.7811 - val_loss: 0.5135 - val_accuracy: 0.7308\n",
      "Epoch 25/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4582 - accuracy: 0.7818 - val_loss: 0.5125 - val_accuracy: 0.7313\n",
      "Epoch 26/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4571 - accuracy: 0.7821 - val_loss: 0.5119 - val_accuracy: 0.7299\n",
      "Epoch 27/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4560 - accuracy: 0.7835 - val_loss: 0.5120 - val_accuracy: 0.7313\n",
      "Epoch 28/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4550 - accuracy: 0.7843 - val_loss: 0.5115 - val_accuracy: 0.7322\n",
      "Epoch 29/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4541 - accuracy: 0.7862 - val_loss: 0.5108 - val_accuracy: 0.7351\n",
      "Epoch 30/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7861 - val_loss: 0.5106 - val_accuracy: 0.7351\n",
      "Epoch 31/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4523 - accuracy: 0.7874 - val_loss: 0.5104 - val_accuracy: 0.7365\n",
      "Epoch 32/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7878 - val_loss: 0.5098 - val_accuracy: 0.7379\n",
      "Epoch 33/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4506 - accuracy: 0.7886 - val_loss: 0.5090 - val_accuracy: 0.7379\n",
      "Epoch 34/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4498 - accuracy: 0.7887 - val_loss: 0.5089 - val_accuracy: 0.7398\n",
      "Epoch 35/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4491 - accuracy: 0.7893 - val_loss: 0.5084 - val_accuracy: 0.7403\n",
      "Epoch 36/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4483 - accuracy: 0.7905 - val_loss: 0.5083 - val_accuracy: 0.7412\n",
      "Epoch 37/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4476 - accuracy: 0.7905 - val_loss: 0.5083 - val_accuracy: 0.7412\n",
      "Epoch 38/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4469 - accuracy: 0.7912 - val_loss: 0.5084 - val_accuracy: 0.7408\n",
      "Epoch 39/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4463 - accuracy: 0.7914 - val_loss: 0.5088 - val_accuracy: 0.7408\n",
      "Epoch 40/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4457 - accuracy: 0.7923 - val_loss: 0.5085 - val_accuracy: 0.7417\n",
      "Epoch 41/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4450 - accuracy: 0.7923 - val_loss: 0.5094 - val_accuracy: 0.7408\n",
      "Epoch 42/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4445 - accuracy: 0.7929 - val_loss: 0.5086 - val_accuracy: 0.7422\n",
      "Epoch 43/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4439 - accuracy: 0.7941 - val_loss: 0.5092 - val_accuracy: 0.7422\n",
      "Epoch 44/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4434 - accuracy: 0.7944 - val_loss: 0.5091 - val_accuracy: 0.7412\n",
      "Epoch 45/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7950 - val_loss: 0.5091 - val_accuracy: 0.7412\n",
      "Epoch 46/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4424 - accuracy: 0.7952 - val_loss: 0.5079 - val_accuracy: 0.7412\n",
      "Epoch 47/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7958 - val_loss: 0.5078 - val_accuracy: 0.7417\n",
      "Epoch 48/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4416 - accuracy: 0.7957 - val_loss: 0.5081 - val_accuracy: 0.7422\n",
      "Epoch 49/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7961 - val_loss: 0.5071 - val_accuracy: 0.7412\n",
      "Epoch 50/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4408 - accuracy: 0.7979 - val_loss: 0.5076 - val_accuracy: 0.7427\n",
      "Epoch 51/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7981 - val_loss: 0.5075 - val_accuracy: 0.7422\n",
      "Epoch 52/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7977 - val_loss: 0.5072 - val_accuracy: 0.7408\n",
      "Epoch 53/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7993 - val_loss: 0.5083 - val_accuracy: 0.7417\n",
      "Epoch 54/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4394 - accuracy: 0.7995 - val_loss: 0.5078 - val_accuracy: 0.7431\n",
      "Epoch 55/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4391 - accuracy: 0.8008 - val_loss: 0.5065 - val_accuracy: 0.7427\n",
      "Epoch 56/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4388 - accuracy: 0.8004 - val_loss: 0.5067 - val_accuracy: 0.7431\n",
      "Epoch 57/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4384 - accuracy: 0.8008 - val_loss: 0.5079 - val_accuracy: 0.7427\n",
      "Epoch 58/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4381 - accuracy: 0.8011 - val_loss: 0.5076 - val_accuracy: 0.7427\n",
      "Epoch 59/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4378 - accuracy: 0.8001 - val_loss: 0.5062 - val_accuracy: 0.7431\n",
      "Epoch 60/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4375 - accuracy: 0.8024 - val_loss: 0.5070 - val_accuracy: 0.7450\n",
      "Epoch 61/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4372 - accuracy: 0.8024 - val_loss: 0.5076 - val_accuracy: 0.7445\n",
      "Epoch 62/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4369 - accuracy: 0.8023 - val_loss: 0.5069 - val_accuracy: 0.7445\n",
      "Epoch 63/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4367 - accuracy: 0.8033 - val_loss: 0.5075 - val_accuracy: 0.7455\n",
      "Epoch 64/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4364 - accuracy: 0.8023 - val_loss: 0.5077 - val_accuracy: 0.7455\n",
      "Epoch 65/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4362 - accuracy: 0.8030 - val_loss: 0.5083 - val_accuracy: 0.7450\n",
      "Epoch 66/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4359 - accuracy: 0.8029 - val_loss: 0.5082 - val_accuracy: 0.7445\n",
      "Epoch 67/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4356 - accuracy: 0.8017 - val_loss: 0.5069 - val_accuracy: 0.7455\n",
      "Epoch 68/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4354 - accuracy: 0.8030 - val_loss: 0.5067 - val_accuracy: 0.7450\n",
      "Epoch 69/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4352 - accuracy: 0.8030 - val_loss: 0.5070 - val_accuracy: 0.7445\n",
      "Epoch 70/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4350 - accuracy: 0.8031 - val_loss: 0.5071 - val_accuracy: 0.7450\n",
      "Epoch 71/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4347 - accuracy: 0.8026 - val_loss: 0.5065 - val_accuracy: 0.7450\n",
      "Epoch 72/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4345 - accuracy: 0.8042 - val_loss: 0.5072 - val_accuracy: 0.7455\n",
      "Epoch 73/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4343 - accuracy: 0.8026 - val_loss: 0.5069 - val_accuracy: 0.7460\n",
      "Epoch 74/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4341 - accuracy: 0.8035 - val_loss: 0.5062 - val_accuracy: 0.7455\n",
      "Epoch 75/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4339 - accuracy: 0.8033 - val_loss: 0.5068 - val_accuracy: 0.7455\n",
      "Epoch 76/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4337 - accuracy: 0.8037 - val_loss: 0.5063 - val_accuracy: 0.7450\n",
      "Epoch 77/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4335 - accuracy: 0.8040 - val_loss: 0.5059 - val_accuracy: 0.7450\n",
      "Epoch 78/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4333 - accuracy: 0.8042 - val_loss: 0.5064 - val_accuracy: 0.7441\n",
      "Epoch 79/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4332 - accuracy: 0.8040 - val_loss: 0.5073 - val_accuracy: 0.7436\n",
      "Epoch 80/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4330 - accuracy: 0.8048 - val_loss: 0.5072 - val_accuracy: 0.7445\n",
      "Epoch 81/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4328 - accuracy: 0.8045 - val_loss: 0.5075 - val_accuracy: 0.7455\n",
      "Epoch 82/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4326 - accuracy: 0.8042 - val_loss: 0.5063 - val_accuracy: 0.7455\n",
      "Epoch 83/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4325 - accuracy: 0.8049 - val_loss: 0.5053 - val_accuracy: 0.7445\n",
      "Epoch 84/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4323 - accuracy: 0.8051 - val_loss: 0.5062 - val_accuracy: 0.7450\n",
      "Epoch 85/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4321 - accuracy: 0.8052 - val_loss: 0.5065 - val_accuracy: 0.7441\n",
      "Epoch 86/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4320 - accuracy: 0.8048 - val_loss: 0.5066 - val_accuracy: 0.7441\n",
      "Epoch 87/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4318 - accuracy: 0.8052 - val_loss: 0.5067 - val_accuracy: 0.7445\n",
      "Epoch 88/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4317 - accuracy: 0.8049 - val_loss: 0.5066 - val_accuracy: 0.7450\n",
      "Epoch 89/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4315 - accuracy: 0.8038 - val_loss: 0.5073 - val_accuracy: 0.7450\n",
      "Epoch 90/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4313 - accuracy: 0.8044 - val_loss: 0.5075 - val_accuracy: 0.7441\n",
      "Epoch 91/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4312 - accuracy: 0.8048 - val_loss: 0.5075 - val_accuracy: 0.7445\n",
      "Epoch 92/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4311 - accuracy: 0.8035 - val_loss: 0.5077 - val_accuracy: 0.7441\n",
      "Epoch 93/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4309 - accuracy: 0.8040 - val_loss: 0.5067 - val_accuracy: 0.7445\n",
      "Epoch 94/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4308 - accuracy: 0.8046 - val_loss: 0.5073 - val_accuracy: 0.7445\n",
      "Epoch 95/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4306 - accuracy: 0.8046 - val_loss: 0.5060 - val_accuracy: 0.7445\n",
      "Epoch 96/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4305 - accuracy: 0.8037 - val_loss: 0.5057 - val_accuracy: 0.7445\n",
      "Epoch 97/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4303 - accuracy: 0.8033 - val_loss: 0.5062 - val_accuracy: 0.7441\n",
      "Epoch 98/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4301 - accuracy: 0.8040 - val_loss: 0.5046 - val_accuracy: 0.7450\n",
      "Epoch 99/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4301 - accuracy: 0.8040 - val_loss: 0.5049 - val_accuracy: 0.7441\n",
      "Epoch 100/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4300 - accuracy: 0.8034 - val_loss: 0.5060 - val_accuracy: 0.7441\n",
      "Epoch 101/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4299 - accuracy: 0.8038 - val_loss: 0.5065 - val_accuracy: 0.7441\n",
      "Epoch 102/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4297 - accuracy: 0.8041 - val_loss: 0.5066 - val_accuracy: 0.7436\n",
      "Epoch 103/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4296 - accuracy: 0.8042 - val_loss: 0.5071 - val_accuracy: 0.7436\n",
      "Epoch 104/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4295 - accuracy: 0.8046 - val_loss: 0.5062 - val_accuracy: 0.7431\n",
      "Epoch 105/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4294 - accuracy: 0.8040 - val_loss: 0.5054 - val_accuracy: 0.7436\n",
      "Epoch 106/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4292 - accuracy: 0.8046 - val_loss: 0.5052 - val_accuracy: 0.7441\n",
      "Epoch 107/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4291 - accuracy: 0.8041 - val_loss: 0.5056 - val_accuracy: 0.7431\n",
      "Epoch 108/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4290 - accuracy: 0.8046 - val_loss: 0.5062 - val_accuracy: 0.7436\n",
      "Epoch 109/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4289 - accuracy: 0.8053 - val_loss: 0.5068 - val_accuracy: 0.7436\n",
      "Epoch 110/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4288 - accuracy: 0.8055 - val_loss: 0.5065 - val_accuracy: 0.7431\n",
      "Epoch 111/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4287 - accuracy: 0.8048 - val_loss: 0.5057 - val_accuracy: 0.7422\n",
      "Epoch 112/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4285 - accuracy: 0.8053 - val_loss: 0.5057 - val_accuracy: 0.7422\n",
      "Epoch 113/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4285 - accuracy: 0.8063 - val_loss: 0.5057 - val_accuracy: 0.7422\n",
      "Epoch 114/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4283 - accuracy: 0.8056 - val_loss: 0.5066 - val_accuracy: 0.7417\n",
      "Epoch 115/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4282 - accuracy: 0.8059 - val_loss: 0.5059 - val_accuracy: 0.7422\n",
      "Epoch 116/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4281 - accuracy: 0.8056 - val_loss: 0.5063 - val_accuracy: 0.7422\n",
      "Epoch 117/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4280 - accuracy: 0.8066 - val_loss: 0.5061 - val_accuracy: 0.7431\n",
      "Epoch 118/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4279 - accuracy: 0.8064 - val_loss: 0.5061 - val_accuracy: 0.7427\n",
      "Epoch 119/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4278 - accuracy: 0.8058 - val_loss: 0.5060 - val_accuracy: 0.7427\n",
      "Epoch 120/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4277 - accuracy: 0.8064 - val_loss: 0.5070 - val_accuracy: 0.7431\n",
      "Epoch 121/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4276 - accuracy: 0.8060 - val_loss: 0.5064 - val_accuracy: 0.7436\n",
      "Epoch 122/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4275 - accuracy: 0.8062 - val_loss: 0.5064 - val_accuracy: 0.7427\n",
      "Epoch 123/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4273 - accuracy: 0.8069 - val_loss: 0.5056 - val_accuracy: 0.7436\n",
      "Epoch 124/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4272 - accuracy: 0.8056 - val_loss: 0.5053 - val_accuracy: 0.7436\n",
      "Epoch 125/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4271 - accuracy: 0.8063 - val_loss: 0.5059 - val_accuracy: 0.7441\n",
      "Epoch 126/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4270 - accuracy: 0.8063 - val_loss: 0.5067 - val_accuracy: 0.7422\n",
      "Epoch 127/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4269 - accuracy: 0.8058 - val_loss: 0.5062 - val_accuracy: 0.7431\n",
      "Epoch 128/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4268 - accuracy: 0.8059 - val_loss: 0.5056 - val_accuracy: 0.7422\n",
      "Epoch 129/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4267 - accuracy: 0.8062 - val_loss: 0.5055 - val_accuracy: 0.7422\n",
      "Epoch 130/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4266 - accuracy: 0.8064 - val_loss: 0.5069 - val_accuracy: 0.7412\n",
      "Epoch 131/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4265 - accuracy: 0.8060 - val_loss: 0.5068 - val_accuracy: 0.7408\n",
      "Epoch 132/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4264 - accuracy: 0.8069 - val_loss: 0.5053 - val_accuracy: 0.7412\n",
      "Epoch 133/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4263 - accuracy: 0.8062 - val_loss: 0.5047 - val_accuracy: 0.7427\n",
      "Epoch 134/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4262 - accuracy: 0.8066 - val_loss: 0.5053 - val_accuracy: 0.7422\n",
      "Epoch 135/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4261 - accuracy: 0.8064 - val_loss: 0.5051 - val_accuracy: 0.7403\n",
      "Epoch 136/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4260 - accuracy: 0.8058 - val_loss: 0.5064 - val_accuracy: 0.7422\n",
      "Epoch 137/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4259 - accuracy: 0.8071 - val_loss: 0.5051 - val_accuracy: 0.7412\n",
      "Epoch 138/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4258 - accuracy: 0.8071 - val_loss: 0.5038 - val_accuracy: 0.7408\n",
      "Epoch 139/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4257 - accuracy: 0.8069 - val_loss: 0.5045 - val_accuracy: 0.7408\n",
      "Epoch 140/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4256 - accuracy: 0.8069 - val_loss: 0.5043 - val_accuracy: 0.7412\n",
      "Epoch 141/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4255 - accuracy: 0.8067 - val_loss: 0.5039 - val_accuracy: 0.7412\n",
      "Epoch 142/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4254 - accuracy: 0.8063 - val_loss: 0.5050 - val_accuracy: 0.7417\n",
      "Epoch 143/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4254 - accuracy: 0.8077 - val_loss: 0.5054 - val_accuracy: 0.7412\n",
      "Epoch 144/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4252 - accuracy: 0.8074 - val_loss: 0.5039 - val_accuracy: 0.7427\n",
      "Epoch 145/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4252 - accuracy: 0.8071 - val_loss: 0.5048 - val_accuracy: 0.7422\n",
      "Epoch 146/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4250 - accuracy: 0.8070 - val_loss: 0.5050 - val_accuracy: 0.7417\n",
      "Epoch 147/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4249 - accuracy: 0.8073 - val_loss: 0.5040 - val_accuracy: 0.7422\n",
      "Epoch 148/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4249 - accuracy: 0.8078 - val_loss: 0.5046 - val_accuracy: 0.7417\n",
      "Epoch 149/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4247 - accuracy: 0.8070 - val_loss: 0.5051 - val_accuracy: 0.7422\n",
      "Epoch 150/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4247 - accuracy: 0.8078 - val_loss: 0.5053 - val_accuracy: 0.7427\n",
      "Epoch 151/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4246 - accuracy: 0.8077 - val_loss: 0.5056 - val_accuracy: 0.7431\n",
      "Epoch 152/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4245 - accuracy: 0.8089 - val_loss: 0.5058 - val_accuracy: 0.7427\n",
      "Epoch 153/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4244 - accuracy: 0.8084 - val_loss: 0.5062 - val_accuracy: 0.7427\n",
      "Epoch 154/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4243 - accuracy: 0.8084 - val_loss: 0.5063 - val_accuracy: 0.7417\n",
      "Epoch 155/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4242 - accuracy: 0.8088 - val_loss: 0.5057 - val_accuracy: 0.7422\n",
      "Epoch 156/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4241 - accuracy: 0.8078 - val_loss: 0.5055 - val_accuracy: 0.7427\n",
      "Epoch 157/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4240 - accuracy: 0.8087 - val_loss: 0.5054 - val_accuracy: 0.7431\n",
      "Epoch 158/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4238 - accuracy: 0.8095 - val_loss: 0.5063 - val_accuracy: 0.7422\n",
      "Epoch 159/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4238 - accuracy: 0.8080 - val_loss: 0.5061 - val_accuracy: 0.7422\n",
      "Epoch 160/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4237 - accuracy: 0.8082 - val_loss: 0.5060 - val_accuracy: 0.7417\n",
      "Epoch 161/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4235 - accuracy: 0.8084 - val_loss: 0.5058 - val_accuracy: 0.7422\n",
      "Epoch 162/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4235 - accuracy: 0.8085 - val_loss: 0.5053 - val_accuracy: 0.7427\n",
      "Epoch 163/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4233 - accuracy: 0.8076 - val_loss: 0.5048 - val_accuracy: 0.7431\n",
      "Epoch 164/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4232 - accuracy: 0.8081 - val_loss: 0.5063 - val_accuracy: 0.7408\n",
      "Epoch 165/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4232 - accuracy: 0.8085 - val_loss: 0.5050 - val_accuracy: 0.7431\n",
      "Epoch 166/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4231 - accuracy: 0.8085 - val_loss: 0.5054 - val_accuracy: 0.7427\n",
      "Epoch 167/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4230 - accuracy: 0.8089 - val_loss: 0.5051 - val_accuracy: 0.7431\n",
      "Epoch 168/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4229 - accuracy: 0.8098 - val_loss: 0.5051 - val_accuracy: 0.7436\n",
      "Epoch 169/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4228 - accuracy: 0.8076 - val_loss: 0.5047 - val_accuracy: 0.7417\n",
      "Epoch 170/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4227 - accuracy: 0.8099 - val_loss: 0.5055 - val_accuracy: 0.7417\n",
      "Epoch 171/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4226 - accuracy: 0.8099 - val_loss: 0.5063 - val_accuracy: 0.7427\n",
      "Epoch 172/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4225 - accuracy: 0.8084 - val_loss: 0.5054 - val_accuracy: 0.7422\n",
      "Epoch 173/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4224 - accuracy: 0.8098 - val_loss: 0.5065 - val_accuracy: 0.7412\n",
      "Epoch 174/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4223 - accuracy: 0.8080 - val_loss: 0.5052 - val_accuracy: 0.7417\n",
      "Epoch 175/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4222 - accuracy: 0.8099 - val_loss: 0.5058 - val_accuracy: 0.7412\n",
      "Epoch 176/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4221 - accuracy: 0.8096 - val_loss: 0.5053 - val_accuracy: 0.7408\n",
      "Epoch 177/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4220 - accuracy: 0.8098 - val_loss: 0.5065 - val_accuracy: 0.7412\n",
      "Epoch 178/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4219 - accuracy: 0.8096 - val_loss: 0.5071 - val_accuracy: 0.7422\n",
      "Epoch 179/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4218 - accuracy: 0.8087 - val_loss: 0.5063 - val_accuracy: 0.7422\n",
      "Epoch 180/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4217 - accuracy: 0.8078 - val_loss: 0.5055 - val_accuracy: 0.7417\n",
      "Epoch 181/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8092 - val_loss: 0.5064 - val_accuracy: 0.7412\n",
      "Epoch 182/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8088 - val_loss: 0.5062 - val_accuracy: 0.7417\n",
      "Epoch 183/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8094 - val_loss: 0.5060 - val_accuracy: 0.7417\n",
      "Epoch 184/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8088 - val_loss: 0.5050 - val_accuracy: 0.7403\n",
      "Epoch 185/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4213 - accuracy: 0.8096 - val_loss: 0.5048 - val_accuracy: 0.7403\n",
      "Epoch 186/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4211 - accuracy: 0.8091 - val_loss: 0.5069 - val_accuracy: 0.7422\n",
      "Epoch 187/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4210 - accuracy: 0.8084 - val_loss: 0.5045 - val_accuracy: 0.7403\n",
      "Epoch 188/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4209 - accuracy: 0.8089 - val_loss: 0.5054 - val_accuracy: 0.7417\n",
      "Epoch 189/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4208 - accuracy: 0.8092 - val_loss: 0.5055 - val_accuracy: 0.7417\n",
      "Epoch 190/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4207 - accuracy: 0.8099 - val_loss: 0.5071 - val_accuracy: 0.7408\n",
      "Epoch 191/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4205 - accuracy: 0.8105 - val_loss: 0.5076 - val_accuracy: 0.7427\n",
      "Epoch 192/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4205 - accuracy: 0.8091 - val_loss: 0.5061 - val_accuracy: 0.7417\n",
      "Epoch 193/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4205 - accuracy: 0.8094 - val_loss: 0.5067 - val_accuracy: 0.7417\n",
      "Epoch 194/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4203 - accuracy: 0.8105 - val_loss: 0.5054 - val_accuracy: 0.7417\n",
      "Epoch 195/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4202 - accuracy: 0.8096 - val_loss: 0.5064 - val_accuracy: 0.7403\n",
      "Epoch 196/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4201 - accuracy: 0.8107 - val_loss: 0.5068 - val_accuracy: 0.7408\n",
      "Epoch 197/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4200 - accuracy: 0.8103 - val_loss: 0.5061 - val_accuracy: 0.7403\n",
      "Epoch 198/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4199 - accuracy: 0.8100 - val_loss: 0.5050 - val_accuracy: 0.7431\n",
      "Epoch 199/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4198 - accuracy: 0.8100 - val_loss: 0.5061 - val_accuracy: 0.7403\n",
      "Epoch 200/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8099 - val_loss: 0.5047 - val_accuracy: 0.7412\n",
      "Epoch 201/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8102 - val_loss: 0.5059 - val_accuracy: 0.7412\n",
      "Epoch 202/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8094 - val_loss: 0.5056 - val_accuracy: 0.7412\n",
      "Epoch 203/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4194 - accuracy: 0.8103 - val_loss: 0.5058 - val_accuracy: 0.7403\n",
      "Epoch 204/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8105 - val_loss: 0.5051 - val_accuracy: 0.7422\n",
      "Epoch 205/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4191 - accuracy: 0.8112 - val_loss: 0.5057 - val_accuracy: 0.7422\n",
      "Epoch 206/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8098 - val_loss: 0.5041 - val_accuracy: 0.7436\n",
      "Epoch 207/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8100 - val_loss: 0.5050 - val_accuracy: 0.7427\n",
      "Epoch 208/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8103 - val_loss: 0.5060 - val_accuracy: 0.7427\n",
      "Epoch 209/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4187 - accuracy: 0.8105 - val_loss: 0.5053 - val_accuracy: 0.7412\n",
      "Epoch 210/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8099 - val_loss: 0.5059 - val_accuracy: 0.7431\n",
      "Epoch 211/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8105 - val_loss: 0.5039 - val_accuracy: 0.7431\n",
      "Epoch 212/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8106 - val_loss: 0.5050 - val_accuracy: 0.7417\n",
      "Epoch 213/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8106 - val_loss: 0.5054 - val_accuracy: 0.7431\n",
      "Epoch 214/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8112 - val_loss: 0.5041 - val_accuracy: 0.7441\n",
      "Epoch 215/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8109 - val_loss: 0.5018 - val_accuracy: 0.7431\n",
      "Epoch 216/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8110 - val_loss: 0.5042 - val_accuracy: 0.7431\n",
      "Epoch 217/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8112 - val_loss: 0.5061 - val_accuracy: 0.7431\n",
      "Epoch 218/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4178 - accuracy: 0.8106 - val_loss: 0.5068 - val_accuracy: 0.7427\n",
      "Epoch 219/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8100 - val_loss: 0.5036 - val_accuracy: 0.7431\n",
      "Epoch 220/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8102 - val_loss: 0.5048 - val_accuracy: 0.7431\n",
      "Epoch 221/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8116 - val_loss: 0.5061 - val_accuracy: 0.7431\n",
      "Epoch 222/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4174 - accuracy: 0.8118 - val_loss: 0.5046 - val_accuracy: 0.7431\n",
      "Epoch 223/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4173 - accuracy: 0.8099 - val_loss: 0.5049 - val_accuracy: 0.7436\n",
      "Epoch 224/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4172 - accuracy: 0.8107 - val_loss: 0.5057 - val_accuracy: 0.7441\n",
      "Epoch 225/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8105 - val_loss: 0.5048 - val_accuracy: 0.7441\n",
      "Epoch 226/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8109 - val_loss: 0.5044 - val_accuracy: 0.7445\n",
      "Epoch 227/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8109 - val_loss: 0.5056 - val_accuracy: 0.7445\n",
      "Epoch 228/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8127 - val_loss: 0.5064 - val_accuracy: 0.7436\n",
      "Epoch 229/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8098 - val_loss: 0.5066 - val_accuracy: 0.7455\n",
      "Epoch 230/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8112 - val_loss: 0.5046 - val_accuracy: 0.7441\n",
      "Epoch 231/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8110 - val_loss: 0.5057 - val_accuracy: 0.7436\n",
      "Epoch 232/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8116 - val_loss: 0.5052 - val_accuracy: 0.7445\n",
      "Epoch 233/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4164 - accuracy: 0.8109 - val_loss: 0.5073 - val_accuracy: 0.7450\n",
      "Epoch 234/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4164 - accuracy: 0.8110 - val_loss: 0.5048 - val_accuracy: 0.7445\n",
      "Epoch 235/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4163 - accuracy: 0.8113 - val_loss: 0.5057 - val_accuracy: 0.7469\n",
      "Epoch 236/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4162 - accuracy: 0.8107 - val_loss: 0.5041 - val_accuracy: 0.7455\n",
      "Epoch 237/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4161 - accuracy: 0.8113 - val_loss: 0.5055 - val_accuracy: 0.7455\n",
      "Epoch 238/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4159 - accuracy: 0.8113 - val_loss: 0.5033 - val_accuracy: 0.7436\n",
      "Epoch 239/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8123 - val_loss: 0.5054 - val_accuracy: 0.7455\n",
      "Epoch 240/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4158 - accuracy: 0.8117 - val_loss: 0.5077 - val_accuracy: 0.7441\n",
      "Epoch 241/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8110 - val_loss: 0.5066 - val_accuracy: 0.7450\n",
      "Epoch 242/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4156 - accuracy: 0.8118 - val_loss: 0.5063 - val_accuracy: 0.7436\n",
      "Epoch 243/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.8127 - val_loss: 0.5063 - val_accuracy: 0.7450\n",
      "Epoch 244/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4154 - accuracy: 0.8117 - val_loss: 0.5050 - val_accuracy: 0.7455\n",
      "Epoch 245/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8123 - val_loss: 0.5059 - val_accuracy: 0.7441\n",
      "Epoch 246/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8112 - val_loss: 0.5059 - val_accuracy: 0.7445\n",
      "Epoch 247/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8124 - val_loss: 0.5068 - val_accuracy: 0.7455\n",
      "Epoch 248/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8110 - val_loss: 0.5052 - val_accuracy: 0.7455\n",
      "Epoch 249/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8116 - val_loss: 0.5054 - val_accuracy: 0.7450\n",
      "Epoch 250/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8112 - val_loss: 0.5055 - val_accuracy: 0.7436\n",
      "Epoch 251/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.8117 - val_loss: 0.5053 - val_accuracy: 0.7455\n",
      "Epoch 252/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8117 - val_loss: 0.5058 - val_accuracy: 0.7450\n",
      "Epoch 253/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8121 - val_loss: 0.5059 - val_accuracy: 0.7450\n",
      "Epoch 254/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8121 - val_loss: 0.5062 - val_accuracy: 0.7464\n",
      "Epoch 255/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8114 - val_loss: 0.5063 - val_accuracy: 0.7474\n",
      "Epoch 256/1500\n",
      "226/226 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8121 - val_loss: 0.5051 - val_accuracy: 0.7469\n",
      "Epoch 257/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4143 - accuracy: 0.8112 - val_loss: 0.5063 - val_accuracy: 0.7469\n",
      "Epoch 258/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4142 - accuracy: 0.8113 - val_loss: 0.5042 - val_accuracy: 0.7479\n",
      "Epoch 259/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4141 - accuracy: 0.8139 - val_loss: 0.5074 - val_accuracy: 0.7474\n",
      "Epoch 260/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4140 - accuracy: 0.8120 - val_loss: 0.5063 - val_accuracy: 0.7460\n",
      "Epoch 261/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4140 - accuracy: 0.8117 - val_loss: 0.5060 - val_accuracy: 0.7469\n",
      "Epoch 262/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4139 - accuracy: 0.8129 - val_loss: 0.5044 - val_accuracy: 0.7488\n",
      "Epoch 263/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4138 - accuracy: 0.8128 - val_loss: 0.5061 - val_accuracy: 0.7464\n",
      "Epoch 264/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4137 - accuracy: 0.8123 - val_loss: 0.5050 - val_accuracy: 0.7474\n",
      "Epoch 265/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4136 - accuracy: 0.8124 - val_loss: 0.5032 - val_accuracy: 0.7479\n",
      "Epoch 266/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4136 - accuracy: 0.8125 - val_loss: 0.5046 - val_accuracy: 0.7483\n",
      "Epoch 267/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4135 - accuracy: 0.8123 - val_loss: 0.5064 - val_accuracy: 0.7464\n",
      "Epoch 268/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4134 - accuracy: 0.8131 - val_loss: 0.5064 - val_accuracy: 0.7469\n",
      "Epoch 269/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4134 - accuracy: 0.8135 - val_loss: 0.5056 - val_accuracy: 0.7483\n",
      "Epoch 270/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4132 - accuracy: 0.8127 - val_loss: 0.5050 - val_accuracy: 0.7474\n",
      "Epoch 271/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4131 - accuracy: 0.8109 - val_loss: 0.5053 - val_accuracy: 0.7455\n",
      "Epoch 272/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4130 - accuracy: 0.8129 - val_loss: 0.5067 - val_accuracy: 0.7483\n",
      "Epoch 273/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4130 - accuracy: 0.8113 - val_loss: 0.5052 - val_accuracy: 0.7488\n",
      "Epoch 274/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4129 - accuracy: 0.8123 - val_loss: 0.5078 - val_accuracy: 0.7460\n",
      "Epoch 275/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4128 - accuracy: 0.8114 - val_loss: 0.5077 - val_accuracy: 0.7460\n",
      "Epoch 276/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4128 - accuracy: 0.8128 - val_loss: 0.5054 - val_accuracy: 0.7455\n",
      "Epoch 277/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4127 - accuracy: 0.8120 - val_loss: 0.5052 - val_accuracy: 0.7469\n",
      "Epoch 278/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4126 - accuracy: 0.8136 - val_loss: 0.5069 - val_accuracy: 0.7488\n",
      "Epoch 279/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4125 - accuracy: 0.8123 - val_loss: 0.5037 - val_accuracy: 0.7488\n",
      "Epoch 280/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4125 - accuracy: 0.8135 - val_loss: 0.5055 - val_accuracy: 0.7483\n",
      "Epoch 281/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4124 - accuracy: 0.8118 - val_loss: 0.5052 - val_accuracy: 0.7488\n",
      "Epoch 282/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4122 - accuracy: 0.8132 - val_loss: 0.5043 - val_accuracy: 0.7460\n",
      "Epoch 283/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4121 - accuracy: 0.8131 - val_loss: 0.5047 - val_accuracy: 0.7464\n",
      "Epoch 284/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4120 - accuracy: 0.8142 - val_loss: 0.5064 - val_accuracy: 0.7479\n",
      "Epoch 285/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4120 - accuracy: 0.8125 - val_loss: 0.5043 - val_accuracy: 0.7483\n",
      "Epoch 286/1500\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.4118 - accuracy: 0.8135 - val_loss: 0.5035 - val_accuracy: 0.7469\n",
      "Epoch 287/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4118 - accuracy: 0.8123 - val_loss: 0.5049 - val_accuracy: 0.7498\n",
      "Epoch 288/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4117 - accuracy: 0.8123 - val_loss: 0.5048 - val_accuracy: 0.7464\n",
      "Epoch 289/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4116 - accuracy: 0.8125 - val_loss: 0.5055 - val_accuracy: 0.7502\n",
      "Epoch 290/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4114 - accuracy: 0.8135 - val_loss: 0.5062 - val_accuracy: 0.7464\n",
      "Epoch 291/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4114 - accuracy: 0.8127 - val_loss: 0.5039 - val_accuracy: 0.7479\n",
      "Epoch 292/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4113 - accuracy: 0.8127 - val_loss: 0.5047 - val_accuracy: 0.7464\n",
      "Epoch 293/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4112 - accuracy: 0.8129 - val_loss: 0.5069 - val_accuracy: 0.7436\n",
      "Epoch 294/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4112 - accuracy: 0.8134 - val_loss: 0.5054 - val_accuracy: 0.7464\n",
      "Epoch 295/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4110 - accuracy: 0.8131 - val_loss: 0.5043 - val_accuracy: 0.7488\n",
      "Epoch 296/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4110 - accuracy: 0.8129 - val_loss: 0.5054 - val_accuracy: 0.7469\n",
      "Epoch 297/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4109 - accuracy: 0.8129 - val_loss: 0.5049 - val_accuracy: 0.7445\n",
      "Epoch 298/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4108 - accuracy: 0.8123 - val_loss: 0.5051 - val_accuracy: 0.7483\n",
      "Epoch 299/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4107 - accuracy: 0.8123 - val_loss: 0.5045 - val_accuracy: 0.7464\n",
      "Epoch 300/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4105 - accuracy: 0.8136 - val_loss: 0.5039 - val_accuracy: 0.7488\n",
      "Epoch 301/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4104 - accuracy: 0.8125 - val_loss: 0.5073 - val_accuracy: 0.7450\n",
      "Epoch 302/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4104 - accuracy: 0.8131 - val_loss: 0.5043 - val_accuracy: 0.7469\n",
      "Epoch 303/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4102 - accuracy: 0.8135 - val_loss: 0.5040 - val_accuracy: 0.7479\n",
      "Epoch 304/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4102 - accuracy: 0.8125 - val_loss: 0.5041 - val_accuracy: 0.7469\n",
      "Epoch 305/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4100 - accuracy: 0.8118 - val_loss: 0.5069 - val_accuracy: 0.7422\n",
      "Epoch 306/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4100 - accuracy: 0.8125 - val_loss: 0.5053 - val_accuracy: 0.7483\n",
      "Epoch 307/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4099 - accuracy: 0.8134 - val_loss: 0.5047 - val_accuracy: 0.7479\n",
      "Epoch 308/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4099 - accuracy: 0.8134 - val_loss: 0.5046 - val_accuracy: 0.7474\n",
      "Epoch 309/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4097 - accuracy: 0.8147 - val_loss: 0.5041 - val_accuracy: 0.7483\n",
      "Epoch 310/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4096 - accuracy: 0.8136 - val_loss: 0.5059 - val_accuracy: 0.7469\n",
      "Epoch 311/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4095 - accuracy: 0.8129 - val_loss: 0.5085 - val_accuracy: 0.7455\n",
      "Epoch 312/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4095 - accuracy: 0.8132 - val_loss: 0.5062 - val_accuracy: 0.7474\n",
      "Epoch 313/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4093 - accuracy: 0.8136 - val_loss: 0.5054 - val_accuracy: 0.7460\n",
      "Epoch 314/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4093 - accuracy: 0.8135 - val_loss: 0.5053 - val_accuracy: 0.7464\n",
      "Epoch 315/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4092 - accuracy: 0.8143 - val_loss: 0.5030 - val_accuracy: 0.7483\n",
      "Epoch 316/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4091 - accuracy: 0.8145 - val_loss: 0.5045 - val_accuracy: 0.7469\n",
      "Epoch 317/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4090 - accuracy: 0.8134 - val_loss: 0.5051 - val_accuracy: 0.7464\n",
      "Epoch 318/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4089 - accuracy: 0.8132 - val_loss: 0.5043 - val_accuracy: 0.7455\n",
      "Epoch 319/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4089 - accuracy: 0.8142 - val_loss: 0.5049 - val_accuracy: 0.7469\n",
      "Epoch 320/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4087 - accuracy: 0.8136 - val_loss: 0.5041 - val_accuracy: 0.7483\n",
      "Epoch 321/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4087 - accuracy: 0.8128 - val_loss: 0.5040 - val_accuracy: 0.7483\n",
      "Epoch 322/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4085 - accuracy: 0.8147 - val_loss: 0.5055 - val_accuracy: 0.7474\n",
      "Epoch 323/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4084 - accuracy: 0.8136 - val_loss: 0.5048 - val_accuracy: 0.7474\n",
      "Epoch 324/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4083 - accuracy: 0.8134 - val_loss: 0.5020 - val_accuracy: 0.7498\n",
      "Epoch 325/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4083 - accuracy: 0.8142 - val_loss: 0.5035 - val_accuracy: 0.7498\n",
      "Epoch 326/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4081 - accuracy: 0.8145 - val_loss: 0.5047 - val_accuracy: 0.7493\n",
      "Epoch 327/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4080 - accuracy: 0.8139 - val_loss: 0.5046 - val_accuracy: 0.7483\n",
      "Epoch 328/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4080 - accuracy: 0.8149 - val_loss: 0.5026 - val_accuracy: 0.7483\n",
      "Epoch 329/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4078 - accuracy: 0.8154 - val_loss: 0.5046 - val_accuracy: 0.7493\n",
      "Epoch 330/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8131 - val_loss: 0.5045 - val_accuracy: 0.7498\n",
      "Epoch 331/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4076 - accuracy: 0.8152 - val_loss: 0.5049 - val_accuracy: 0.7498\n",
      "Epoch 332/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4076 - accuracy: 0.8132 - val_loss: 0.5046 - val_accuracy: 0.7474\n",
      "Epoch 333/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4074 - accuracy: 0.8145 - val_loss: 0.5041 - val_accuracy: 0.7469\n",
      "Epoch 334/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4073 - accuracy: 0.8153 - val_loss: 0.5048 - val_accuracy: 0.7460\n",
      "Epoch 335/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4072 - accuracy: 0.8152 - val_loss: 0.5063 - val_accuracy: 0.7474\n",
      "Epoch 336/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4071 - accuracy: 0.8157 - val_loss: 0.5050 - val_accuracy: 0.7488\n",
      "Epoch 337/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4070 - accuracy: 0.8156 - val_loss: 0.5028 - val_accuracy: 0.7498\n",
      "Epoch 338/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4069 - accuracy: 0.8157 - val_loss: 0.5030 - val_accuracy: 0.7493\n",
      "Epoch 339/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4068 - accuracy: 0.8163 - val_loss: 0.5051 - val_accuracy: 0.7488\n",
      "Epoch 340/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4066 - accuracy: 0.8156 - val_loss: 0.5034 - val_accuracy: 0.7493\n",
      "Epoch 341/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8167 - val_loss: 0.5014 - val_accuracy: 0.7512\n",
      "Epoch 342/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8152 - val_loss: 0.5029 - val_accuracy: 0.7507\n",
      "Epoch 343/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4064 - accuracy: 0.8159 - val_loss: 0.5032 - val_accuracy: 0.7488\n",
      "Epoch 344/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8159 - val_loss: 0.5027 - val_accuracy: 0.7498\n",
      "Epoch 345/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4061 - accuracy: 0.8153 - val_loss: 0.5043 - val_accuracy: 0.7493\n",
      "Epoch 346/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4061 - accuracy: 0.8160 - val_loss: 0.5052 - val_accuracy: 0.7479\n",
      "Epoch 347/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4058 - accuracy: 0.8164 - val_loss: 0.5040 - val_accuracy: 0.7502\n",
      "Epoch 348/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4058 - accuracy: 0.8170 - val_loss: 0.5044 - val_accuracy: 0.7479\n",
      "Epoch 349/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4058 - accuracy: 0.8163 - val_loss: 0.5026 - val_accuracy: 0.7502\n",
      "Epoch 350/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.4054 - accuracy: 0.8147 - val_loss: 0.5059 - val_accuracy: 0.7460\n",
      "Epoch 351/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4056 - accuracy: 0.8153 - val_loss: 0.5046 - val_accuracy: 0.7498\n",
      "Epoch 352/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4054 - accuracy: 0.8157 - val_loss: 0.5058 - val_accuracy: 0.7488\n",
      "Epoch 353/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4053 - accuracy: 0.8153 - val_loss: 0.5023 - val_accuracy: 0.7493\n",
      "Epoch 354/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4052 - accuracy: 0.8156 - val_loss: 0.5032 - val_accuracy: 0.7493\n",
      "Epoch 355/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4051 - accuracy: 0.8167 - val_loss: 0.5054 - val_accuracy: 0.7498\n",
      "Epoch 356/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4049 - accuracy: 0.8160 - val_loss: 0.5028 - val_accuracy: 0.7512\n",
      "Epoch 357/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4049 - accuracy: 0.8159 - val_loss: 0.5031 - val_accuracy: 0.7526\n",
      "Epoch 358/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4048 - accuracy: 0.8164 - val_loss: 0.5030 - val_accuracy: 0.7536\n",
      "Epoch 359/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4047 - accuracy: 0.8161 - val_loss: 0.5036 - val_accuracy: 0.7512\n",
      "Epoch 360/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4045 - accuracy: 0.8168 - val_loss: 0.5067 - val_accuracy: 0.7498\n",
      "Epoch 361/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4045 - accuracy: 0.8178 - val_loss: 0.5038 - val_accuracy: 0.7521\n",
      "Epoch 362/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4043 - accuracy: 0.8159 - val_loss: 0.5062 - val_accuracy: 0.7507\n",
      "Epoch 363/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4042 - accuracy: 0.8171 - val_loss: 0.5023 - val_accuracy: 0.7540\n",
      "Epoch 364/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4042 - accuracy: 0.8160 - val_loss: 0.5042 - val_accuracy: 0.7531\n",
      "Epoch 365/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4039 - accuracy: 0.8168 - val_loss: 0.5045 - val_accuracy: 0.7502\n",
      "Epoch 366/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4039 - accuracy: 0.8172 - val_loss: 0.5045 - val_accuracy: 0.7521\n",
      "Epoch 367/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4039 - accuracy: 0.8172 - val_loss: 0.5020 - val_accuracy: 0.7550\n",
      "Epoch 368/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4037 - accuracy: 0.8167 - val_loss: 0.4997 - val_accuracy: 0.7569\n",
      "Epoch 369/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4036 - accuracy: 0.8161 - val_loss: 0.5026 - val_accuracy: 0.7531\n",
      "Epoch 370/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4034 - accuracy: 0.8164 - val_loss: 0.5036 - val_accuracy: 0.7540\n",
      "Epoch 371/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4032 - accuracy: 0.8181 - val_loss: 0.5000 - val_accuracy: 0.7545\n",
      "Epoch 372/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4032 - accuracy: 0.8160 - val_loss: 0.5002 - val_accuracy: 0.7555\n",
      "Epoch 373/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4030 - accuracy: 0.8178 - val_loss: 0.5028 - val_accuracy: 0.7545\n",
      "Epoch 374/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4027 - accuracy: 0.8167 - val_loss: 0.5007 - val_accuracy: 0.7545\n",
      "Epoch 375/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4027 - accuracy: 0.8175 - val_loss: 0.4987 - val_accuracy: 0.7540\n",
      "Epoch 376/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4025 - accuracy: 0.8167 - val_loss: 0.5043 - val_accuracy: 0.7536\n",
      "Epoch 377/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4024 - accuracy: 0.8183 - val_loss: 0.4988 - val_accuracy: 0.7573\n",
      "Epoch 378/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4022 - accuracy: 0.8175 - val_loss: 0.5005 - val_accuracy: 0.7564\n",
      "Epoch 379/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4019 - accuracy: 0.8167 - val_loss: 0.5011 - val_accuracy: 0.7550\n",
      "Epoch 380/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4019 - accuracy: 0.8183 - val_loss: 0.5021 - val_accuracy: 0.7559\n",
      "Epoch 381/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4018 - accuracy: 0.8179 - val_loss: 0.5025 - val_accuracy: 0.7545\n",
      "Epoch 382/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4016 - accuracy: 0.8177 - val_loss: 0.5026 - val_accuracy: 0.7540\n",
      "Epoch 383/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4015 - accuracy: 0.8189 - val_loss: 0.5002 - val_accuracy: 0.7564\n",
      "Epoch 384/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.4013 - accuracy: 0.8181 - val_loss: 0.5025 - val_accuracy: 0.7559\n",
      "Epoch 385/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.4012 - accuracy: 0.8178 - val_loss: 0.5029 - val_accuracy: 0.7540\n",
      "Epoch 386/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.4010 - accuracy: 0.8183 - val_loss: 0.5028 - val_accuracy: 0.7536\n",
      "Epoch 387/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4008 - accuracy: 0.8179 - val_loss: 0.5041 - val_accuracy: 0.7517\n",
      "Epoch 388/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4007 - accuracy: 0.8175 - val_loss: 0.4977 - val_accuracy: 0.7583\n",
      "Epoch 389/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4005 - accuracy: 0.8204 - val_loss: 0.4977 - val_accuracy: 0.7592\n",
      "Epoch 390/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.4004 - accuracy: 0.8186 - val_loss: 0.5023 - val_accuracy: 0.7569\n",
      "Epoch 391/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4001 - accuracy: 0.8186 - val_loss: 0.5022 - val_accuracy: 0.7569\n",
      "Epoch 392/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3999 - accuracy: 0.8183 - val_loss: 0.5046 - val_accuracy: 0.7536\n",
      "Epoch 393/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.4000 - accuracy: 0.8192 - val_loss: 0.5034 - val_accuracy: 0.7555\n",
      "Epoch 394/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3996 - accuracy: 0.8207 - val_loss: 0.4991 - val_accuracy: 0.7555\n",
      "Epoch 395/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3993 - accuracy: 0.8214 - val_loss: 0.5020 - val_accuracy: 0.7573\n",
      "Epoch 396/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3994 - accuracy: 0.8192 - val_loss: 0.5021 - val_accuracy: 0.7521\n",
      "Epoch 397/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3991 - accuracy: 0.8197 - val_loss: 0.5061 - val_accuracy: 0.7512\n",
      "Epoch 398/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3991 - accuracy: 0.8179 - val_loss: 0.5004 - val_accuracy: 0.7526\n",
      "Epoch 399/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3988 - accuracy: 0.8201 - val_loss: 0.5041 - val_accuracy: 0.7531\n",
      "Epoch 400/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3988 - accuracy: 0.8199 - val_loss: 0.5004 - val_accuracy: 0.7540\n",
      "Epoch 401/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3986 - accuracy: 0.8199 - val_loss: 0.5003 - val_accuracy: 0.7559\n",
      "Epoch 402/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3986 - accuracy: 0.8204 - val_loss: 0.4995 - val_accuracy: 0.7550\n",
      "Epoch 403/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3982 - accuracy: 0.8199 - val_loss: 0.5011 - val_accuracy: 0.7526\n",
      "Epoch 404/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3982 - accuracy: 0.8208 - val_loss: 0.5032 - val_accuracy: 0.7521\n",
      "Epoch 405/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3980 - accuracy: 0.8192 - val_loss: 0.5049 - val_accuracy: 0.7531\n",
      "Epoch 406/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3979 - accuracy: 0.8201 - val_loss: 0.5017 - val_accuracy: 0.7564\n",
      "Epoch 407/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3979 - accuracy: 0.8196 - val_loss: 0.5025 - val_accuracy: 0.7545\n",
      "Epoch 408/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3977 - accuracy: 0.8214 - val_loss: 0.4997 - val_accuracy: 0.7555\n",
      "Epoch 409/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3974 - accuracy: 0.8207 - val_loss: 0.5045 - val_accuracy: 0.7531\n",
      "Epoch 410/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3973 - accuracy: 0.8229 - val_loss: 0.5032 - val_accuracy: 0.7536\n",
      "Epoch 411/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3972 - accuracy: 0.8215 - val_loss: 0.5009 - val_accuracy: 0.7555\n",
      "Epoch 412/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3971 - accuracy: 0.8199 - val_loss: 0.5004 - val_accuracy: 0.7545\n",
      "Epoch 413/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3972 - accuracy: 0.8208 - val_loss: 0.4996 - val_accuracy: 0.7559\n",
      "Epoch 414/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3968 - accuracy: 0.8233 - val_loss: 0.5009 - val_accuracy: 0.7559\n",
      "Epoch 415/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3968 - accuracy: 0.8214 - val_loss: 0.5009 - val_accuracy: 0.7545\n",
      "Epoch 416/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3967 - accuracy: 0.8208 - val_loss: 0.5025 - val_accuracy: 0.7536\n",
      "Epoch 417/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3967 - accuracy: 0.8219 - val_loss: 0.4988 - val_accuracy: 0.7540\n",
      "Epoch 418/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3965 - accuracy: 0.8210 - val_loss: 0.4976 - val_accuracy: 0.7559\n",
      "Epoch 419/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3964 - accuracy: 0.8207 - val_loss: 0.4997 - val_accuracy: 0.7545\n",
      "Epoch 420/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3961 - accuracy: 0.8215 - val_loss: 0.5010 - val_accuracy: 0.7536\n",
      "Epoch 421/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3959 - accuracy: 0.8207 - val_loss: 0.4999 - val_accuracy: 0.7531\n",
      "Epoch 422/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3960 - accuracy: 0.8213 - val_loss: 0.5040 - val_accuracy: 0.7512\n",
      "Epoch 423/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3958 - accuracy: 0.8221 - val_loss: 0.5040 - val_accuracy: 0.7521\n",
      "Epoch 424/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3957 - accuracy: 0.8218 - val_loss: 0.4946 - val_accuracy: 0.7550\n",
      "Epoch 425/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3955 - accuracy: 0.8229 - val_loss: 0.5007 - val_accuracy: 0.7536\n",
      "Epoch 426/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3954 - accuracy: 0.8215 - val_loss: 0.4958 - val_accuracy: 0.7550\n",
      "Epoch 427/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3953 - accuracy: 0.8226 - val_loss: 0.5023 - val_accuracy: 0.7517\n",
      "Epoch 428/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3951 - accuracy: 0.8207 - val_loss: 0.5023 - val_accuracy: 0.7517\n",
      "Epoch 429/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3951 - accuracy: 0.8211 - val_loss: 0.5047 - val_accuracy: 0.7526\n",
      "Epoch 430/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3949 - accuracy: 0.8217 - val_loss: 0.4992 - val_accuracy: 0.7521\n",
      "Epoch 431/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3948 - accuracy: 0.8217 - val_loss: 0.4996 - val_accuracy: 0.7536\n",
      "Epoch 432/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3947 - accuracy: 0.8206 - val_loss: 0.4986 - val_accuracy: 0.7521\n",
      "Epoch 433/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3946 - accuracy: 0.8219 - val_loss: 0.5039 - val_accuracy: 0.7498\n",
      "Epoch 434/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3944 - accuracy: 0.8218 - val_loss: 0.5017 - val_accuracy: 0.7502\n",
      "Epoch 435/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3943 - accuracy: 0.8217 - val_loss: 0.5027 - val_accuracy: 0.7517\n",
      "Epoch 436/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3944 - accuracy: 0.8204 - val_loss: 0.4990 - val_accuracy: 0.7517\n",
      "Epoch 437/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3940 - accuracy: 0.8221 - val_loss: 0.5050 - val_accuracy: 0.7493\n",
      "Epoch 438/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3941 - accuracy: 0.8221 - val_loss: 0.4987 - val_accuracy: 0.7517\n",
      "Epoch 439/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3939 - accuracy: 0.8204 - val_loss: 0.4992 - val_accuracy: 0.7498\n",
      "Epoch 440/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3937 - accuracy: 0.8215 - val_loss: 0.4976 - val_accuracy: 0.7526\n",
      "Epoch 441/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3936 - accuracy: 0.8224 - val_loss: 0.5021 - val_accuracy: 0.7502\n",
      "Epoch 442/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3936 - accuracy: 0.8233 - val_loss: 0.5019 - val_accuracy: 0.7512\n",
      "Epoch 443/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3933 - accuracy: 0.8226 - val_loss: 0.5087 - val_accuracy: 0.7493\n",
      "Epoch 444/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3933 - accuracy: 0.8228 - val_loss: 0.4990 - val_accuracy: 0.7507\n",
      "Epoch 445/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3931 - accuracy: 0.8213 - val_loss: 0.5009 - val_accuracy: 0.7526\n",
      "Epoch 446/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3932 - accuracy: 0.8222 - val_loss: 0.4998 - val_accuracy: 0.7512\n",
      "Epoch 447/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3931 - accuracy: 0.8226 - val_loss: 0.5019 - val_accuracy: 0.7507\n",
      "Epoch 448/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3923 - accuracy: 0.8190 - val_loss: 0.5019 - val_accuracy: 0.7540\n",
      "Epoch 449/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3929 - accuracy: 0.8219 - val_loss: 0.4964 - val_accuracy: 0.7540\n",
      "Epoch 450/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3927 - accuracy: 0.8207 - val_loss: 0.5023 - val_accuracy: 0.7536\n",
      "Epoch 451/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3925 - accuracy: 0.8235 - val_loss: 0.5042 - val_accuracy: 0.7507\n",
      "Epoch 452/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3926 - accuracy: 0.8226 - val_loss: 0.4987 - val_accuracy: 0.7512\n",
      "Epoch 453/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3922 - accuracy: 0.8215 - val_loss: 0.5036 - val_accuracy: 0.7507\n",
      "Epoch 454/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3924 - accuracy: 0.8221 - val_loss: 0.5020 - val_accuracy: 0.7531\n",
      "Epoch 455/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3923 - accuracy: 0.8228 - val_loss: 0.4983 - val_accuracy: 0.7550\n",
      "Epoch 456/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3919 - accuracy: 0.8237 - val_loss: 0.5024 - val_accuracy: 0.7498\n",
      "Epoch 457/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3920 - accuracy: 0.8219 - val_loss: 0.4996 - val_accuracy: 0.7550\n",
      "Epoch 458/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3918 - accuracy: 0.8232 - val_loss: 0.4964 - val_accuracy: 0.7559\n",
      "Epoch 459/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3917 - accuracy: 0.8221 - val_loss: 0.4972 - val_accuracy: 0.7564\n",
      "Epoch 460/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3917 - accuracy: 0.8229 - val_loss: 0.5028 - val_accuracy: 0.7531\n",
      "Epoch 461/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3915 - accuracy: 0.8211 - val_loss: 0.4956 - val_accuracy: 0.7559\n",
      "Epoch 462/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3912 - accuracy: 0.8237 - val_loss: 0.5018 - val_accuracy: 0.7545\n",
      "Epoch 463/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3913 - accuracy: 0.8192 - val_loss: 0.4994 - val_accuracy: 0.7583\n",
      "Epoch 464/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3906 - accuracy: 0.8219 - val_loss: 0.4924 - val_accuracy: 0.7573\n",
      "Epoch 465/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3909 - accuracy: 0.8211 - val_loss: 0.4985 - val_accuracy: 0.7559\n",
      "Epoch 466/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3906 - accuracy: 0.8233 - val_loss: 0.4910 - val_accuracy: 0.7588\n",
      "Epoch 467/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3906 - accuracy: 0.8225 - val_loss: 0.4961 - val_accuracy: 0.7583\n",
      "Epoch 468/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3906 - accuracy: 0.8213 - val_loss: 0.4961 - val_accuracy: 0.7588\n",
      "Epoch 469/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3905 - accuracy: 0.8219 - val_loss: 0.4951 - val_accuracy: 0.7611\n",
      "Epoch 470/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3905 - accuracy: 0.8221 - val_loss: 0.5028 - val_accuracy: 0.7521\n",
      "Epoch 471/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3901 - accuracy: 0.8211 - val_loss: 0.5092 - val_accuracy: 0.7507\n",
      "Epoch 472/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3904 - accuracy: 0.8218 - val_loss: 0.5012 - val_accuracy: 0.7564\n",
      "Epoch 473/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3903 - accuracy: 0.8193 - val_loss: 0.4990 - val_accuracy: 0.7559\n",
      "Epoch 474/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3901 - accuracy: 0.8214 - val_loss: 0.5003 - val_accuracy: 0.7550\n",
      "Epoch 475/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3899 - accuracy: 0.8217 - val_loss: 0.5003 - val_accuracy: 0.7550\n",
      "Epoch 476/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3900 - accuracy: 0.8219 - val_loss: 0.4965 - val_accuracy: 0.7578\n",
      "Epoch 477/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3898 - accuracy: 0.8229 - val_loss: 0.4992 - val_accuracy: 0.7583\n",
      "Epoch 478/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3896 - accuracy: 0.8232 - val_loss: 0.4997 - val_accuracy: 0.7564\n",
      "Epoch 479/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3896 - accuracy: 0.8237 - val_loss: 0.4954 - val_accuracy: 0.7588\n",
      "Epoch 480/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3894 - accuracy: 0.8233 - val_loss: 0.4944 - val_accuracy: 0.7588\n",
      "Epoch 481/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3892 - accuracy: 0.8221 - val_loss: 0.5023 - val_accuracy: 0.7493\n",
      "Epoch 482/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3894 - accuracy: 0.8232 - val_loss: 0.4997 - val_accuracy: 0.7569\n",
      "Epoch 483/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3888 - accuracy: 0.8229 - val_loss: 0.4940 - val_accuracy: 0.7630\n",
      "Epoch 484/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3892 - accuracy: 0.8218 - val_loss: 0.4929 - val_accuracy: 0.7616\n",
      "Epoch 485/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3891 - accuracy: 0.8221 - val_loss: 0.4997 - val_accuracy: 0.7602\n",
      "Epoch 486/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3891 - accuracy: 0.8208 - val_loss: 0.4962 - val_accuracy: 0.7602\n",
      "Epoch 487/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3890 - accuracy: 0.8232 - val_loss: 0.4934 - val_accuracy: 0.7607\n",
      "Epoch 488/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3889 - accuracy: 0.8230 - val_loss: 0.4989 - val_accuracy: 0.7564\n",
      "Epoch 489/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3888 - accuracy: 0.8214 - val_loss: 0.4964 - val_accuracy: 0.7592\n",
      "Epoch 490/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3887 - accuracy: 0.8222 - val_loss: 0.4998 - val_accuracy: 0.7559\n",
      "Epoch 491/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3885 - accuracy: 0.8239 - val_loss: 0.4960 - val_accuracy: 0.7597\n",
      "Epoch 492/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3886 - accuracy: 0.8233 - val_loss: 0.4966 - val_accuracy: 0.7583\n",
      "Epoch 493/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3884 - accuracy: 0.8219 - val_loss: 0.4916 - val_accuracy: 0.7645\n",
      "Epoch 494/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3881 - accuracy: 0.8224 - val_loss: 0.4970 - val_accuracy: 0.7588\n",
      "Epoch 495/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3883 - accuracy: 0.8233 - val_loss: 0.4942 - val_accuracy: 0.7616\n",
      "Epoch 496/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3884 - accuracy: 0.8221 - val_loss: 0.4991 - val_accuracy: 0.7588\n",
      "Epoch 497/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3881 - accuracy: 0.8215 - val_loss: 0.4898 - val_accuracy: 0.7649\n",
      "Epoch 498/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3882 - accuracy: 0.8222 - val_loss: 0.4944 - val_accuracy: 0.7630\n",
      "Epoch 499/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3880 - accuracy: 0.8228 - val_loss: 0.5021 - val_accuracy: 0.7555\n",
      "Epoch 500/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3879 - accuracy: 0.8221 - val_loss: 0.5002 - val_accuracy: 0.7564\n",
      "Epoch 501/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3877 - accuracy: 0.8210 - val_loss: 0.4979 - val_accuracy: 0.7621\n",
      "Epoch 502/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3880 - accuracy: 0.8237 - val_loss: 0.4953 - val_accuracy: 0.7602\n",
      "Epoch 503/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3879 - accuracy: 0.8219 - val_loss: 0.4983 - val_accuracy: 0.7583\n",
      "Epoch 504/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3879 - accuracy: 0.8229 - val_loss: 0.4972 - val_accuracy: 0.7611\n",
      "Epoch 505/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3876 - accuracy: 0.8244 - val_loss: 0.4977 - val_accuracy: 0.7592\n",
      "Epoch 506/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3874 - accuracy: 0.8236 - val_loss: 0.4996 - val_accuracy: 0.7607\n",
      "Epoch 507/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3876 - accuracy: 0.8232 - val_loss: 0.4928 - val_accuracy: 0.7602\n",
      "Epoch 508/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3871 - accuracy: 0.8208 - val_loss: 0.5017 - val_accuracy: 0.7545\n",
      "Epoch 509/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3874 - accuracy: 0.8219 - val_loss: 0.5027 - val_accuracy: 0.7559\n",
      "Epoch 510/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3875 - accuracy: 0.8236 - val_loss: 0.4984 - val_accuracy: 0.7578\n",
      "Epoch 511/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3868 - accuracy: 0.8239 - val_loss: 0.4900 - val_accuracy: 0.7664\n",
      "Epoch 512/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3874 - accuracy: 0.8225 - val_loss: 0.4986 - val_accuracy: 0.7588\n",
      "Epoch 513/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3874 - accuracy: 0.8226 - val_loss: 0.5027 - val_accuracy: 0.7573\n",
      "Epoch 514/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3872 - accuracy: 0.8207 - val_loss: 0.5002 - val_accuracy: 0.7573\n",
      "Epoch 515/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3868 - accuracy: 0.8219 - val_loss: 0.4916 - val_accuracy: 0.7597\n",
      "Epoch 516/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3870 - accuracy: 0.8242 - val_loss: 0.4952 - val_accuracy: 0.7578\n",
      "Epoch 517/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3868 - accuracy: 0.8221 - val_loss: 0.4931 - val_accuracy: 0.7602\n",
      "Epoch 518/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3870 - accuracy: 0.8226 - val_loss: 0.4929 - val_accuracy: 0.7611\n",
      "Epoch 519/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3868 - accuracy: 0.8215 - val_loss: 0.4977 - val_accuracy: 0.7555\n",
      "Epoch 520/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3864 - accuracy: 0.8221 - val_loss: 0.4903 - val_accuracy: 0.7630\n",
      "Epoch 521/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3867 - accuracy: 0.8215 - val_loss: 0.5005 - val_accuracy: 0.7545\n",
      "Epoch 522/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3866 - accuracy: 0.8237 - val_loss: 0.4968 - val_accuracy: 0.7592\n",
      "Epoch 523/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3865 - accuracy: 0.8226 - val_loss: 0.4959 - val_accuracy: 0.7616\n",
      "Epoch 524/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3865 - accuracy: 0.8243 - val_loss: 0.4964 - val_accuracy: 0.7602\n",
      "Epoch 525/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3864 - accuracy: 0.8230 - val_loss: 0.4986 - val_accuracy: 0.7573\n",
      "Epoch 526/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3865 - accuracy: 0.8217 - val_loss: 0.5000 - val_accuracy: 0.7588\n",
      "Epoch 527/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3866 - accuracy: 0.8244 - val_loss: 0.5000 - val_accuracy: 0.7550\n",
      "Epoch 528/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3863 - accuracy: 0.8229 - val_loss: 0.4958 - val_accuracy: 0.7616\n",
      "Epoch 529/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3864 - accuracy: 0.8228 - val_loss: 0.4942 - val_accuracy: 0.7630\n",
      "Epoch 530/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3860 - accuracy: 0.8230 - val_loss: 0.4925 - val_accuracy: 0.7592\n",
      "Epoch 531/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3862 - accuracy: 0.8211 - val_loss: 0.4931 - val_accuracy: 0.7597\n",
      "Epoch 532/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3860 - accuracy: 0.8232 - val_loss: 0.4947 - val_accuracy: 0.7592\n",
      "Epoch 533/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3859 - accuracy: 0.8233 - val_loss: 0.4910 - val_accuracy: 0.7607\n",
      "Epoch 534/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3861 - accuracy: 0.8211 - val_loss: 0.4957 - val_accuracy: 0.7564\n",
      "Epoch 535/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3859 - accuracy: 0.8215 - val_loss: 0.5004 - val_accuracy: 0.7555\n",
      "Epoch 536/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3857 - accuracy: 0.8251 - val_loss: 0.4914 - val_accuracy: 0.7611\n",
      "Epoch 537/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3858 - accuracy: 0.8237 - val_loss: 0.4992 - val_accuracy: 0.7588\n",
      "Epoch 538/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3855 - accuracy: 0.8240 - val_loss: 0.4953 - val_accuracy: 0.7588\n",
      "Epoch 539/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3852 - accuracy: 0.8224 - val_loss: 0.4967 - val_accuracy: 0.7573\n",
      "Epoch 540/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3856 - accuracy: 0.8258 - val_loss: 0.4994 - val_accuracy: 0.7592\n",
      "Epoch 541/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3854 - accuracy: 0.8214 - val_loss: 0.4971 - val_accuracy: 0.7564\n",
      "Epoch 542/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3851 - accuracy: 0.8254 - val_loss: 0.5047 - val_accuracy: 0.7573\n",
      "Epoch 543/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3855 - accuracy: 0.8226 - val_loss: 0.4980 - val_accuracy: 0.7569\n",
      "Epoch 544/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3852 - accuracy: 0.8210 - val_loss: 0.4960 - val_accuracy: 0.7583\n",
      "Epoch 545/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3848 - accuracy: 0.8230 - val_loss: 0.4986 - val_accuracy: 0.7588\n",
      "Epoch 546/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3851 - accuracy: 0.8222 - val_loss: 0.4990 - val_accuracy: 0.7569\n",
      "Epoch 547/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3851 - accuracy: 0.8235 - val_loss: 0.4991 - val_accuracy: 0.7564\n",
      "Epoch 548/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3851 - accuracy: 0.8217 - val_loss: 0.4972 - val_accuracy: 0.7592\n",
      "Epoch 549/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3849 - accuracy: 0.8236 - val_loss: 0.4983 - val_accuracy: 0.7578\n",
      "Epoch 550/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3847 - accuracy: 0.8226 - val_loss: 0.4993 - val_accuracy: 0.7583\n",
      "Epoch 551/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3843 - accuracy: 0.8235 - val_loss: 0.4977 - val_accuracy: 0.7545\n",
      "Epoch 552/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3843 - accuracy: 0.8261 - val_loss: 0.4950 - val_accuracy: 0.7592\n",
      "Epoch 553/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3842 - accuracy: 0.8235 - val_loss: 0.4992 - val_accuracy: 0.7592\n",
      "Epoch 554/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3841 - accuracy: 0.8230 - val_loss: 0.5026 - val_accuracy: 0.7569\n",
      "Epoch 555/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3843 - accuracy: 0.8218 - val_loss: 0.4936 - val_accuracy: 0.7588\n",
      "Epoch 556/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3840 - accuracy: 0.8235 - val_loss: 0.4968 - val_accuracy: 0.7592\n",
      "Epoch 557/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3842 - accuracy: 0.8224 - val_loss: 0.4986 - val_accuracy: 0.7559\n",
      "Epoch 558/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3841 - accuracy: 0.8240 - val_loss: 0.4963 - val_accuracy: 0.7616\n",
      "Epoch 559/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3839 - accuracy: 0.8235 - val_loss: 0.4950 - val_accuracy: 0.7626\n",
      "Epoch 560/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3836 - accuracy: 0.8239 - val_loss: 0.4985 - val_accuracy: 0.7588\n",
      "Epoch 561/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3838 - accuracy: 0.8247 - val_loss: 0.5008 - val_accuracy: 0.7545\n",
      "Epoch 562/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3838 - accuracy: 0.8214 - val_loss: 0.4924 - val_accuracy: 0.7626\n",
      "Epoch 563/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3837 - accuracy: 0.8224 - val_loss: 0.5001 - val_accuracy: 0.7602\n",
      "Epoch 564/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3833 - accuracy: 0.8244 - val_loss: 0.5069 - val_accuracy: 0.7517\n",
      "Epoch 565/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3841 - accuracy: 0.8221 - val_loss: 0.4936 - val_accuracy: 0.7626\n",
      "Epoch 566/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3837 - accuracy: 0.8214 - val_loss: 0.4964 - val_accuracy: 0.7602\n",
      "Epoch 567/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3835 - accuracy: 0.8229 - val_loss: 0.4925 - val_accuracy: 0.7630\n",
      "Epoch 568/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3835 - accuracy: 0.8213 - val_loss: 0.4915 - val_accuracy: 0.7649\n",
      "Epoch 569/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3835 - accuracy: 0.8230 - val_loss: 0.4990 - val_accuracy: 0.7578\n",
      "Epoch 570/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3831 - accuracy: 0.8219 - val_loss: 0.4973 - val_accuracy: 0.7573\n",
      "Epoch 571/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3827 - accuracy: 0.8243 - val_loss: 0.4950 - val_accuracy: 0.7616\n",
      "Epoch 572/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3833 - accuracy: 0.8224 - val_loss: 0.4968 - val_accuracy: 0.7597\n",
      "Epoch 573/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3835 - accuracy: 0.8219 - val_loss: 0.4980 - val_accuracy: 0.7630\n",
      "Epoch 574/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3834 - accuracy: 0.8215 - val_loss: 0.4993 - val_accuracy: 0.7607\n",
      "Epoch 575/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3834 - accuracy: 0.8219 - val_loss: 0.5007 - val_accuracy: 0.7578\n",
      "Epoch 576/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3831 - accuracy: 0.8230 - val_loss: 0.4971 - val_accuracy: 0.7640\n",
      "Epoch 577/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3834 - accuracy: 0.8217 - val_loss: 0.4980 - val_accuracy: 0.7621\n",
      "Epoch 578/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3829 - accuracy: 0.8236 - val_loss: 0.4883 - val_accuracy: 0.7687\n",
      "Epoch 579/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3831 - accuracy: 0.8213 - val_loss: 0.4919 - val_accuracy: 0.7640\n",
      "Epoch 580/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3832 - accuracy: 0.8237 - val_loss: 0.4950 - val_accuracy: 0.7626\n",
      "Epoch 581/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3828 - accuracy: 0.8237 - val_loss: 0.5031 - val_accuracy: 0.7559\n",
      "Epoch 582/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3829 - accuracy: 0.8219 - val_loss: 0.5004 - val_accuracy: 0.7569\n",
      "Epoch 583/1500\n",
      "226/226 [==============================] - 3s 11ms/step - loss: 0.3828 - accuracy: 0.8247 - val_loss: 0.4938 - val_accuracy: 0.7621\n",
      "Epoch 584/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3832 - accuracy: 0.8237 - val_loss: 0.4980 - val_accuracy: 0.7578\n",
      "Epoch 585/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3831 - accuracy: 0.8229 - val_loss: 0.5050 - val_accuracy: 0.7597\n",
      "Epoch 586/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3831 - accuracy: 0.8225 - val_loss: 0.4916 - val_accuracy: 0.7664\n",
      "Epoch 587/1500\n",
      "226/226 [==============================] - 3s 14ms/step - loss: 0.3828 - accuracy: 0.8233 - val_loss: 0.4991 - val_accuracy: 0.7611\n",
      "Epoch 588/1500\n",
      "226/226 [==============================] - 3s 13ms/step - loss: 0.3825 - accuracy: 0.8237 - val_loss: 0.4844 - val_accuracy: 0.7716\n",
      "Epoch 589/1500\n",
      "226/226 [==============================] - 3s 13ms/step - loss: 0.3829 - accuracy: 0.8228 - val_loss: 0.4845 - val_accuracy: 0.7701\n",
      "Epoch 590/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3827 - accuracy: 0.8240 - val_loss: 0.4982 - val_accuracy: 0.7597\n",
      "Epoch 591/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3827 - accuracy: 0.8233 - val_loss: 0.4925 - val_accuracy: 0.7673\n",
      "Epoch 592/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3826 - accuracy: 0.8228 - val_loss: 0.5022 - val_accuracy: 0.7592\n",
      "Epoch 593/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3831 - accuracy: 0.8235 - val_loss: 0.4958 - val_accuracy: 0.7630\n",
      "Epoch 594/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3825 - accuracy: 0.8232 - val_loss: 0.4899 - val_accuracy: 0.7664\n",
      "Epoch 595/1500\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.3828 - accuracy: 0.8233 - val_loss: 0.4960 - val_accuracy: 0.7616\n",
      "Epoch 596/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3826 - accuracy: 0.8251 - val_loss: 0.5025 - val_accuracy: 0.7588\n",
      "Epoch 597/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3826 - accuracy: 0.8235 - val_loss: 0.4938 - val_accuracy: 0.7607\n",
      "Epoch 598/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3825 - accuracy: 0.8228 - val_loss: 0.4970 - val_accuracy: 0.7635\n",
      "Epoch 599/1500\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.3826 - accuracy: 0.8253 - val_loss: 0.4937 - val_accuracy: 0.7607\n",
      "Epoch 600/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3821 - accuracy: 0.8235 - val_loss: 0.4914 - val_accuracy: 0.7668\n",
      "Epoch 601/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3822 - accuracy: 0.8232 - val_loss: 0.4959 - val_accuracy: 0.7602\n",
      "Epoch 602/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3826 - accuracy: 0.8244 - val_loss: 0.4941 - val_accuracy: 0.7659\n",
      "Epoch 603/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3821 - accuracy: 0.8242 - val_loss: 0.4948 - val_accuracy: 0.7630\n",
      "Epoch 604/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3822 - accuracy: 0.8240 - val_loss: 0.5006 - val_accuracy: 0.7616\n",
      "Epoch 605/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3824 - accuracy: 0.8242 - val_loss: 0.4925 - val_accuracy: 0.7640\n",
      "Epoch 606/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3822 - accuracy: 0.8235 - val_loss: 0.4952 - val_accuracy: 0.7626\n",
      "Epoch 607/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3823 - accuracy: 0.8251 - val_loss: 0.4972 - val_accuracy: 0.7592\n",
      "Epoch 608/1500\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.3823 - accuracy: 0.8237 - val_loss: 0.4948 - val_accuracy: 0.7664\n",
      "Epoch 609/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3821 - accuracy: 0.8239 - val_loss: 0.4956 - val_accuracy: 0.7621\n",
      "Epoch 610/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3821 - accuracy: 0.8248 - val_loss: 0.5044 - val_accuracy: 0.7578\n",
      "Epoch 611/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3823 - accuracy: 0.8226 - val_loss: 0.4965 - val_accuracy: 0.7621\n",
      "Epoch 612/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3821 - accuracy: 0.8248 - val_loss: 0.5002 - val_accuracy: 0.7602\n",
      "Epoch 613/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3820 - accuracy: 0.8237 - val_loss: 0.5002 - val_accuracy: 0.7616\n",
      "Epoch 614/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3821 - accuracy: 0.8228 - val_loss: 0.4956 - val_accuracy: 0.7654\n",
      "Epoch 615/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3821 - accuracy: 0.8258 - val_loss: 0.4890 - val_accuracy: 0.7649\n",
      "Epoch 616/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3823 - accuracy: 0.8228 - val_loss: 0.4986 - val_accuracy: 0.7602\n",
      "Epoch 617/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3819 - accuracy: 0.8243 - val_loss: 0.4889 - val_accuracy: 0.7678\n",
      "Epoch 618/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3822 - accuracy: 0.8236 - val_loss: 0.4930 - val_accuracy: 0.7649\n",
      "Epoch 619/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3822 - accuracy: 0.8242 - val_loss: 0.4980 - val_accuracy: 0.7649\n",
      "Epoch 620/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3821 - accuracy: 0.8244 - val_loss: 0.4945 - val_accuracy: 0.7649\n",
      "Epoch 621/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3816 - accuracy: 0.8242 - val_loss: 0.4966 - val_accuracy: 0.7645\n",
      "Epoch 622/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3820 - accuracy: 0.8239 - val_loss: 0.4903 - val_accuracy: 0.7673\n",
      "Epoch 623/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3818 - accuracy: 0.8253 - val_loss: 0.4902 - val_accuracy: 0.7664\n",
      "Epoch 624/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3816 - accuracy: 0.8237 - val_loss: 0.5008 - val_accuracy: 0.7626\n",
      "Epoch 625/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3819 - accuracy: 0.8262 - val_loss: 0.5028 - val_accuracy: 0.7621\n",
      "Epoch 626/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3820 - accuracy: 0.8261 - val_loss: 0.4919 - val_accuracy: 0.7673\n",
      "Epoch 627/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3820 - accuracy: 0.8230 - val_loss: 0.4937 - val_accuracy: 0.7664\n",
      "Epoch 628/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3816 - accuracy: 0.8237 - val_loss: 0.4959 - val_accuracy: 0.7640\n",
      "Epoch 629/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3820 - accuracy: 0.8254 - val_loss: 0.5005 - val_accuracy: 0.7640\n",
      "Epoch 630/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3813 - accuracy: 0.8235 - val_loss: 0.4850 - val_accuracy: 0.7720\n",
      "Epoch 631/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3817 - accuracy: 0.8258 - val_loss: 0.4923 - val_accuracy: 0.7673\n",
      "Epoch 632/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3815 - accuracy: 0.8258 - val_loss: 0.5004 - val_accuracy: 0.7616\n",
      "Epoch 633/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3819 - accuracy: 0.8233 - val_loss: 0.4945 - val_accuracy: 0.7678\n",
      "Epoch 634/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3815 - accuracy: 0.8257 - val_loss: 0.4975 - val_accuracy: 0.7654\n",
      "Epoch 635/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3813 - accuracy: 0.8258 - val_loss: 0.4994 - val_accuracy: 0.7659\n",
      "Epoch 636/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3817 - accuracy: 0.8250 - val_loss: 0.4974 - val_accuracy: 0.7673\n",
      "Epoch 637/1500\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.3816 - accuracy: 0.8243 - val_loss: 0.4998 - val_accuracy: 0.7621\n",
      "Epoch 638/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3818 - accuracy: 0.8243 - val_loss: 0.4976 - val_accuracy: 0.7659\n",
      "Epoch 639/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3814 - accuracy: 0.8239 - val_loss: 0.4855 - val_accuracy: 0.7711\n",
      "Epoch 640/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3815 - accuracy: 0.8251 - val_loss: 0.4934 - val_accuracy: 0.7692\n",
      "Epoch 641/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3812 - accuracy: 0.8244 - val_loss: 0.4915 - val_accuracy: 0.7678\n",
      "Epoch 642/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3815 - accuracy: 0.8229 - val_loss: 0.5034 - val_accuracy: 0.7611\n",
      "Epoch 643/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3815 - accuracy: 0.8248 - val_loss: 0.4960 - val_accuracy: 0.7668\n",
      "Epoch 644/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3807 - accuracy: 0.8260 - val_loss: 0.4947 - val_accuracy: 0.7678\n",
      "Epoch 645/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3810 - accuracy: 0.8255 - val_loss: 0.4906 - val_accuracy: 0.7701\n",
      "Epoch 646/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3813 - accuracy: 0.8260 - val_loss: 0.4955 - val_accuracy: 0.7687\n",
      "Epoch 647/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3812 - accuracy: 0.8258 - val_loss: 0.4898 - val_accuracy: 0.7687\n",
      "Epoch 648/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3811 - accuracy: 0.8250 - val_loss: 0.4974 - val_accuracy: 0.7616\n",
      "Epoch 649/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3810 - accuracy: 0.8248 - val_loss: 0.4976 - val_accuracy: 0.7668\n",
      "Epoch 650/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3813 - accuracy: 0.8254 - val_loss: 0.4953 - val_accuracy: 0.7673\n",
      "Epoch 651/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3813 - accuracy: 0.8269 - val_loss: 0.4976 - val_accuracy: 0.7687\n",
      "Epoch 652/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3814 - accuracy: 0.8229 - val_loss: 0.4952 - val_accuracy: 0.7640\n",
      "Epoch 653/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3810 - accuracy: 0.8243 - val_loss: 0.4938 - val_accuracy: 0.7673\n",
      "Epoch 654/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3812 - accuracy: 0.8248 - val_loss: 0.5000 - val_accuracy: 0.7630\n",
      "Epoch 655/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3805 - accuracy: 0.8236 - val_loss: 0.4902 - val_accuracy: 0.7659\n",
      "Epoch 656/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3814 - accuracy: 0.8240 - val_loss: 0.4998 - val_accuracy: 0.7640\n",
      "Epoch 657/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3810 - accuracy: 0.8247 - val_loss: 0.4972 - val_accuracy: 0.7635\n",
      "Epoch 658/1500\n",
      "226/226 [==============================] - 3s 13ms/step - loss: 0.3809 - accuracy: 0.8254 - val_loss: 0.4963 - val_accuracy: 0.7673\n",
      "Epoch 659/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3810 - accuracy: 0.8261 - val_loss: 0.4982 - val_accuracy: 0.7649\n",
      "Epoch 660/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3808 - accuracy: 0.8246 - val_loss: 0.4905 - val_accuracy: 0.7668\n",
      "Epoch 661/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3810 - accuracy: 0.8247 - val_loss: 0.4977 - val_accuracy: 0.7640\n",
      "Epoch 662/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3809 - accuracy: 0.8272 - val_loss: 0.5016 - val_accuracy: 0.7626\n",
      "Epoch 663/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3808 - accuracy: 0.8229 - val_loss: 0.5056 - val_accuracy: 0.7626\n",
      "Epoch 664/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3807 - accuracy: 0.8251 - val_loss: 0.5028 - val_accuracy: 0.7592\n",
      "Epoch 665/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3810 - accuracy: 0.8257 - val_loss: 0.4964 - val_accuracy: 0.7654\n",
      "Epoch 666/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3808 - accuracy: 0.8243 - val_loss: 0.5040 - val_accuracy: 0.7564\n",
      "Epoch 667/1500\n",
      "226/226 [==============================] - 3s 11ms/step - loss: 0.3805 - accuracy: 0.8255 - val_loss: 0.4996 - val_accuracy: 0.7635\n",
      "Epoch 668/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3810 - accuracy: 0.8255 - val_loss: 0.4936 - val_accuracy: 0.7668\n",
      "Epoch 669/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3808 - accuracy: 0.8260 - val_loss: 0.4968 - val_accuracy: 0.7659\n",
      "Epoch 670/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3805 - accuracy: 0.8247 - val_loss: 0.4965 - val_accuracy: 0.7621\n",
      "Epoch 671/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3802 - accuracy: 0.8260 - val_loss: 0.5069 - val_accuracy: 0.7578\n",
      "Epoch 672/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3807 - accuracy: 0.8250 - val_loss: 0.4925 - val_accuracy: 0.7668\n",
      "Epoch 673/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3810 - accuracy: 0.8266 - val_loss: 0.4987 - val_accuracy: 0.7654\n",
      "Epoch 674/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3805 - accuracy: 0.8273 - val_loss: 0.4971 - val_accuracy: 0.7678\n",
      "Epoch 675/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3807 - accuracy: 0.8237 - val_loss: 0.4938 - val_accuracy: 0.7692\n",
      "Epoch 676/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3808 - accuracy: 0.8242 - val_loss: 0.4945 - val_accuracy: 0.7673\n",
      "Epoch 677/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3806 - accuracy: 0.8257 - val_loss: 0.4987 - val_accuracy: 0.7635\n",
      "Epoch 678/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3803 - accuracy: 0.8243 - val_loss: 0.4952 - val_accuracy: 0.7697\n",
      "Epoch 679/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3806 - accuracy: 0.8235 - val_loss: 0.4929 - val_accuracy: 0.7659\n",
      "Epoch 680/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3804 - accuracy: 0.8261 - val_loss: 0.4982 - val_accuracy: 0.7626\n",
      "Epoch 681/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3804 - accuracy: 0.8242 - val_loss: 0.5034 - val_accuracy: 0.7578\n",
      "Epoch 682/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3803 - accuracy: 0.8262 - val_loss: 0.4938 - val_accuracy: 0.7673\n",
      "Epoch 683/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3806 - accuracy: 0.8247 - val_loss: 0.5013 - val_accuracy: 0.7645\n",
      "Epoch 684/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3799 - accuracy: 0.8237 - val_loss: 0.5055 - val_accuracy: 0.7597\n",
      "Epoch 685/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3802 - accuracy: 0.8250 - val_loss: 0.4958 - val_accuracy: 0.7654\n",
      "Epoch 686/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3802 - accuracy: 0.8255 - val_loss: 0.4982 - val_accuracy: 0.7649\n",
      "Epoch 687/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3805 - accuracy: 0.8264 - val_loss: 0.5000 - val_accuracy: 0.7654\n",
      "Epoch 688/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3799 - accuracy: 0.8251 - val_loss: 0.5007 - val_accuracy: 0.7630\n",
      "Epoch 689/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3804 - accuracy: 0.8237 - val_loss: 0.4986 - val_accuracy: 0.7630\n",
      "Epoch 690/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3802 - accuracy: 0.8243 - val_loss: 0.4961 - val_accuracy: 0.7678\n",
      "Epoch 691/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3801 - accuracy: 0.8258 - val_loss: 0.5005 - val_accuracy: 0.7645\n",
      "Epoch 692/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3800 - accuracy: 0.8247 - val_loss: 0.4894 - val_accuracy: 0.7682\n",
      "Epoch 693/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3802 - accuracy: 0.8268 - val_loss: 0.4991 - val_accuracy: 0.7626\n",
      "Epoch 694/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3801 - accuracy: 0.8247 - val_loss: 0.5044 - val_accuracy: 0.7649\n",
      "Epoch 695/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3804 - accuracy: 0.8255 - val_loss: 0.5021 - val_accuracy: 0.7621\n",
      "Epoch 696/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3804 - accuracy: 0.8261 - val_loss: 0.4955 - val_accuracy: 0.7645\n",
      "Epoch 697/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3800 - accuracy: 0.8233 - val_loss: 0.4980 - val_accuracy: 0.7640\n",
      "Epoch 698/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3800 - accuracy: 0.8248 - val_loss: 0.4995 - val_accuracy: 0.7602\n",
      "Epoch 699/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3802 - accuracy: 0.8248 - val_loss: 0.4969 - val_accuracy: 0.7640\n",
      "Epoch 700/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3801 - accuracy: 0.8254 - val_loss: 0.4972 - val_accuracy: 0.7682\n",
      "Epoch 701/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3797 - accuracy: 0.8255 - val_loss: 0.4963 - val_accuracy: 0.7673\n",
      "Epoch 702/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3800 - accuracy: 0.8257 - val_loss: 0.5012 - val_accuracy: 0.7630\n",
      "Epoch 703/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3802 - accuracy: 0.8268 - val_loss: 0.4931 - val_accuracy: 0.7673\n",
      "Epoch 704/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3801 - accuracy: 0.8240 - val_loss: 0.4991 - val_accuracy: 0.7649\n",
      "Epoch 705/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3799 - accuracy: 0.8255 - val_loss: 0.4975 - val_accuracy: 0.7649\n",
      "Epoch 706/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3799 - accuracy: 0.8232 - val_loss: 0.4937 - val_accuracy: 0.7640\n",
      "Epoch 707/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3795 - accuracy: 0.8255 - val_loss: 0.5046 - val_accuracy: 0.7621\n",
      "Epoch 708/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3800 - accuracy: 0.8258 - val_loss: 0.5014 - val_accuracy: 0.7611\n",
      "Epoch 709/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3800 - accuracy: 0.8260 - val_loss: 0.4927 - val_accuracy: 0.7678\n",
      "Epoch 710/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3799 - accuracy: 0.8266 - val_loss: 0.4887 - val_accuracy: 0.7730\n",
      "Epoch 711/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3800 - accuracy: 0.8247 - val_loss: 0.5009 - val_accuracy: 0.7687\n",
      "Epoch 712/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3801 - accuracy: 0.8255 - val_loss: 0.4948 - val_accuracy: 0.7668\n",
      "Epoch 713/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3801 - accuracy: 0.8255 - val_loss: 0.4937 - val_accuracy: 0.7716\n",
      "Epoch 714/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3799 - accuracy: 0.8257 - val_loss: 0.4974 - val_accuracy: 0.7706\n",
      "Epoch 715/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3796 - accuracy: 0.8255 - val_loss: 0.4953 - val_accuracy: 0.7654\n",
      "Epoch 716/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3797 - accuracy: 0.8282 - val_loss: 0.4959 - val_accuracy: 0.7664\n",
      "Epoch 717/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3795 - accuracy: 0.8255 - val_loss: 0.5020 - val_accuracy: 0.7673\n",
      "Epoch 718/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3796 - accuracy: 0.8243 - val_loss: 0.4962 - val_accuracy: 0.7664\n",
      "Epoch 719/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3800 - accuracy: 0.8248 - val_loss: 0.4965 - val_accuracy: 0.7673\n",
      "Epoch 720/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3795 - accuracy: 0.8246 - val_loss: 0.4957 - val_accuracy: 0.7654\n",
      "Epoch 721/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3794 - accuracy: 0.8251 - val_loss: 0.4946 - val_accuracy: 0.7630\n",
      "Epoch 722/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3795 - accuracy: 0.8283 - val_loss: 0.4985 - val_accuracy: 0.7635\n",
      "Epoch 723/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3796 - accuracy: 0.8250 - val_loss: 0.5032 - val_accuracy: 0.7616\n",
      "Epoch 724/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3794 - accuracy: 0.8262 - val_loss: 0.4972 - val_accuracy: 0.7645\n",
      "Epoch 725/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3799 - accuracy: 0.8244 - val_loss: 0.5017 - val_accuracy: 0.7626\n",
      "Epoch 726/1500\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.3801 - accuracy: 0.8257 - val_loss: 0.4956 - val_accuracy: 0.7626\n",
      "Epoch 727/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3796 - accuracy: 0.8261 - val_loss: 0.4994 - val_accuracy: 0.7635\n",
      "Epoch 728/1500\n",
      "226/226 [==============================] - 3s 11ms/step - loss: 0.3794 - accuracy: 0.8262 - val_loss: 0.5037 - val_accuracy: 0.7597\n",
      "Epoch 729/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3792 - accuracy: 0.8251 - val_loss: 0.5003 - val_accuracy: 0.7649\n",
      "Epoch 730/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3795 - accuracy: 0.8255 - val_loss: 0.5064 - val_accuracy: 0.7607\n",
      "Epoch 731/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3797 - accuracy: 0.8237 - val_loss: 0.5076 - val_accuracy: 0.7654\n",
      "Epoch 732/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3795 - accuracy: 0.8255 - val_loss: 0.4950 - val_accuracy: 0.7659\n",
      "Epoch 733/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3795 - accuracy: 0.8271 - val_loss: 0.4989 - val_accuracy: 0.7630\n",
      "Epoch 734/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3795 - accuracy: 0.8262 - val_loss: 0.4977 - val_accuracy: 0.7635\n",
      "Epoch 735/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3797 - accuracy: 0.8264 - val_loss: 0.4981 - val_accuracy: 0.7682\n",
      "Epoch 736/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3794 - accuracy: 0.8266 - val_loss: 0.4948 - val_accuracy: 0.7645\n",
      "Epoch 737/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3794 - accuracy: 0.8257 - val_loss: 0.4951 - val_accuracy: 0.7654\n",
      "Epoch 738/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3794 - accuracy: 0.8247 - val_loss: 0.4952 - val_accuracy: 0.7640\n",
      "Epoch 739/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3797 - accuracy: 0.8239 - val_loss: 0.5049 - val_accuracy: 0.7611\n",
      "Epoch 740/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3797 - accuracy: 0.8269 - val_loss: 0.4951 - val_accuracy: 0.7682\n",
      "Epoch 741/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3796 - accuracy: 0.8239 - val_loss: 0.4916 - val_accuracy: 0.7697\n",
      "Epoch 742/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3793 - accuracy: 0.8255 - val_loss: 0.4999 - val_accuracy: 0.7664\n",
      "Epoch 743/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3789 - accuracy: 0.8248 - val_loss: 0.5093 - val_accuracy: 0.7555\n",
      "Epoch 744/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3789 - accuracy: 0.8275 - val_loss: 0.5037 - val_accuracy: 0.7645\n",
      "Epoch 745/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3797 - accuracy: 0.8239 - val_loss: 0.5049 - val_accuracy: 0.7635\n",
      "Epoch 746/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3794 - accuracy: 0.8262 - val_loss: 0.4997 - val_accuracy: 0.7649\n",
      "Epoch 747/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3791 - accuracy: 0.8258 - val_loss: 0.5009 - val_accuracy: 0.7640\n",
      "Epoch 748/1500\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.3792 - accuracy: 0.8257 - val_loss: 0.4938 - val_accuracy: 0.7645\n",
      "Epoch 749/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3792 - accuracy: 0.8262 - val_loss: 0.5066 - val_accuracy: 0.7592\n",
      "Epoch 750/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3791 - accuracy: 0.8262 - val_loss: 0.4898 - val_accuracy: 0.7735\n",
      "Epoch 751/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3792 - accuracy: 0.8243 - val_loss: 0.5093 - val_accuracy: 0.7635\n",
      "Epoch 752/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3795 - accuracy: 0.8248 - val_loss: 0.5012 - val_accuracy: 0.7654\n",
      "Epoch 753/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3794 - accuracy: 0.8251 - val_loss: 0.5006 - val_accuracy: 0.7635\n",
      "Epoch 754/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3791 - accuracy: 0.8258 - val_loss: 0.4985 - val_accuracy: 0.7654\n",
      "Epoch 755/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3789 - accuracy: 0.8257 - val_loss: 0.4989 - val_accuracy: 0.7592\n",
      "Epoch 756/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3796 - accuracy: 0.8271 - val_loss: 0.4990 - val_accuracy: 0.7616\n",
      "Epoch 757/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3794 - accuracy: 0.8251 - val_loss: 0.4981 - val_accuracy: 0.7649\n",
      "Epoch 758/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3791 - accuracy: 0.8260 - val_loss: 0.5017 - val_accuracy: 0.7626\n",
      "Epoch 759/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3794 - accuracy: 0.8272 - val_loss: 0.4999 - val_accuracy: 0.7659\n",
      "Epoch 760/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3789 - accuracy: 0.8254 - val_loss: 0.4979 - val_accuracy: 0.7668\n",
      "Epoch 761/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3788 - accuracy: 0.8264 - val_loss: 0.5006 - val_accuracy: 0.7711\n",
      "Epoch 762/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3790 - accuracy: 0.8244 - val_loss: 0.5029 - val_accuracy: 0.7621\n",
      "Epoch 763/1500\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.3789 - accuracy: 0.8268 - val_loss: 0.4983 - val_accuracy: 0.7607\n",
      "Epoch 764/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3795 - accuracy: 0.8265 - val_loss: 0.4979 - val_accuracy: 0.7635\n",
      "Epoch 765/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3789 - accuracy: 0.8266 - val_loss: 0.4952 - val_accuracy: 0.7716\n",
      "Epoch 766/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3792 - accuracy: 0.8262 - val_loss: 0.4906 - val_accuracy: 0.7687\n",
      "Epoch 767/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3791 - accuracy: 0.8258 - val_loss: 0.4978 - val_accuracy: 0.7578\n",
      "Epoch 768/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3792 - accuracy: 0.8260 - val_loss: 0.4941 - val_accuracy: 0.7668\n",
      "Epoch 769/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3791 - accuracy: 0.8265 - val_loss: 0.4999 - val_accuracy: 0.7701\n",
      "Epoch 770/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3792 - accuracy: 0.8262 - val_loss: 0.4996 - val_accuracy: 0.7640\n",
      "Epoch 771/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3784 - accuracy: 0.8287 - val_loss: 0.5085 - val_accuracy: 0.7654\n",
      "Epoch 772/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3792 - accuracy: 0.8235 - val_loss: 0.4953 - val_accuracy: 0.7716\n",
      "Epoch 773/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3788 - accuracy: 0.8240 - val_loss: 0.5056 - val_accuracy: 0.7664\n",
      "Epoch 774/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3789 - accuracy: 0.8260 - val_loss: 0.5013 - val_accuracy: 0.7664\n",
      "Epoch 775/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3789 - accuracy: 0.8276 - val_loss: 0.4970 - val_accuracy: 0.7649\n",
      "Epoch 776/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3791 - accuracy: 0.8261 - val_loss: 0.4995 - val_accuracy: 0.7664\n",
      "Epoch 777/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3788 - accuracy: 0.8250 - val_loss: 0.4880 - val_accuracy: 0.7682\n",
      "Epoch 778/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3793 - accuracy: 0.8244 - val_loss: 0.4888 - val_accuracy: 0.7706\n",
      "Epoch 779/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3790 - accuracy: 0.8246 - val_loss: 0.4980 - val_accuracy: 0.7692\n",
      "Epoch 780/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3793 - accuracy: 0.8253 - val_loss: 0.4979 - val_accuracy: 0.7668\n",
      "Epoch 781/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3790 - accuracy: 0.8276 - val_loss: 0.5001 - val_accuracy: 0.7621\n",
      "Epoch 782/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3789 - accuracy: 0.8268 - val_loss: 0.4983 - val_accuracy: 0.7649\n",
      "Epoch 783/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3789 - accuracy: 0.8251 - val_loss: 0.4982 - val_accuracy: 0.7635\n",
      "Epoch 784/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3789 - accuracy: 0.8243 - val_loss: 0.5002 - val_accuracy: 0.7597\n",
      "Epoch 785/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3791 - accuracy: 0.8273 - val_loss: 0.4885 - val_accuracy: 0.7706\n",
      "Epoch 786/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3792 - accuracy: 0.8265 - val_loss: 0.4948 - val_accuracy: 0.7673\n",
      "Epoch 787/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3790 - accuracy: 0.8255 - val_loss: 0.5013 - val_accuracy: 0.7635\n",
      "Epoch 788/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3790 - accuracy: 0.8260 - val_loss: 0.4943 - val_accuracy: 0.7692\n",
      "Epoch 789/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3784 - accuracy: 0.8254 - val_loss: 0.4947 - val_accuracy: 0.7678\n",
      "Epoch 790/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3788 - accuracy: 0.8250 - val_loss: 0.5004 - val_accuracy: 0.7569\n",
      "Epoch 791/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3790 - accuracy: 0.8254 - val_loss: 0.4995 - val_accuracy: 0.7664\n",
      "Epoch 792/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3788 - accuracy: 0.8257 - val_loss: 0.4947 - val_accuracy: 0.7645\n",
      "Epoch 793/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3791 - accuracy: 0.8247 - val_loss: 0.5003 - val_accuracy: 0.7630\n",
      "Epoch 794/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3789 - accuracy: 0.8266 - val_loss: 0.5080 - val_accuracy: 0.7602\n",
      "Epoch 795/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3785 - accuracy: 0.8266 - val_loss: 0.5018 - val_accuracy: 0.7621\n",
      "Epoch 796/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3794 - accuracy: 0.8266 - val_loss: 0.4981 - val_accuracy: 0.7687\n",
      "Epoch 797/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3784 - accuracy: 0.8265 - val_loss: 0.4988 - val_accuracy: 0.7640\n",
      "Epoch 798/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3793 - accuracy: 0.8251 - val_loss: 0.4990 - val_accuracy: 0.7659\n",
      "Epoch 799/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3788 - accuracy: 0.8251 - val_loss: 0.4948 - val_accuracy: 0.7706\n",
      "Epoch 800/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3790 - accuracy: 0.8265 - val_loss: 0.5099 - val_accuracy: 0.7597\n",
      "Epoch 801/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3792 - accuracy: 0.8240 - val_loss: 0.4932 - val_accuracy: 0.7701\n",
      "Epoch 802/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3788 - accuracy: 0.8251 - val_loss: 0.4916 - val_accuracy: 0.7692\n",
      "Epoch 803/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3784 - accuracy: 0.8264 - val_loss: 0.4951 - val_accuracy: 0.7673\n",
      "Epoch 804/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3787 - accuracy: 0.8239 - val_loss: 0.4906 - val_accuracy: 0.7678\n",
      "Epoch 805/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3791 - accuracy: 0.8271 - val_loss: 0.5024 - val_accuracy: 0.7602\n",
      "Epoch 806/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3790 - accuracy: 0.8253 - val_loss: 0.5014 - val_accuracy: 0.7659\n",
      "Epoch 807/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3789 - accuracy: 0.8253 - val_loss: 0.4966 - val_accuracy: 0.7659\n",
      "Epoch 808/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3787 - accuracy: 0.8253 - val_loss: 0.5010 - val_accuracy: 0.7635\n",
      "Epoch 809/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3787 - accuracy: 0.8253 - val_loss: 0.4996 - val_accuracy: 0.7635\n",
      "Epoch 810/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3789 - accuracy: 0.8265 - val_loss: 0.4987 - val_accuracy: 0.7668\n",
      "Epoch 811/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3787 - accuracy: 0.8266 - val_loss: 0.4977 - val_accuracy: 0.7611\n",
      "Epoch 812/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3788 - accuracy: 0.8244 - val_loss: 0.4939 - val_accuracy: 0.7701\n",
      "Epoch 813/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3785 - accuracy: 0.8260 - val_loss: 0.4963 - val_accuracy: 0.7716\n",
      "Epoch 814/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3788 - accuracy: 0.8251 - val_loss: 0.4956 - val_accuracy: 0.7664\n",
      "Epoch 815/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3789 - accuracy: 0.8254 - val_loss: 0.4946 - val_accuracy: 0.7687\n",
      "Epoch 816/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3787 - accuracy: 0.8247 - val_loss: 0.4971 - val_accuracy: 0.7668\n",
      "Epoch 817/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3790 - accuracy: 0.8268 - val_loss: 0.4980 - val_accuracy: 0.7687\n",
      "Epoch 818/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3789 - accuracy: 0.8246 - val_loss: 0.5046 - val_accuracy: 0.7630\n",
      "Epoch 819/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3789 - accuracy: 0.8255 - val_loss: 0.5101 - val_accuracy: 0.7578\n",
      "Epoch 820/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3787 - accuracy: 0.8262 - val_loss: 0.5031 - val_accuracy: 0.7578\n",
      "Epoch 821/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3783 - accuracy: 0.8246 - val_loss: 0.4920 - val_accuracy: 0.7687\n",
      "Epoch 822/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3783 - accuracy: 0.8257 - val_loss: 0.5042 - val_accuracy: 0.7635\n",
      "Epoch 823/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3789 - accuracy: 0.8251 - val_loss: 0.4930 - val_accuracy: 0.7678\n",
      "Epoch 824/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3787 - accuracy: 0.8250 - val_loss: 0.5020 - val_accuracy: 0.7640\n",
      "Epoch 825/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3788 - accuracy: 0.8260 - val_loss: 0.4972 - val_accuracy: 0.7701\n",
      "Epoch 826/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3785 - accuracy: 0.8273 - val_loss: 0.4929 - val_accuracy: 0.7664\n",
      "Epoch 827/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3785 - accuracy: 0.8237 - val_loss: 0.4957 - val_accuracy: 0.7668\n",
      "Epoch 828/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3785 - accuracy: 0.8253 - val_loss: 0.5017 - val_accuracy: 0.7645\n",
      "Epoch 829/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3782 - accuracy: 0.8260 - val_loss: 0.4817 - val_accuracy: 0.7739\n",
      "Epoch 830/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3787 - accuracy: 0.8254 - val_loss: 0.4960 - val_accuracy: 0.7649\n",
      "Epoch 831/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3788 - accuracy: 0.8246 - val_loss: 0.4922 - val_accuracy: 0.7711\n",
      "Epoch 832/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3784 - accuracy: 0.8278 - val_loss: 0.4997 - val_accuracy: 0.7697\n",
      "Epoch 833/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3783 - accuracy: 0.8257 - val_loss: 0.5007 - val_accuracy: 0.7678\n",
      "Epoch 834/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3786 - accuracy: 0.8264 - val_loss: 0.4938 - val_accuracy: 0.7654\n",
      "Epoch 835/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3787 - accuracy: 0.8257 - val_loss: 0.4984 - val_accuracy: 0.7668\n",
      "Epoch 836/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3783 - accuracy: 0.8266 - val_loss: 0.4945 - val_accuracy: 0.7725\n",
      "Epoch 837/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3783 - accuracy: 0.8251 - val_loss: 0.5099 - val_accuracy: 0.7573\n",
      "Epoch 838/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3783 - accuracy: 0.8264 - val_loss: 0.4967 - val_accuracy: 0.7664\n",
      "Epoch 839/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3783 - accuracy: 0.8272 - val_loss: 0.4955 - val_accuracy: 0.7692\n",
      "Epoch 840/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3786 - accuracy: 0.8258 - val_loss: 0.5023 - val_accuracy: 0.7664\n",
      "Epoch 841/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3782 - accuracy: 0.8253 - val_loss: 0.4919 - val_accuracy: 0.7673\n",
      "Epoch 842/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3779 - accuracy: 0.8261 - val_loss: 0.4968 - val_accuracy: 0.7697\n",
      "Epoch 843/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3786 - accuracy: 0.8261 - val_loss: 0.4948 - val_accuracy: 0.7701\n",
      "Epoch 844/1500\n",
      "226/226 [==============================] - 3s 11ms/step - loss: 0.3788 - accuracy: 0.8248 - val_loss: 0.5016 - val_accuracy: 0.7654\n",
      "Epoch 845/1500\n",
      "226/226 [==============================] - 3s 11ms/step - loss: 0.3783 - accuracy: 0.8258 - val_loss: 0.4914 - val_accuracy: 0.7673\n",
      "Epoch 846/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3781 - accuracy: 0.8248 - val_loss: 0.4930 - val_accuracy: 0.7682\n",
      "Epoch 847/1500\n",
      "226/226 [==============================] - 3s 13ms/step - loss: 0.3784 - accuracy: 0.8254 - val_loss: 0.4940 - val_accuracy: 0.7701\n",
      "Epoch 848/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3781 - accuracy: 0.8240 - val_loss: 0.5070 - val_accuracy: 0.7602\n",
      "Epoch 849/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3786 - accuracy: 0.8260 - val_loss: 0.4960 - val_accuracy: 0.7682\n",
      "Epoch 850/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3786 - accuracy: 0.8247 - val_loss: 0.4985 - val_accuracy: 0.7640\n",
      "Epoch 851/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3782 - accuracy: 0.8262 - val_loss: 0.4993 - val_accuracy: 0.7649\n",
      "Epoch 852/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3784 - accuracy: 0.8258 - val_loss: 0.5061 - val_accuracy: 0.7602\n",
      "Epoch 853/1500\n",
      "226/226 [==============================] - 3s 11ms/step - loss: 0.3782 - accuracy: 0.8247 - val_loss: 0.4954 - val_accuracy: 0.7697\n",
      "Epoch 854/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3784 - accuracy: 0.8244 - val_loss: 0.5009 - val_accuracy: 0.7664\n",
      "Epoch 855/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3784 - accuracy: 0.8264 - val_loss: 0.4973 - val_accuracy: 0.7697\n",
      "Epoch 856/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3785 - accuracy: 0.8239 - val_loss: 0.4971 - val_accuracy: 0.7635\n",
      "Epoch 857/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3786 - accuracy: 0.8264 - val_loss: 0.4886 - val_accuracy: 0.7711\n",
      "Epoch 858/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3779 - accuracy: 0.8254 - val_loss: 0.4896 - val_accuracy: 0.7711\n",
      "Epoch 859/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3785 - accuracy: 0.8257 - val_loss: 0.4917 - val_accuracy: 0.7706\n",
      "Epoch 860/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3784 - accuracy: 0.8258 - val_loss: 0.4936 - val_accuracy: 0.7659\n",
      "Epoch 861/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3783 - accuracy: 0.8233 - val_loss: 0.5009 - val_accuracy: 0.7616\n",
      "Epoch 862/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3782 - accuracy: 0.8253 - val_loss: 0.4950 - val_accuracy: 0.7649\n",
      "Epoch 863/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3782 - accuracy: 0.8250 - val_loss: 0.4958 - val_accuracy: 0.7673\n",
      "Epoch 864/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3781 - accuracy: 0.8257 - val_loss: 0.4988 - val_accuracy: 0.7621\n",
      "Epoch 865/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3784 - accuracy: 0.8248 - val_loss: 0.4905 - val_accuracy: 0.7701\n",
      "Epoch 866/1500\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.3784 - accuracy: 0.8265 - val_loss: 0.4957 - val_accuracy: 0.7682\n",
      "Epoch 867/1500\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.3781 - accuracy: 0.8253 - val_loss: 0.5057 - val_accuracy: 0.7583\n",
      "Epoch 868/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3785 - accuracy: 0.8247 - val_loss: 0.5009 - val_accuracy: 0.7640\n",
      "Epoch 869/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3781 - accuracy: 0.8265 - val_loss: 0.4926 - val_accuracy: 0.7720\n",
      "Epoch 870/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3779 - accuracy: 0.8258 - val_loss: 0.4983 - val_accuracy: 0.7635\n",
      "Epoch 871/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3781 - accuracy: 0.8260 - val_loss: 0.4950 - val_accuracy: 0.7664\n",
      "Epoch 872/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3780 - accuracy: 0.8261 - val_loss: 0.4952 - val_accuracy: 0.7682\n",
      "Epoch 873/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3779 - accuracy: 0.8255 - val_loss: 0.5079 - val_accuracy: 0.7626\n",
      "Epoch 874/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3786 - accuracy: 0.8243 - val_loss: 0.5005 - val_accuracy: 0.7640\n",
      "Epoch 875/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3778 - accuracy: 0.8251 - val_loss: 0.4895 - val_accuracy: 0.7754\n",
      "Epoch 876/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3780 - accuracy: 0.8262 - val_loss: 0.4903 - val_accuracy: 0.7701\n",
      "Epoch 877/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3781 - accuracy: 0.8260 - val_loss: 0.4997 - val_accuracy: 0.7621\n",
      "Epoch 878/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3785 - accuracy: 0.8258 - val_loss: 0.4932 - val_accuracy: 0.7668\n",
      "Epoch 879/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3784 - accuracy: 0.8240 - val_loss: 0.4969 - val_accuracy: 0.7654\n",
      "Epoch 880/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3779 - accuracy: 0.8225 - val_loss: 0.5013 - val_accuracy: 0.7678\n",
      "Epoch 881/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3785 - accuracy: 0.8254 - val_loss: 0.4908 - val_accuracy: 0.7697\n",
      "Epoch 882/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3779 - accuracy: 0.8244 - val_loss: 0.4926 - val_accuracy: 0.7687\n",
      "Epoch 883/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3778 - accuracy: 0.8260 - val_loss: 0.5105 - val_accuracy: 0.7569\n",
      "Epoch 884/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3785 - accuracy: 0.8261 - val_loss: 0.4945 - val_accuracy: 0.7664\n",
      "Epoch 885/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3781 - accuracy: 0.8232 - val_loss: 0.4984 - val_accuracy: 0.7621\n",
      "Epoch 886/1500\n",
      "226/226 [==============================] - 3s 13ms/step - loss: 0.3776 - accuracy: 0.8273 - val_loss: 0.5015 - val_accuracy: 0.7630\n",
      "Epoch 887/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3775 - accuracy: 0.8240 - val_loss: 0.5018 - val_accuracy: 0.7664\n",
      "Epoch 888/1500\n",
      "226/226 [==============================] - 3s 11ms/step - loss: 0.3778 - accuracy: 0.8262 - val_loss: 0.5014 - val_accuracy: 0.7654\n",
      "Epoch 889/1500\n",
      "226/226 [==============================] - 3s 11ms/step - loss: 0.3783 - accuracy: 0.8261 - val_loss: 0.4978 - val_accuracy: 0.7701\n",
      "Epoch 890/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3781 - accuracy: 0.8248 - val_loss: 0.4939 - val_accuracy: 0.7687\n",
      "Epoch 891/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3777 - accuracy: 0.8261 - val_loss: 0.4946 - val_accuracy: 0.7706\n",
      "Epoch 892/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3780 - accuracy: 0.8251 - val_loss: 0.4898 - val_accuracy: 0.7678\n",
      "Epoch 893/1500\n",
      "226/226 [==============================] - 3s 11ms/step - loss: 0.3778 - accuracy: 0.8236 - val_loss: 0.4970 - val_accuracy: 0.7645\n",
      "Epoch 894/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3779 - accuracy: 0.8268 - val_loss: 0.4899 - val_accuracy: 0.7692\n",
      "Epoch 895/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3775 - accuracy: 0.8261 - val_loss: 0.4922 - val_accuracy: 0.7692\n",
      "Epoch 896/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3780 - accuracy: 0.8248 - val_loss: 0.4962 - val_accuracy: 0.7664\n",
      "Epoch 897/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3779 - accuracy: 0.8239 - val_loss: 0.4956 - val_accuracy: 0.7673\n",
      "Epoch 898/1500\n",
      "226/226 [==============================] - 3s 13ms/step - loss: 0.3781 - accuracy: 0.8257 - val_loss: 0.4964 - val_accuracy: 0.7649\n",
      "Epoch 899/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3778 - accuracy: 0.8258 - val_loss: 0.4967 - val_accuracy: 0.7621\n",
      "Epoch 900/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3782 - accuracy: 0.8250 - val_loss: 0.5024 - val_accuracy: 0.7626\n",
      "Epoch 901/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3781 - accuracy: 0.8242 - val_loss: 0.4978 - val_accuracy: 0.7621\n",
      "Epoch 902/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3777 - accuracy: 0.8229 - val_loss: 0.4950 - val_accuracy: 0.7682\n",
      "Epoch 903/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3780 - accuracy: 0.8272 - val_loss: 0.4931 - val_accuracy: 0.7687\n",
      "Epoch 904/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3779 - accuracy: 0.8250 - val_loss: 0.4913 - val_accuracy: 0.7720\n",
      "Epoch 905/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3778 - accuracy: 0.8262 - val_loss: 0.4927 - val_accuracy: 0.7706\n",
      "Epoch 906/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3776 - accuracy: 0.8251 - val_loss: 0.4959 - val_accuracy: 0.7659\n",
      "Epoch 907/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3778 - accuracy: 0.8265 - val_loss: 0.4996 - val_accuracy: 0.7682\n",
      "Epoch 908/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3778 - accuracy: 0.8273 - val_loss: 0.4979 - val_accuracy: 0.7664\n",
      "Epoch 909/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3781 - accuracy: 0.8243 - val_loss: 0.4984 - val_accuracy: 0.7649\n",
      "Epoch 910/1500\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.3779 - accuracy: 0.8262 - val_loss: 0.4966 - val_accuracy: 0.7645\n",
      "Epoch 911/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3774 - accuracy: 0.8268 - val_loss: 0.4940 - val_accuracy: 0.7640\n",
      "Epoch 912/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3782 - accuracy: 0.8261 - val_loss: 0.5004 - val_accuracy: 0.7578\n",
      "Epoch 913/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3777 - accuracy: 0.8265 - val_loss: 0.4969 - val_accuracy: 0.7668\n",
      "Epoch 914/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3777 - accuracy: 0.8255 - val_loss: 0.4952 - val_accuracy: 0.7607\n",
      "Epoch 915/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3780 - accuracy: 0.8254 - val_loss: 0.4995 - val_accuracy: 0.7649\n",
      "Epoch 916/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3780 - accuracy: 0.8255 - val_loss: 0.4973 - val_accuracy: 0.7635\n",
      "Epoch 917/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3777 - accuracy: 0.8229 - val_loss: 0.5054 - val_accuracy: 0.7621\n",
      "Epoch 918/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3778 - accuracy: 0.8254 - val_loss: 0.4963 - val_accuracy: 0.7668\n",
      "Epoch 919/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3779 - accuracy: 0.8261 - val_loss: 0.4935 - val_accuracy: 0.7711\n",
      "Epoch 920/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3779 - accuracy: 0.8268 - val_loss: 0.4968 - val_accuracy: 0.7640\n",
      "Epoch 921/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3775 - accuracy: 0.8278 - val_loss: 0.4937 - val_accuracy: 0.7645\n",
      "Epoch 922/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3776 - accuracy: 0.8269 - val_loss: 0.5003 - val_accuracy: 0.7630\n",
      "Epoch 923/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3774 - accuracy: 0.8254 - val_loss: 0.5046 - val_accuracy: 0.7607\n",
      "Epoch 924/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3775 - accuracy: 0.8243 - val_loss: 0.5041 - val_accuracy: 0.7635\n",
      "Epoch 925/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3776 - accuracy: 0.8262 - val_loss: 0.4885 - val_accuracy: 0.7701\n",
      "Epoch 926/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3781 - accuracy: 0.8255 - val_loss: 0.4947 - val_accuracy: 0.7645\n",
      "Epoch 927/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3775 - accuracy: 0.8261 - val_loss: 0.4988 - val_accuracy: 0.7649\n",
      "Epoch 928/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3778 - accuracy: 0.8250 - val_loss: 0.5033 - val_accuracy: 0.7654\n",
      "Epoch 929/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3778 - accuracy: 0.8261 - val_loss: 0.5006 - val_accuracy: 0.7621\n",
      "Epoch 930/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3778 - accuracy: 0.8279 - val_loss: 0.5039 - val_accuracy: 0.7664\n",
      "Epoch 931/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3775 - accuracy: 0.8264 - val_loss: 0.4985 - val_accuracy: 0.7649\n",
      "Epoch 932/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3781 - accuracy: 0.8260 - val_loss: 0.4962 - val_accuracy: 0.7649\n",
      "Epoch 933/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3778 - accuracy: 0.8253 - val_loss: 0.5061 - val_accuracy: 0.7607\n",
      "Epoch 934/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3775 - accuracy: 0.8239 - val_loss: 0.4955 - val_accuracy: 0.7687\n",
      "Epoch 935/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3777 - accuracy: 0.8265 - val_loss: 0.4900 - val_accuracy: 0.7701\n",
      "Epoch 936/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3775 - accuracy: 0.8264 - val_loss: 0.5029 - val_accuracy: 0.7630\n",
      "Epoch 937/1500\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.3779 - accuracy: 0.8251 - val_loss: 0.4971 - val_accuracy: 0.7630\n",
      "Epoch 938/1500\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.3777 - accuracy: 0.8254 - val_loss: 0.4925 - val_accuracy: 0.7716\n",
      "Epoch 939/1500\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.3779 - accuracy: 0.8246 - val_loss: 0.4970 - val_accuracy: 0.7673\n",
      "Epoch 940/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3774 - accuracy: 0.8264 - val_loss: 0.4929 - val_accuracy: 0.7687\n",
      "Epoch 941/1500\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.3773 - accuracy: 0.8258 - val_loss: 0.5120 - val_accuracy: 0.7592\n",
      "Epoch 942/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3776 - accuracy: 0.8262 - val_loss: 0.4910 - val_accuracy: 0.7664\n",
      "Epoch 943/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3775 - accuracy: 0.8242 - val_loss: 0.5051 - val_accuracy: 0.7630\n",
      "Epoch 944/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3772 - accuracy: 0.8254 - val_loss: 0.5025 - val_accuracy: 0.7659\n",
      "Epoch 945/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3773 - accuracy: 0.8248 - val_loss: 0.4993 - val_accuracy: 0.7640\n",
      "Epoch 946/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3773 - accuracy: 0.8262 - val_loss: 0.5016 - val_accuracy: 0.7621\n",
      "Epoch 947/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3771 - accuracy: 0.8260 - val_loss: 0.5031 - val_accuracy: 0.7635\n",
      "Epoch 948/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3773 - accuracy: 0.8258 - val_loss: 0.5044 - val_accuracy: 0.7602\n",
      "Epoch 949/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3770 - accuracy: 0.8264 - val_loss: 0.4982 - val_accuracy: 0.7673\n",
      "Epoch 950/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3778 - accuracy: 0.8225 - val_loss: 0.4988 - val_accuracy: 0.7649\n",
      "Epoch 951/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3776 - accuracy: 0.8271 - val_loss: 0.4957 - val_accuracy: 0.7678\n",
      "Epoch 952/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3776 - accuracy: 0.8269 - val_loss: 0.5003 - val_accuracy: 0.7668\n",
      "Epoch 953/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3776 - accuracy: 0.8239 - val_loss: 0.4908 - val_accuracy: 0.7687\n",
      "Epoch 954/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3775 - accuracy: 0.8265 - val_loss: 0.4946 - val_accuracy: 0.7640\n",
      "Epoch 955/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3773 - accuracy: 0.8226 - val_loss: 0.5007 - val_accuracy: 0.7626\n",
      "Epoch 956/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3776 - accuracy: 0.8242 - val_loss: 0.4958 - val_accuracy: 0.7673\n",
      "Epoch 957/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3774 - accuracy: 0.8253 - val_loss: 0.5059 - val_accuracy: 0.7616\n",
      "Epoch 958/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3775 - accuracy: 0.8275 - val_loss: 0.4993 - val_accuracy: 0.7616\n",
      "Epoch 959/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3769 - accuracy: 0.8251 - val_loss: 0.4954 - val_accuracy: 0.7673\n",
      "Epoch 960/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3773 - accuracy: 0.8257 - val_loss: 0.5029 - val_accuracy: 0.7602\n",
      "Epoch 961/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3773 - accuracy: 0.8266 - val_loss: 0.4927 - val_accuracy: 0.7687\n",
      "Epoch 962/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3773 - accuracy: 0.8264 - val_loss: 0.5022 - val_accuracy: 0.7664\n",
      "Epoch 963/1500\n",
      "226/226 [==============================] - 3s 11ms/step - loss: 0.3772 - accuracy: 0.8273 - val_loss: 0.4960 - val_accuracy: 0.7678\n",
      "Epoch 964/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3776 - accuracy: 0.8248 - val_loss: 0.4936 - val_accuracy: 0.7673\n",
      "Epoch 965/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3770 - accuracy: 0.8268 - val_loss: 0.5118 - val_accuracy: 0.7569\n",
      "Epoch 966/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3775 - accuracy: 0.8266 - val_loss: 0.5038 - val_accuracy: 0.7635\n",
      "Epoch 967/1500\n",
      "226/226 [==============================] - 3s 11ms/step - loss: 0.3773 - accuracy: 0.8248 - val_loss: 0.5002 - val_accuracy: 0.7649\n",
      "Epoch 968/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3775 - accuracy: 0.8243 - val_loss: 0.5037 - val_accuracy: 0.7597\n",
      "Epoch 969/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3776 - accuracy: 0.8283 - val_loss: 0.4943 - val_accuracy: 0.7673\n",
      "Epoch 970/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3772 - accuracy: 0.8266 - val_loss: 0.5006 - val_accuracy: 0.7692\n",
      "Epoch 971/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3770 - accuracy: 0.8275 - val_loss: 0.4999 - val_accuracy: 0.7602\n",
      "Epoch 972/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3771 - accuracy: 0.8254 - val_loss: 0.4954 - val_accuracy: 0.7668\n",
      "Epoch 973/1500\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.3769 - accuracy: 0.8243 - val_loss: 0.4891 - val_accuracy: 0.7735\n",
      "Epoch 974/1500\n",
      "226/226 [==============================] - 3s 11ms/step - loss: 0.3771 - accuracy: 0.8246 - val_loss: 0.4983 - val_accuracy: 0.7654\n",
      "Epoch 975/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3774 - accuracy: 0.8243 - val_loss: 0.5007 - val_accuracy: 0.7630\n",
      "Epoch 976/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3775 - accuracy: 0.8239 - val_loss: 0.4989 - val_accuracy: 0.7659\n",
      "Epoch 977/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3771 - accuracy: 0.8255 - val_loss: 0.4999 - val_accuracy: 0.7635\n",
      "Epoch 978/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3768 - accuracy: 0.8273 - val_loss: 0.4959 - val_accuracy: 0.7611\n",
      "Epoch 979/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3771 - accuracy: 0.8247 - val_loss: 0.4966 - val_accuracy: 0.7673\n",
      "Epoch 980/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3772 - accuracy: 0.8272 - val_loss: 0.5023 - val_accuracy: 0.7645\n",
      "Epoch 981/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3774 - accuracy: 0.8269 - val_loss: 0.5000 - val_accuracy: 0.7592\n",
      "Epoch 982/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3773 - accuracy: 0.8269 - val_loss: 0.5061 - val_accuracy: 0.7611\n",
      "Epoch 983/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3768 - accuracy: 0.8265 - val_loss: 0.4946 - val_accuracy: 0.7630\n",
      "Epoch 984/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3775 - accuracy: 0.8254 - val_loss: 0.4968 - val_accuracy: 0.7630\n",
      "Epoch 985/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3772 - accuracy: 0.8254 - val_loss: 0.4896 - val_accuracy: 0.7720\n",
      "Epoch 986/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3770 - accuracy: 0.8266 - val_loss: 0.5026 - val_accuracy: 0.7664\n",
      "Epoch 987/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3769 - accuracy: 0.8242 - val_loss: 0.4966 - val_accuracy: 0.7687\n",
      "Epoch 988/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3773 - accuracy: 0.8255 - val_loss: 0.5030 - val_accuracy: 0.7654\n",
      "Epoch 989/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3773 - accuracy: 0.8269 - val_loss: 0.4967 - val_accuracy: 0.7664\n",
      "Epoch 990/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3774 - accuracy: 0.8260 - val_loss: 0.4949 - val_accuracy: 0.7654\n",
      "Epoch 991/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3771 - accuracy: 0.8236 - val_loss: 0.5034 - val_accuracy: 0.7592\n",
      "Epoch 992/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3769 - accuracy: 0.8278 - val_loss: 0.4962 - val_accuracy: 0.7640\n",
      "Epoch 993/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3769 - accuracy: 0.8255 - val_loss: 0.5032 - val_accuracy: 0.7649\n",
      "Epoch 994/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3769 - accuracy: 0.8271 - val_loss: 0.4992 - val_accuracy: 0.7611\n",
      "Epoch 995/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3774 - accuracy: 0.8271 - val_loss: 0.4953 - val_accuracy: 0.7664\n",
      "Epoch 996/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3771 - accuracy: 0.8268 - val_loss: 0.5001 - val_accuracy: 0.7635\n",
      "Epoch 997/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3770 - accuracy: 0.8253 - val_loss: 0.4949 - val_accuracy: 0.7668\n",
      "Epoch 998/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3769 - accuracy: 0.8240 - val_loss: 0.5022 - val_accuracy: 0.7678\n",
      "Epoch 999/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3769 - accuracy: 0.8246 - val_loss: 0.4962 - val_accuracy: 0.7673\n",
      "Epoch 1000/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3765 - accuracy: 0.8264 - val_loss: 0.5070 - val_accuracy: 0.7640\n",
      "Epoch 1001/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3772 - accuracy: 0.8269 - val_loss: 0.4987 - val_accuracy: 0.7678\n",
      "Epoch 1002/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3766 - accuracy: 0.8269 - val_loss: 0.5066 - val_accuracy: 0.7597\n",
      "Epoch 1003/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3773 - accuracy: 0.8261 - val_loss: 0.4939 - val_accuracy: 0.7697\n",
      "Epoch 1004/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3770 - accuracy: 0.8258 - val_loss: 0.4974 - val_accuracy: 0.7654\n",
      "Epoch 1005/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3767 - accuracy: 0.8250 - val_loss: 0.5012 - val_accuracy: 0.7597\n",
      "Epoch 1006/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3770 - accuracy: 0.8261 - val_loss: 0.4997 - val_accuracy: 0.7630\n",
      "Epoch 1007/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3767 - accuracy: 0.8255 - val_loss: 0.4913 - val_accuracy: 0.7668\n",
      "Epoch 1008/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3770 - accuracy: 0.8269 - val_loss: 0.4898 - val_accuracy: 0.7678\n",
      "Epoch 1009/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3766 - accuracy: 0.8271 - val_loss: 0.4980 - val_accuracy: 0.7673\n",
      "Epoch 1010/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3767 - accuracy: 0.8265 - val_loss: 0.4970 - val_accuracy: 0.7649\n",
      "Epoch 1011/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3770 - accuracy: 0.8251 - val_loss: 0.4952 - val_accuracy: 0.7697\n",
      "Epoch 1012/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3769 - accuracy: 0.8286 - val_loss: 0.5038 - val_accuracy: 0.7597\n",
      "Epoch 1013/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3773 - accuracy: 0.8251 - val_loss: 0.4978 - val_accuracy: 0.7668\n",
      "Epoch 1014/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3769 - accuracy: 0.8269 - val_loss: 0.4959 - val_accuracy: 0.7630\n",
      "Epoch 1015/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3770 - accuracy: 0.8275 - val_loss: 0.4998 - val_accuracy: 0.7659\n",
      "Epoch 1016/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3768 - accuracy: 0.8260 - val_loss: 0.4973 - val_accuracy: 0.7673\n",
      "Epoch 1017/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3768 - accuracy: 0.8261 - val_loss: 0.5043 - val_accuracy: 0.7607\n",
      "Epoch 1018/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3771 - accuracy: 0.8264 - val_loss: 0.5056 - val_accuracy: 0.7607\n",
      "Epoch 1019/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3773 - accuracy: 0.8258 - val_loss: 0.5002 - val_accuracy: 0.7649\n",
      "Epoch 1020/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3771 - accuracy: 0.8254 - val_loss: 0.5015 - val_accuracy: 0.7668\n",
      "Epoch 1021/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3771 - accuracy: 0.8273 - val_loss: 0.5036 - val_accuracy: 0.7682\n",
      "Epoch 1022/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3766 - accuracy: 0.8272 - val_loss: 0.5007 - val_accuracy: 0.7697\n",
      "Epoch 1023/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3768 - accuracy: 0.8276 - val_loss: 0.5050 - val_accuracy: 0.7668\n",
      "Epoch 1024/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3769 - accuracy: 0.8257 - val_loss: 0.4980 - val_accuracy: 0.7682\n",
      "Epoch 1025/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3768 - accuracy: 0.8240 - val_loss: 0.4924 - val_accuracy: 0.7711\n",
      "Epoch 1026/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3766 - accuracy: 0.8251 - val_loss: 0.5134 - val_accuracy: 0.7592\n",
      "Epoch 1027/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3769 - accuracy: 0.8282 - val_loss: 0.4958 - val_accuracy: 0.7630\n",
      "Epoch 1028/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3769 - accuracy: 0.8264 - val_loss: 0.4996 - val_accuracy: 0.7668\n",
      "Epoch 1029/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3768 - accuracy: 0.8266 - val_loss: 0.5037 - val_accuracy: 0.7654\n",
      "Epoch 1030/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3765 - accuracy: 0.8255 - val_loss: 0.4924 - val_accuracy: 0.7668\n",
      "Epoch 1031/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3769 - accuracy: 0.8276 - val_loss: 0.4940 - val_accuracy: 0.7678\n",
      "Epoch 1032/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3770 - accuracy: 0.8278 - val_loss: 0.4962 - val_accuracy: 0.7687\n",
      "Epoch 1033/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3769 - accuracy: 0.8242 - val_loss: 0.4999 - val_accuracy: 0.7664\n",
      "Epoch 1034/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3770 - accuracy: 0.8248 - val_loss: 0.5034 - val_accuracy: 0.7649\n",
      "Epoch 1035/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3767 - accuracy: 0.8261 - val_loss: 0.4848 - val_accuracy: 0.7749\n",
      "Epoch 1036/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3768 - accuracy: 0.8282 - val_loss: 0.4954 - val_accuracy: 0.7682\n",
      "Epoch 1037/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3767 - accuracy: 0.8265 - val_loss: 0.5018 - val_accuracy: 0.7673\n",
      "Epoch 1038/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3769 - accuracy: 0.8247 - val_loss: 0.5019 - val_accuracy: 0.7664\n",
      "Epoch 1039/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3768 - accuracy: 0.8265 - val_loss: 0.4974 - val_accuracy: 0.7649\n",
      "Epoch 1040/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3770 - accuracy: 0.8261 - val_loss: 0.4987 - val_accuracy: 0.7682\n",
      "Epoch 1041/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3769 - accuracy: 0.8266 - val_loss: 0.5024 - val_accuracy: 0.7654\n",
      "Epoch 1042/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3767 - accuracy: 0.8260 - val_loss: 0.5007 - val_accuracy: 0.7645\n",
      "Epoch 1043/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3769 - accuracy: 0.8262 - val_loss: 0.5037 - val_accuracy: 0.7621\n",
      "Epoch 1044/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3768 - accuracy: 0.8273 - val_loss: 0.5056 - val_accuracy: 0.7621\n",
      "Epoch 1045/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3770 - accuracy: 0.8276 - val_loss: 0.4959 - val_accuracy: 0.7664\n",
      "Epoch 1046/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3767 - accuracy: 0.8283 - val_loss: 0.5061 - val_accuracy: 0.7640\n",
      "Epoch 1047/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3770 - accuracy: 0.8254 - val_loss: 0.4988 - val_accuracy: 0.7668\n",
      "Epoch 1048/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3764 - accuracy: 0.8265 - val_loss: 0.4966 - val_accuracy: 0.7654\n",
      "Epoch 1049/1500\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.3770 - accuracy: 0.8275 - val_loss: 0.4996 - val_accuracy: 0.7678\n",
      "Epoch 1050/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3767 - accuracy: 0.8264 - val_loss: 0.4931 - val_accuracy: 0.7716\n",
      "Epoch 1051/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3766 - accuracy: 0.8257 - val_loss: 0.4969 - val_accuracy: 0.7687\n",
      "Epoch 1052/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3769 - accuracy: 0.8257 - val_loss: 0.4913 - val_accuracy: 0.7678\n",
      "Epoch 1053/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3771 - accuracy: 0.8264 - val_loss: 0.4964 - val_accuracy: 0.7678\n",
      "Epoch 1054/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3768 - accuracy: 0.8279 - val_loss: 0.5053 - val_accuracy: 0.7607\n",
      "Epoch 1055/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3770 - accuracy: 0.8273 - val_loss: 0.5098 - val_accuracy: 0.7611\n",
      "Epoch 1056/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3767 - accuracy: 0.8271 - val_loss: 0.5044 - val_accuracy: 0.7649\n",
      "Epoch 1057/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3766 - accuracy: 0.8257 - val_loss: 0.4974 - val_accuracy: 0.7659\n",
      "Epoch 1058/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3770 - accuracy: 0.8275 - val_loss: 0.4936 - val_accuracy: 0.7697\n",
      "Epoch 1059/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3766 - accuracy: 0.8275 - val_loss: 0.4991 - val_accuracy: 0.7635\n",
      "Epoch 1060/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3766 - accuracy: 0.8261 - val_loss: 0.4974 - val_accuracy: 0.7668\n",
      "Epoch 1061/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3770 - accuracy: 0.8286 - val_loss: 0.4943 - val_accuracy: 0.7645\n",
      "Epoch 1062/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3763 - accuracy: 0.8266 - val_loss: 0.5108 - val_accuracy: 0.7659\n",
      "Epoch 1063/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3762 - accuracy: 0.8262 - val_loss: 0.5004 - val_accuracy: 0.7664\n",
      "Epoch 1064/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3765 - accuracy: 0.8265 - val_loss: 0.4996 - val_accuracy: 0.7611\n",
      "Epoch 1065/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3762 - accuracy: 0.8257 - val_loss: 0.4950 - val_accuracy: 0.7687\n",
      "Epoch 1066/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3764 - accuracy: 0.8282 - val_loss: 0.4953 - val_accuracy: 0.7678\n",
      "Epoch 1067/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3767 - accuracy: 0.8266 - val_loss: 0.4987 - val_accuracy: 0.7630\n",
      "Epoch 1068/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3766 - accuracy: 0.8258 - val_loss: 0.4954 - val_accuracy: 0.7654\n",
      "Epoch 1069/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3763 - accuracy: 0.8275 - val_loss: 0.5017 - val_accuracy: 0.7621\n",
      "Epoch 1070/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3766 - accuracy: 0.8257 - val_loss: 0.4950 - val_accuracy: 0.7654\n",
      "Epoch 1071/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3764 - accuracy: 0.8254 - val_loss: 0.5019 - val_accuracy: 0.7654\n",
      "Epoch 1072/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3764 - accuracy: 0.8248 - val_loss: 0.4995 - val_accuracy: 0.7645\n",
      "Epoch 1073/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3766 - accuracy: 0.8261 - val_loss: 0.5010 - val_accuracy: 0.7668\n",
      "Epoch 1074/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3766 - accuracy: 0.8278 - val_loss: 0.5022 - val_accuracy: 0.7630\n",
      "Epoch 1075/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3759 - accuracy: 0.8269 - val_loss: 0.4988 - val_accuracy: 0.7659\n",
      "Epoch 1076/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3770 - accuracy: 0.8253 - val_loss: 0.5008 - val_accuracy: 0.7630\n",
      "Epoch 1077/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3760 - accuracy: 0.8253 - val_loss: 0.5083 - val_accuracy: 0.7640\n",
      "Epoch 1078/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3766 - accuracy: 0.8276 - val_loss: 0.4971 - val_accuracy: 0.7692\n",
      "Epoch 1079/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3767 - accuracy: 0.8244 - val_loss: 0.4919 - val_accuracy: 0.7711\n",
      "Epoch 1080/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3767 - accuracy: 0.8264 - val_loss: 0.5050 - val_accuracy: 0.7635\n",
      "Epoch 1081/1500\n",
      "226/226 [==============================] - 3s 11ms/step - loss: 0.3766 - accuracy: 0.8248 - val_loss: 0.4998 - val_accuracy: 0.7664\n",
      "Epoch 1082/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3766 - accuracy: 0.8250 - val_loss: 0.4936 - val_accuracy: 0.7706\n",
      "Epoch 1083/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3763 - accuracy: 0.8272 - val_loss: 0.4990 - val_accuracy: 0.7711\n",
      "Epoch 1084/1500\n",
      "226/226 [==============================] - 2s 10ms/step - loss: 0.3756 - accuracy: 0.8280 - val_loss: 0.4934 - val_accuracy: 0.7673\n",
      "Epoch 1085/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3764 - accuracy: 0.8261 - val_loss: 0.4973 - val_accuracy: 0.7640\n",
      "Epoch 1086/1500\n",
      "226/226 [==============================] - 2s 11ms/step - loss: 0.3764 - accuracy: 0.8268 - val_loss: 0.4983 - val_accuracy: 0.7645\n",
      "Epoch 1087/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3762 - accuracy: 0.8271 - val_loss: 0.5030 - val_accuracy: 0.7578\n",
      "Epoch 1088/1500\n",
      "226/226 [==============================] - 2s 9ms/step - loss: 0.3762 - accuracy: 0.8279 - val_loss: 0.4980 - val_accuracy: 0.7659\n",
      "Epoch 1089/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3765 - accuracy: 0.8257 - val_loss: 0.4976 - val_accuracy: 0.7635\n",
      "Epoch 1090/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3766 - accuracy: 0.8251 - val_loss: 0.4983 - val_accuracy: 0.7668\n",
      "Epoch 1091/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3767 - accuracy: 0.8287 - val_loss: 0.4953 - val_accuracy: 0.7640\n",
      "Epoch 1092/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3760 - accuracy: 0.8244 - val_loss: 0.4979 - val_accuracy: 0.7664\n",
      "Epoch 1093/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3767 - accuracy: 0.8254 - val_loss: 0.4920 - val_accuracy: 0.7711\n",
      "Epoch 1094/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3764 - accuracy: 0.8265 - val_loss: 0.5052 - val_accuracy: 0.7630\n",
      "Epoch 1095/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3762 - accuracy: 0.8280 - val_loss: 0.4994 - val_accuracy: 0.7649\n",
      "Epoch 1096/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3764 - accuracy: 0.8280 - val_loss: 0.5016 - val_accuracy: 0.7626\n",
      "Epoch 1097/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3766 - accuracy: 0.8275 - val_loss: 0.5026 - val_accuracy: 0.7611\n",
      "Epoch 1098/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3762 - accuracy: 0.8268 - val_loss: 0.4989 - val_accuracy: 0.7611\n",
      "Epoch 1099/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3764 - accuracy: 0.8266 - val_loss: 0.4975 - val_accuracy: 0.7659\n",
      "Epoch 1100/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3763 - accuracy: 0.8268 - val_loss: 0.5011 - val_accuracy: 0.7645\n",
      "Epoch 1101/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3762 - accuracy: 0.8269 - val_loss: 0.4955 - val_accuracy: 0.7640\n",
      "Epoch 1102/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3763 - accuracy: 0.8262 - val_loss: 0.5060 - val_accuracy: 0.7635\n",
      "Epoch 1103/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3762 - accuracy: 0.8282 - val_loss: 0.4939 - val_accuracy: 0.7739\n",
      "Epoch 1104/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3765 - accuracy: 0.8257 - val_loss: 0.4954 - val_accuracy: 0.7664\n",
      "Epoch 1105/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3764 - accuracy: 0.8269 - val_loss: 0.4926 - val_accuracy: 0.7687\n",
      "Epoch 1106/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3764 - accuracy: 0.8275 - val_loss: 0.4992 - val_accuracy: 0.7659\n",
      "Epoch 1107/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3766 - accuracy: 0.8264 - val_loss: 0.5025 - val_accuracy: 0.7668\n",
      "Epoch 1108/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3764 - accuracy: 0.8265 - val_loss: 0.4970 - val_accuracy: 0.7687\n",
      "Epoch 1109/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3760 - accuracy: 0.8265 - val_loss: 0.5128 - val_accuracy: 0.7607\n",
      "Epoch 1110/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3762 - accuracy: 0.8258 - val_loss: 0.4978 - val_accuracy: 0.7673\n",
      "Epoch 1111/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3764 - accuracy: 0.8255 - val_loss: 0.5041 - val_accuracy: 0.7578\n",
      "Epoch 1112/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3762 - accuracy: 0.8265 - val_loss: 0.5107 - val_accuracy: 0.7635\n",
      "Epoch 1113/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3763 - accuracy: 0.8264 - val_loss: 0.4944 - val_accuracy: 0.7687\n",
      "Epoch 1114/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3760 - accuracy: 0.8289 - val_loss: 0.4931 - val_accuracy: 0.7701\n",
      "Epoch 1115/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3762 - accuracy: 0.8246 - val_loss: 0.4977 - val_accuracy: 0.7668\n",
      "Epoch 1116/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3762 - accuracy: 0.8251 - val_loss: 0.5054 - val_accuracy: 0.7630\n",
      "Epoch 1117/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3760 - accuracy: 0.8255 - val_loss: 0.4984 - val_accuracy: 0.7692\n",
      "Epoch 1118/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3763 - accuracy: 0.8279 - val_loss: 0.5029 - val_accuracy: 0.7654\n",
      "Epoch 1119/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3762 - accuracy: 0.8296 - val_loss: 0.5053 - val_accuracy: 0.7592\n",
      "Epoch 1120/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3761 - accuracy: 0.8250 - val_loss: 0.4990 - val_accuracy: 0.7640\n",
      "Epoch 1121/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3756 - accuracy: 0.8265 - val_loss: 0.5036 - val_accuracy: 0.7649\n",
      "Epoch 1122/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3763 - accuracy: 0.8265 - val_loss: 0.5016 - val_accuracy: 0.7668\n",
      "Epoch 1123/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3764 - accuracy: 0.8271 - val_loss: 0.4987 - val_accuracy: 0.7649\n",
      "Epoch 1124/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3765 - accuracy: 0.8264 - val_loss: 0.4992 - val_accuracy: 0.7668\n",
      "Epoch 1125/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3757 - accuracy: 0.8253 - val_loss: 0.4947 - val_accuracy: 0.7649\n",
      "Epoch 1126/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3758 - accuracy: 0.8265 - val_loss: 0.4995 - val_accuracy: 0.7668\n",
      "Epoch 1127/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3761 - accuracy: 0.8268 - val_loss: 0.4925 - val_accuracy: 0.7687\n",
      "Epoch 1128/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3764 - accuracy: 0.8265 - val_loss: 0.5017 - val_accuracy: 0.7659\n",
      "Epoch 1129/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3761 - accuracy: 0.8255 - val_loss: 0.4995 - val_accuracy: 0.7621\n",
      "Epoch 1130/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3762 - accuracy: 0.8268 - val_loss: 0.5082 - val_accuracy: 0.7616\n",
      "Epoch 1131/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3764 - accuracy: 0.8280 - val_loss: 0.4970 - val_accuracy: 0.7630\n",
      "Epoch 1132/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3757 - accuracy: 0.8251 - val_loss: 0.4978 - val_accuracy: 0.7682\n",
      "Epoch 1133/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3762 - accuracy: 0.8280 - val_loss: 0.4945 - val_accuracy: 0.7649\n",
      "Epoch 1134/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3764 - accuracy: 0.8262 - val_loss: 0.4975 - val_accuracy: 0.7645\n",
      "Epoch 1135/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3759 - accuracy: 0.8258 - val_loss: 0.5153 - val_accuracy: 0.7559\n",
      "Epoch 1136/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3761 - accuracy: 0.8258 - val_loss: 0.5084 - val_accuracy: 0.7583\n",
      "Epoch 1137/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3759 - accuracy: 0.8271 - val_loss: 0.5115 - val_accuracy: 0.7602\n",
      "Epoch 1138/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3762 - accuracy: 0.8272 - val_loss: 0.5057 - val_accuracy: 0.7578\n",
      "Epoch 1139/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3764 - accuracy: 0.8266 - val_loss: 0.4987 - val_accuracy: 0.7645\n",
      "Epoch 1140/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3758 - accuracy: 0.8248 - val_loss: 0.4950 - val_accuracy: 0.7673\n",
      "Epoch 1141/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3758 - accuracy: 0.8261 - val_loss: 0.4968 - val_accuracy: 0.7659\n",
      "Epoch 1142/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3760 - accuracy: 0.8258 - val_loss: 0.4986 - val_accuracy: 0.7711\n",
      "Epoch 1143/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3763 - accuracy: 0.8250 - val_loss: 0.5025 - val_accuracy: 0.7635\n",
      "Epoch 1144/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3762 - accuracy: 0.8275 - val_loss: 0.4926 - val_accuracy: 0.7659\n",
      "Epoch 1145/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3763 - accuracy: 0.8278 - val_loss: 0.4960 - val_accuracy: 0.7664\n",
      "Epoch 1146/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3760 - accuracy: 0.8261 - val_loss: 0.4920 - val_accuracy: 0.7701\n",
      "Epoch 1147/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3761 - accuracy: 0.8264 - val_loss: 0.4980 - val_accuracy: 0.7635\n",
      "Epoch 1148/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3759 - accuracy: 0.8272 - val_loss: 0.4961 - val_accuracy: 0.7692\n",
      "Epoch 1149/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3756 - accuracy: 0.8262 - val_loss: 0.5007 - val_accuracy: 0.7640\n",
      "Epoch 1150/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3763 - accuracy: 0.8272 - val_loss: 0.4936 - val_accuracy: 0.7706\n",
      "Epoch 1151/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3762 - accuracy: 0.8271 - val_loss: 0.5008 - val_accuracy: 0.7602\n",
      "Epoch 1152/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3761 - accuracy: 0.8293 - val_loss: 0.5039 - val_accuracy: 0.7592\n",
      "Epoch 1153/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3759 - accuracy: 0.8264 - val_loss: 0.4993 - val_accuracy: 0.7664\n",
      "Epoch 1154/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3762 - accuracy: 0.8246 - val_loss: 0.4963 - val_accuracy: 0.7687\n",
      "Epoch 1155/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3760 - accuracy: 0.8276 - val_loss: 0.5084 - val_accuracy: 0.7588\n",
      "Epoch 1156/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3756 - accuracy: 0.8243 - val_loss: 0.5001 - val_accuracy: 0.7635\n",
      "Epoch 1157/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3761 - accuracy: 0.8266 - val_loss: 0.4990 - val_accuracy: 0.7635\n",
      "Epoch 1158/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3762 - accuracy: 0.8258 - val_loss: 0.4997 - val_accuracy: 0.7635\n",
      "Epoch 1159/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3758 - accuracy: 0.8271 - val_loss: 0.4897 - val_accuracy: 0.7716\n",
      "Epoch 1160/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3761 - accuracy: 0.8264 - val_loss: 0.4974 - val_accuracy: 0.7626\n",
      "Epoch 1161/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3758 - accuracy: 0.8266 - val_loss: 0.4997 - val_accuracy: 0.7640\n",
      "Epoch 1162/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3758 - accuracy: 0.8269 - val_loss: 0.5028 - val_accuracy: 0.7611\n",
      "Epoch 1163/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3760 - accuracy: 0.8279 - val_loss: 0.4965 - val_accuracy: 0.7645\n",
      "Epoch 1164/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3762 - accuracy: 0.8279 - val_loss: 0.4993 - val_accuracy: 0.7668\n",
      "Epoch 1165/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3757 - accuracy: 0.8264 - val_loss: 0.4889 - val_accuracy: 0.7697\n",
      "Epoch 1166/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3759 - accuracy: 0.8286 - val_loss: 0.4926 - val_accuracy: 0.7697\n",
      "Epoch 1167/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3760 - accuracy: 0.8257 - val_loss: 0.4964 - val_accuracy: 0.7659\n",
      "Epoch 1168/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3759 - accuracy: 0.8287 - val_loss: 0.5010 - val_accuracy: 0.7611\n",
      "Epoch 1169/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3758 - accuracy: 0.8294 - val_loss: 0.4918 - val_accuracy: 0.7706\n",
      "Epoch 1170/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3758 - accuracy: 0.8265 - val_loss: 0.5003 - val_accuracy: 0.7659\n",
      "Epoch 1171/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3759 - accuracy: 0.8271 - val_loss: 0.5021 - val_accuracy: 0.7607\n",
      "Epoch 1172/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3759 - accuracy: 0.8273 - val_loss: 0.5012 - val_accuracy: 0.7635\n",
      "Epoch 1173/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3761 - accuracy: 0.8258 - val_loss: 0.4964 - val_accuracy: 0.7697\n",
      "Epoch 1174/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3758 - accuracy: 0.8269 - val_loss: 0.5063 - val_accuracy: 0.7597\n",
      "Epoch 1175/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3759 - accuracy: 0.8278 - val_loss: 0.5058 - val_accuracy: 0.7597\n",
      "Epoch 1176/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3757 - accuracy: 0.8280 - val_loss: 0.5011 - val_accuracy: 0.7640\n",
      "Epoch 1177/1500\n",
      "226/226 [==============================] - 2s 8ms/step - loss: 0.3755 - accuracy: 0.8282 - val_loss: 0.5084 - val_accuracy: 0.7583\n",
      "Epoch 1178/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3759 - accuracy: 0.8273 - val_loss: 0.5072 - val_accuracy: 0.7611\n",
      "Epoch 1179/1500\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.3760 - accuracy: 0.8262 - val_loss: 0.5078 - val_accuracy: 0.7640\n",
      "Epoch 1180/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3757 - accuracy: 0.8286 - val_loss: 0.4925 - val_accuracy: 0.7682\n",
      "Epoch 1181/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3758 - accuracy: 0.8268 - val_loss: 0.5049 - val_accuracy: 0.7626\n",
      "Epoch 1182/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3762 - accuracy: 0.8287 - val_loss: 0.5055 - val_accuracy: 0.7611\n",
      "Epoch 1183/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3753 - accuracy: 0.8268 - val_loss: 0.5059 - val_accuracy: 0.7649\n",
      "Epoch 1184/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3756 - accuracy: 0.8272 - val_loss: 0.4953 - val_accuracy: 0.7687\n",
      "Epoch 1185/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3759 - accuracy: 0.8275 - val_loss: 0.5065 - val_accuracy: 0.7607\n",
      "Epoch 1186/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3755 - accuracy: 0.8286 - val_loss: 0.5022 - val_accuracy: 0.7588\n",
      "Epoch 1187/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3760 - accuracy: 0.8264 - val_loss: 0.5042 - val_accuracy: 0.7607\n",
      "Epoch 1188/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3756 - accuracy: 0.8282 - val_loss: 0.5167 - val_accuracy: 0.7578\n",
      "Epoch 1189/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3764 - accuracy: 0.8266 - val_loss: 0.5015 - val_accuracy: 0.7635\n",
      "Epoch 1190/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3756 - accuracy: 0.8278 - val_loss: 0.5025 - val_accuracy: 0.7640\n",
      "Epoch 1191/1500\n",
      "226/226 [==============================] - 1s 7ms/step - loss: 0.3761 - accuracy: 0.8262 - val_loss: 0.5011 - val_accuracy: 0.7592\n",
      "Epoch 1192/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3758 - accuracy: 0.8262 - val_loss: 0.5045 - val_accuracy: 0.7616\n",
      "Epoch 1193/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3761 - accuracy: 0.8273 - val_loss: 0.5044 - val_accuracy: 0.7635\n",
      "Epoch 1194/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3756 - accuracy: 0.8275 - val_loss: 0.4975 - val_accuracy: 0.7678\n",
      "Epoch 1195/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3761 - accuracy: 0.8289 - val_loss: 0.4990 - val_accuracy: 0.7640\n",
      "Epoch 1196/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3758 - accuracy: 0.8262 - val_loss: 0.5044 - val_accuracy: 0.7635\n",
      "Epoch 1197/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3756 - accuracy: 0.8276 - val_loss: 0.5042 - val_accuracy: 0.7616\n",
      "Epoch 1198/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3759 - accuracy: 0.8272 - val_loss: 0.5054 - val_accuracy: 0.7592\n",
      "Epoch 1199/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3759 - accuracy: 0.8283 - val_loss: 0.5015 - val_accuracy: 0.7621\n",
      "Epoch 1200/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3760 - accuracy: 0.8271 - val_loss: 0.4975 - val_accuracy: 0.7626\n",
      "Epoch 1201/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3758 - accuracy: 0.8284 - val_loss: 0.4979 - val_accuracy: 0.7673\n",
      "Epoch 1202/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3757 - accuracy: 0.8282 - val_loss: 0.4954 - val_accuracy: 0.7668\n",
      "Epoch 1203/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3759 - accuracy: 0.8262 - val_loss: 0.5047 - val_accuracy: 0.7626\n",
      "Epoch 1204/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3757 - accuracy: 0.8260 - val_loss: 0.4988 - val_accuracy: 0.7654\n",
      "Epoch 1205/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3754 - accuracy: 0.8276 - val_loss: 0.5060 - val_accuracy: 0.7588\n",
      "Epoch 1206/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3758 - accuracy: 0.8302 - val_loss: 0.4981 - val_accuracy: 0.7630\n",
      "Epoch 1207/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3756 - accuracy: 0.8273 - val_loss: 0.4946 - val_accuracy: 0.7682\n",
      "Epoch 1208/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3756 - accuracy: 0.8276 - val_loss: 0.5033 - val_accuracy: 0.7626\n",
      "Epoch 1209/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3754 - accuracy: 0.8272 - val_loss: 0.5027 - val_accuracy: 0.7635\n",
      "Epoch 1210/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3756 - accuracy: 0.8289 - val_loss: 0.5020 - val_accuracy: 0.7630\n",
      "Epoch 1211/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3755 - accuracy: 0.8280 - val_loss: 0.5002 - val_accuracy: 0.7611\n",
      "Epoch 1212/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3756 - accuracy: 0.8250 - val_loss: 0.4915 - val_accuracy: 0.7697\n",
      "Epoch 1213/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3758 - accuracy: 0.8276 - val_loss: 0.5139 - val_accuracy: 0.7555\n",
      "Epoch 1214/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3757 - accuracy: 0.8289 - val_loss: 0.4986 - val_accuracy: 0.7640\n",
      "Epoch 1215/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3754 - accuracy: 0.8294 - val_loss: 0.4989 - val_accuracy: 0.7635\n",
      "Epoch 1216/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3756 - accuracy: 0.8264 - val_loss: 0.5009 - val_accuracy: 0.7645\n",
      "Epoch 1217/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3757 - accuracy: 0.8266 - val_loss: 0.5028 - val_accuracy: 0.7640\n",
      "Epoch 1218/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3760 - accuracy: 0.8275 - val_loss: 0.4979 - val_accuracy: 0.7640\n",
      "Epoch 1219/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3758 - accuracy: 0.8265 - val_loss: 0.4998 - val_accuracy: 0.7668\n",
      "Epoch 1220/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3756 - accuracy: 0.8260 - val_loss: 0.5052 - val_accuracy: 0.7597\n",
      "Epoch 1221/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3760 - accuracy: 0.8279 - val_loss: 0.5008 - val_accuracy: 0.7626\n",
      "Epoch 1222/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3761 - accuracy: 0.8275 - val_loss: 0.4945 - val_accuracy: 0.7682\n",
      "Epoch 1223/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3758 - accuracy: 0.8276 - val_loss: 0.5028 - val_accuracy: 0.7659\n",
      "Epoch 1224/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3760 - accuracy: 0.8265 - val_loss: 0.4994 - val_accuracy: 0.7649\n",
      "Epoch 1225/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3755 - accuracy: 0.8294 - val_loss: 0.5003 - val_accuracy: 0.7588\n",
      "Epoch 1226/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3758 - accuracy: 0.8266 - val_loss: 0.5003 - val_accuracy: 0.7654\n",
      "Epoch 1227/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3758 - accuracy: 0.8286 - val_loss: 0.4977 - val_accuracy: 0.7654\n",
      "Epoch 1228/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3752 - accuracy: 0.8269 - val_loss: 0.4909 - val_accuracy: 0.7716\n",
      "Epoch 1229/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3760 - accuracy: 0.8258 - val_loss: 0.5003 - val_accuracy: 0.7588\n",
      "Epoch 1230/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3757 - accuracy: 0.8282 - val_loss: 0.4998 - val_accuracy: 0.7664\n",
      "Epoch 1231/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3757 - accuracy: 0.8289 - val_loss: 0.4972 - val_accuracy: 0.7659\n",
      "Epoch 1232/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3758 - accuracy: 0.8262 - val_loss: 0.5044 - val_accuracy: 0.7635\n",
      "Epoch 1233/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3755 - accuracy: 0.8261 - val_loss: 0.5032 - val_accuracy: 0.7640\n",
      "Epoch 1234/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3759 - accuracy: 0.8273 - val_loss: 0.5043 - val_accuracy: 0.7626\n",
      "Epoch 1235/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3755 - accuracy: 0.8275 - val_loss: 0.4986 - val_accuracy: 0.7687\n",
      "Epoch 1236/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3756 - accuracy: 0.8282 - val_loss: 0.4982 - val_accuracy: 0.7640\n",
      "Epoch 1237/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3756 - accuracy: 0.8283 - val_loss: 0.4927 - val_accuracy: 0.7716\n",
      "Epoch 1238/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3759 - accuracy: 0.8260 - val_loss: 0.5009 - val_accuracy: 0.7640\n",
      "Epoch 1239/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3755 - accuracy: 0.8258 - val_loss: 0.4943 - val_accuracy: 0.7645\n",
      "Epoch 1240/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3756 - accuracy: 0.8275 - val_loss: 0.4996 - val_accuracy: 0.7682\n",
      "Epoch 1241/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3760 - accuracy: 0.8278 - val_loss: 0.4988 - val_accuracy: 0.7640\n",
      "Epoch 1242/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3756 - accuracy: 0.8275 - val_loss: 0.5026 - val_accuracy: 0.7626\n",
      "Epoch 1243/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3754 - accuracy: 0.8264 - val_loss: 0.5143 - val_accuracy: 0.7526\n",
      "Epoch 1244/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3758 - accuracy: 0.8273 - val_loss: 0.5018 - val_accuracy: 0.7654\n",
      "Epoch 1245/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3757 - accuracy: 0.8265 - val_loss: 0.5007 - val_accuracy: 0.7640\n",
      "Epoch 1246/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3758 - accuracy: 0.8293 - val_loss: 0.4982 - val_accuracy: 0.7626\n",
      "Epoch 1247/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3756 - accuracy: 0.8278 - val_loss: 0.4970 - val_accuracy: 0.7664\n",
      "Epoch 1248/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8261 - val_loss: 0.4997 - val_accuracy: 0.7597\n",
      "Epoch 1249/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3758 - accuracy: 0.8278 - val_loss: 0.5025 - val_accuracy: 0.7654\n",
      "Epoch 1250/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3759 - accuracy: 0.8298 - val_loss: 0.5026 - val_accuracy: 0.7621\n",
      "Epoch 1251/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3756 - accuracy: 0.8289 - val_loss: 0.5061 - val_accuracy: 0.7630\n",
      "Epoch 1252/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3754 - accuracy: 0.8289 - val_loss: 0.5046 - val_accuracy: 0.7630\n",
      "Epoch 1253/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3759 - accuracy: 0.8262 - val_loss: 0.5068 - val_accuracy: 0.7569\n",
      "Epoch 1254/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3757 - accuracy: 0.8272 - val_loss: 0.5063 - val_accuracy: 0.7616\n",
      "Epoch 1255/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3757 - accuracy: 0.8273 - val_loss: 0.5067 - val_accuracy: 0.7616\n",
      "Epoch 1256/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3757 - accuracy: 0.8283 - val_loss: 0.4977 - val_accuracy: 0.7635\n",
      "Epoch 1257/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3757 - accuracy: 0.8266 - val_loss: 0.5004 - val_accuracy: 0.7635\n",
      "Epoch 1258/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3754 - accuracy: 0.8264 - val_loss: 0.5006 - val_accuracy: 0.7597\n",
      "Epoch 1259/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3755 - accuracy: 0.8280 - val_loss: 0.4989 - val_accuracy: 0.7682\n",
      "Epoch 1260/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3755 - accuracy: 0.8264 - val_loss: 0.5025 - val_accuracy: 0.7588\n",
      "Epoch 1261/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3756 - accuracy: 0.8273 - val_loss: 0.5081 - val_accuracy: 0.7573\n",
      "Epoch 1262/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3758 - accuracy: 0.8265 - val_loss: 0.5141 - val_accuracy: 0.7597\n",
      "Epoch 1263/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3755 - accuracy: 0.8282 - val_loss: 0.4985 - val_accuracy: 0.7706\n",
      "Epoch 1264/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8265 - val_loss: 0.5009 - val_accuracy: 0.7607\n",
      "Epoch 1265/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3752 - accuracy: 0.8301 - val_loss: 0.5007 - val_accuracy: 0.7626\n",
      "Epoch 1266/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3752 - accuracy: 0.8275 - val_loss: 0.5007 - val_accuracy: 0.7654\n",
      "Epoch 1267/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3756 - accuracy: 0.8284 - val_loss: 0.4997 - val_accuracy: 0.7611\n",
      "Epoch 1268/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3756 - accuracy: 0.8307 - val_loss: 0.5030 - val_accuracy: 0.7626\n",
      "Epoch 1269/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3758 - accuracy: 0.8275 - val_loss: 0.5015 - val_accuracy: 0.7602\n",
      "Epoch 1270/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3755 - accuracy: 0.8272 - val_loss: 0.5068 - val_accuracy: 0.7592\n",
      "Epoch 1271/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3753 - accuracy: 0.8279 - val_loss: 0.4987 - val_accuracy: 0.7678\n",
      "Epoch 1272/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3758 - accuracy: 0.8284 - val_loss: 0.4973 - val_accuracy: 0.7645\n",
      "Epoch 1273/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3755 - accuracy: 0.8286 - val_loss: 0.4977 - val_accuracy: 0.7673\n",
      "Epoch 1274/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3755 - accuracy: 0.8293 - val_loss: 0.4964 - val_accuracy: 0.7645\n",
      "Epoch 1275/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3752 - accuracy: 0.8283 - val_loss: 0.4992 - val_accuracy: 0.7668\n",
      "Epoch 1276/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3759 - accuracy: 0.8287 - val_loss: 0.5036 - val_accuracy: 0.7592\n",
      "Epoch 1277/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8271 - val_loss: 0.4982 - val_accuracy: 0.7626\n",
      "Epoch 1278/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3754 - accuracy: 0.8282 - val_loss: 0.4954 - val_accuracy: 0.7630\n",
      "Epoch 1279/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3752 - accuracy: 0.8290 - val_loss: 0.5000 - val_accuracy: 0.7573\n",
      "Epoch 1280/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3754 - accuracy: 0.8287 - val_loss: 0.4991 - val_accuracy: 0.7626\n",
      "Epoch 1281/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3753 - accuracy: 0.8304 - val_loss: 0.5035 - val_accuracy: 0.7621\n",
      "Epoch 1282/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3749 - accuracy: 0.8261 - val_loss: 0.4994 - val_accuracy: 0.7664\n",
      "Epoch 1283/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3760 - accuracy: 0.8290 - val_loss: 0.4953 - val_accuracy: 0.7640\n",
      "Epoch 1284/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3754 - accuracy: 0.8268 - val_loss: 0.4980 - val_accuracy: 0.7682\n",
      "Epoch 1285/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3756 - accuracy: 0.8278 - val_loss: 0.5023 - val_accuracy: 0.7592\n",
      "Epoch 1286/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3753 - accuracy: 0.8276 - val_loss: 0.4937 - val_accuracy: 0.7673\n",
      "Epoch 1287/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3754 - accuracy: 0.8279 - val_loss: 0.4907 - val_accuracy: 0.7697\n",
      "Epoch 1288/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3755 - accuracy: 0.8289 - val_loss: 0.4963 - val_accuracy: 0.7649\n",
      "Epoch 1289/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3748 - accuracy: 0.8272 - val_loss: 0.5009 - val_accuracy: 0.7649\n",
      "Epoch 1290/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3748 - accuracy: 0.8268 - val_loss: 0.4980 - val_accuracy: 0.7654\n",
      "Epoch 1291/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3756 - accuracy: 0.8271 - val_loss: 0.5067 - val_accuracy: 0.7611\n",
      "Epoch 1292/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3752 - accuracy: 0.8297 - val_loss: 0.4968 - val_accuracy: 0.7616\n",
      "Epoch 1293/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3757 - accuracy: 0.8273 - val_loss: 0.4991 - val_accuracy: 0.7626\n",
      "Epoch 1294/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3753 - accuracy: 0.8290 - val_loss: 0.4961 - val_accuracy: 0.7630\n",
      "Epoch 1295/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3752 - accuracy: 0.8271 - val_loss: 0.4954 - val_accuracy: 0.7649\n",
      "Epoch 1296/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3756 - accuracy: 0.8283 - val_loss: 0.4987 - val_accuracy: 0.7640\n",
      "Epoch 1297/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3755 - accuracy: 0.8283 - val_loss: 0.5001 - val_accuracy: 0.7659\n",
      "Epoch 1298/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3756 - accuracy: 0.8273 - val_loss: 0.5011 - val_accuracy: 0.7664\n",
      "Epoch 1299/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3755 - accuracy: 0.8287 - val_loss: 0.5033 - val_accuracy: 0.7630\n",
      "Epoch 1300/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3747 - accuracy: 0.8268 - val_loss: 0.5065 - val_accuracy: 0.7583\n",
      "Epoch 1301/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3753 - accuracy: 0.8278 - val_loss: 0.5101 - val_accuracy: 0.7607\n",
      "Epoch 1302/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3747 - accuracy: 0.8280 - val_loss: 0.4959 - val_accuracy: 0.7687\n",
      "Epoch 1303/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3753 - accuracy: 0.8296 - val_loss: 0.5044 - val_accuracy: 0.7645\n",
      "Epoch 1304/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3750 - accuracy: 0.8304 - val_loss: 0.5030 - val_accuracy: 0.7659\n",
      "Epoch 1305/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3755 - accuracy: 0.8291 - val_loss: 0.4982 - val_accuracy: 0.7659\n",
      "Epoch 1306/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3755 - accuracy: 0.8248 - val_loss: 0.5032 - val_accuracy: 0.7592\n",
      "Epoch 1307/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3753 - accuracy: 0.8291 - val_loss: 0.4946 - val_accuracy: 0.7682\n",
      "Epoch 1308/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3754 - accuracy: 0.8294 - val_loss: 0.4985 - val_accuracy: 0.7635\n",
      "Epoch 1309/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3753 - accuracy: 0.8283 - val_loss: 0.5013 - val_accuracy: 0.7659\n",
      "Epoch 1310/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3752 - accuracy: 0.8282 - val_loss: 0.5016 - val_accuracy: 0.7626\n",
      "Epoch 1311/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3753 - accuracy: 0.8293 - val_loss: 0.5039 - val_accuracy: 0.7597\n",
      "Epoch 1312/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3757 - accuracy: 0.8279 - val_loss: 0.4989 - val_accuracy: 0.7654\n",
      "Epoch 1313/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3753 - accuracy: 0.8266 - val_loss: 0.5000 - val_accuracy: 0.7626\n",
      "Epoch 1314/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3755 - accuracy: 0.8282 - val_loss: 0.5066 - val_accuracy: 0.7602\n",
      "Epoch 1315/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3753 - accuracy: 0.8268 - val_loss: 0.5003 - val_accuracy: 0.7626\n",
      "Epoch 1316/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3751 - accuracy: 0.8289 - val_loss: 0.5027 - val_accuracy: 0.7621\n",
      "Epoch 1317/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3757 - accuracy: 0.8278 - val_loss: 0.5017 - val_accuracy: 0.7640\n",
      "Epoch 1318/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3753 - accuracy: 0.8287 - val_loss: 0.5015 - val_accuracy: 0.7616\n",
      "Epoch 1319/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3754 - accuracy: 0.8283 - val_loss: 0.5020 - val_accuracy: 0.7630\n",
      "Epoch 1320/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3754 - accuracy: 0.8283 - val_loss: 0.4989 - val_accuracy: 0.7654\n",
      "Epoch 1321/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3754 - accuracy: 0.8262 - val_loss: 0.4980 - val_accuracy: 0.7626\n",
      "Epoch 1322/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3750 - accuracy: 0.8275 - val_loss: 0.5106 - val_accuracy: 0.7578\n",
      "Epoch 1323/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3752 - accuracy: 0.8297 - val_loss: 0.4967 - val_accuracy: 0.7654\n",
      "Epoch 1324/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3756 - accuracy: 0.8275 - val_loss: 0.5058 - val_accuracy: 0.7597\n",
      "Epoch 1325/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3755 - accuracy: 0.8286 - val_loss: 0.5018 - val_accuracy: 0.7645\n",
      "Epoch 1326/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3748 - accuracy: 0.8308 - val_loss: 0.5089 - val_accuracy: 0.7578\n",
      "Epoch 1327/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3750 - accuracy: 0.8290 - val_loss: 0.4977 - val_accuracy: 0.7616\n",
      "Epoch 1328/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3755 - accuracy: 0.8260 - val_loss: 0.5056 - val_accuracy: 0.7616\n",
      "Epoch 1329/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3753 - accuracy: 0.8301 - val_loss: 0.4997 - val_accuracy: 0.7659\n",
      "Epoch 1330/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3756 - accuracy: 0.8287 - val_loss: 0.5038 - val_accuracy: 0.7578\n",
      "Epoch 1331/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3750 - accuracy: 0.8289 - val_loss: 0.4972 - val_accuracy: 0.7616\n",
      "Epoch 1332/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3755 - accuracy: 0.8276 - val_loss: 0.5029 - val_accuracy: 0.7616\n",
      "Epoch 1333/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3753 - accuracy: 0.8296 - val_loss: 0.5070 - val_accuracy: 0.7592\n",
      "Epoch 1334/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3754 - accuracy: 0.8298 - val_loss: 0.4977 - val_accuracy: 0.7654\n",
      "Epoch 1335/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3754 - accuracy: 0.8300 - val_loss: 0.4944 - val_accuracy: 0.7668\n",
      "Epoch 1336/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3752 - accuracy: 0.8298 - val_loss: 0.4956 - val_accuracy: 0.7673\n",
      "Epoch 1337/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3750 - accuracy: 0.8286 - val_loss: 0.5038 - val_accuracy: 0.7597\n",
      "Epoch 1338/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3751 - accuracy: 0.8297 - val_loss: 0.5032 - val_accuracy: 0.7635\n",
      "Epoch 1339/1500\n",
      "226/226 [==============================] - 2s 7ms/step - loss: 0.3753 - accuracy: 0.8293 - val_loss: 0.4975 - val_accuracy: 0.7664\n",
      "Epoch 1340/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3752 - accuracy: 0.8283 - val_loss: 0.5042 - val_accuracy: 0.7616\n",
      "Epoch 1341/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3750 - accuracy: 0.8302 - val_loss: 0.4975 - val_accuracy: 0.7649\n",
      "Epoch 1342/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3751 - accuracy: 0.8290 - val_loss: 0.4969 - val_accuracy: 0.7678\n",
      "Epoch 1343/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3754 - accuracy: 0.8272 - val_loss: 0.4959 - val_accuracy: 0.7664\n",
      "Epoch 1344/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3746 - accuracy: 0.8304 - val_loss: 0.5110 - val_accuracy: 0.7583\n",
      "Epoch 1345/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3753 - accuracy: 0.8282 - val_loss: 0.5056 - val_accuracy: 0.7607\n",
      "Epoch 1346/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3754 - accuracy: 0.8300 - val_loss: 0.5057 - val_accuracy: 0.7621\n",
      "Epoch 1347/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3750 - accuracy: 0.8248 - val_loss: 0.5019 - val_accuracy: 0.7592\n",
      "Epoch 1348/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3752 - accuracy: 0.8268 - val_loss: 0.4972 - val_accuracy: 0.7640\n",
      "Epoch 1349/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3751 - accuracy: 0.8258 - val_loss: 0.5021 - val_accuracy: 0.7640\n",
      "Epoch 1350/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3750 - accuracy: 0.8273 - val_loss: 0.5041 - val_accuracy: 0.7607\n",
      "Epoch 1351/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3752 - accuracy: 0.8278 - val_loss: 0.5087 - val_accuracy: 0.7592\n",
      "Epoch 1352/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3751 - accuracy: 0.8265 - val_loss: 0.5039 - val_accuracy: 0.7640\n",
      "Epoch 1353/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3751 - accuracy: 0.8278 - val_loss: 0.4979 - val_accuracy: 0.7630\n",
      "Epoch 1354/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3752 - accuracy: 0.8296 - val_loss: 0.4992 - val_accuracy: 0.7626\n",
      "Epoch 1355/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3753 - accuracy: 0.8307 - val_loss: 0.4999 - val_accuracy: 0.7621\n",
      "Epoch 1356/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3752 - accuracy: 0.8294 - val_loss: 0.5018 - val_accuracy: 0.7607\n",
      "Epoch 1357/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3752 - accuracy: 0.8278 - val_loss: 0.5012 - val_accuracy: 0.7611\n",
      "Epoch 1358/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3755 - accuracy: 0.8273 - val_loss: 0.5051 - val_accuracy: 0.7602\n",
      "Epoch 1359/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3751 - accuracy: 0.8275 - val_loss: 0.5029 - val_accuracy: 0.7649\n",
      "Epoch 1360/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3753 - accuracy: 0.8300 - val_loss: 0.4985 - val_accuracy: 0.7664\n",
      "Epoch 1361/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3753 - accuracy: 0.8293 - val_loss: 0.4954 - val_accuracy: 0.7659\n",
      "Epoch 1362/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3752 - accuracy: 0.8284 - val_loss: 0.4994 - val_accuracy: 0.7659\n",
      "Epoch 1363/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3753 - accuracy: 0.8290 - val_loss: 0.5050 - val_accuracy: 0.7583\n",
      "Epoch 1364/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3753 - accuracy: 0.8255 - val_loss: 0.5045 - val_accuracy: 0.7602\n",
      "Epoch 1365/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3746 - accuracy: 0.8289 - val_loss: 0.4993 - val_accuracy: 0.7678\n",
      "Epoch 1366/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8276 - val_loss: 0.5061 - val_accuracy: 0.7616\n",
      "Epoch 1367/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3752 - accuracy: 0.8289 - val_loss: 0.5006 - val_accuracy: 0.7640\n",
      "Epoch 1368/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3747 - accuracy: 0.8296 - val_loss: 0.4992 - val_accuracy: 0.7649\n",
      "Epoch 1369/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3749 - accuracy: 0.8271 - val_loss: 0.4981 - val_accuracy: 0.7659\n",
      "Epoch 1370/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3753 - accuracy: 0.8296 - val_loss: 0.4916 - val_accuracy: 0.7687\n",
      "Epoch 1371/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3754 - accuracy: 0.8308 - val_loss: 0.4962 - val_accuracy: 0.7673\n",
      "Epoch 1372/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8283 - val_loss: 0.4962 - val_accuracy: 0.7654\n",
      "Epoch 1373/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8261 - val_loss: 0.4982 - val_accuracy: 0.7654\n",
      "Epoch 1374/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3751 - accuracy: 0.8291 - val_loss: 0.5056 - val_accuracy: 0.7569\n",
      "Epoch 1375/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3754 - accuracy: 0.8284 - val_loss: 0.4985 - val_accuracy: 0.7645\n",
      "Epoch 1376/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3752 - accuracy: 0.8291 - val_loss: 0.5042 - val_accuracy: 0.7630\n",
      "Epoch 1377/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3750 - accuracy: 0.8301 - val_loss: 0.4996 - val_accuracy: 0.7621\n",
      "Epoch 1378/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3752 - accuracy: 0.8273 - val_loss: 0.4959 - val_accuracy: 0.7668\n",
      "Epoch 1379/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3752 - accuracy: 0.8275 - val_loss: 0.4994 - val_accuracy: 0.7616\n",
      "Epoch 1380/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3749 - accuracy: 0.8284 - val_loss: 0.4930 - val_accuracy: 0.7678\n",
      "Epoch 1381/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3755 - accuracy: 0.8283 - val_loss: 0.5007 - val_accuracy: 0.7616\n",
      "Epoch 1382/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3750 - accuracy: 0.8304 - val_loss: 0.4990 - val_accuracy: 0.7640\n",
      "Epoch 1383/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3749 - accuracy: 0.8276 - val_loss: 0.4938 - val_accuracy: 0.7649\n",
      "Epoch 1384/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8284 - val_loss: 0.5005 - val_accuracy: 0.7635\n",
      "Epoch 1385/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3748 - accuracy: 0.8308 - val_loss: 0.5065 - val_accuracy: 0.7626\n",
      "Epoch 1386/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3750 - accuracy: 0.8291 - val_loss: 0.4909 - val_accuracy: 0.7668\n",
      "Epoch 1387/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3748 - accuracy: 0.8287 - val_loss: 0.5063 - val_accuracy: 0.7583\n",
      "Epoch 1388/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3749 - accuracy: 0.8272 - val_loss: 0.5106 - val_accuracy: 0.7616\n",
      "Epoch 1389/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3750 - accuracy: 0.8287 - val_loss: 0.5059 - val_accuracy: 0.7626\n",
      "Epoch 1390/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8290 - val_loss: 0.5113 - val_accuracy: 0.7611\n",
      "Epoch 1391/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3748 - accuracy: 0.8282 - val_loss: 0.5043 - val_accuracy: 0.7588\n",
      "Epoch 1392/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3753 - accuracy: 0.8304 - val_loss: 0.4992 - val_accuracy: 0.7649\n",
      "Epoch 1393/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3750 - accuracy: 0.8297 - val_loss: 0.5070 - val_accuracy: 0.7602\n",
      "Epoch 1394/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3747 - accuracy: 0.8289 - val_loss: 0.4951 - val_accuracy: 0.7659\n",
      "Epoch 1395/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3752 - accuracy: 0.8311 - val_loss: 0.4973 - val_accuracy: 0.7645\n",
      "Epoch 1396/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3750 - accuracy: 0.8287 - val_loss: 0.5045 - val_accuracy: 0.7640\n",
      "Epoch 1397/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3753 - accuracy: 0.8271 - val_loss: 0.5018 - val_accuracy: 0.7635\n",
      "Epoch 1398/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3750 - accuracy: 0.8312 - val_loss: 0.5008 - val_accuracy: 0.7645\n",
      "Epoch 1399/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8286 - val_loss: 0.4987 - val_accuracy: 0.7616\n",
      "Epoch 1400/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3754 - accuracy: 0.8272 - val_loss: 0.5004 - val_accuracy: 0.7640\n",
      "Epoch 1401/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3748 - accuracy: 0.8279 - val_loss: 0.4942 - val_accuracy: 0.7649\n",
      "Epoch 1402/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8278 - val_loss: 0.4962 - val_accuracy: 0.7649\n",
      "Epoch 1403/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3747 - accuracy: 0.8287 - val_loss: 0.5094 - val_accuracy: 0.7616\n",
      "Epoch 1404/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3749 - accuracy: 0.8286 - val_loss: 0.5082 - val_accuracy: 0.7569\n",
      "Epoch 1405/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8291 - val_loss: 0.4956 - val_accuracy: 0.7664\n",
      "Epoch 1406/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8291 - val_loss: 0.4954 - val_accuracy: 0.7659\n",
      "Epoch 1407/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3745 - accuracy: 0.8284 - val_loss: 0.5115 - val_accuracy: 0.7626\n",
      "Epoch 1408/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3752 - accuracy: 0.8290 - val_loss: 0.5004 - val_accuracy: 0.7659\n",
      "Epoch 1409/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8273 - val_loss: 0.4994 - val_accuracy: 0.7664\n",
      "Epoch 1410/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3749 - accuracy: 0.8304 - val_loss: 0.4943 - val_accuracy: 0.7687\n",
      "Epoch 1411/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3747 - accuracy: 0.8278 - val_loss: 0.5077 - val_accuracy: 0.7592\n",
      "Epoch 1412/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8302 - val_loss: 0.5047 - val_accuracy: 0.7597\n",
      "Epoch 1413/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3752 - accuracy: 0.8279 - val_loss: 0.5023 - val_accuracy: 0.7616\n",
      "Epoch 1414/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3748 - accuracy: 0.8283 - val_loss: 0.5009 - val_accuracy: 0.7602\n",
      "Epoch 1415/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3752 - accuracy: 0.8311 - val_loss: 0.5041 - val_accuracy: 0.7616\n",
      "Epoch 1416/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3745 - accuracy: 0.8264 - val_loss: 0.5016 - val_accuracy: 0.7616\n",
      "Epoch 1417/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8297 - val_loss: 0.4988 - val_accuracy: 0.7630\n",
      "Epoch 1418/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3750 - accuracy: 0.8293 - val_loss: 0.4959 - val_accuracy: 0.7673\n",
      "Epoch 1419/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3748 - accuracy: 0.8294 - val_loss: 0.5028 - val_accuracy: 0.7654\n",
      "Epoch 1420/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3750 - accuracy: 0.8297 - val_loss: 0.4994 - val_accuracy: 0.7645\n",
      "Epoch 1421/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3750 - accuracy: 0.8301 - val_loss: 0.5003 - val_accuracy: 0.7635\n",
      "Epoch 1422/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3747 - accuracy: 0.8283 - val_loss: 0.5039 - val_accuracy: 0.7654\n",
      "Epoch 1423/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3747 - accuracy: 0.8278 - val_loss: 0.5018 - val_accuracy: 0.7645\n",
      "Epoch 1424/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3750 - accuracy: 0.8284 - val_loss: 0.4921 - val_accuracy: 0.7697\n",
      "Epoch 1425/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3745 - accuracy: 0.8322 - val_loss: 0.5106 - val_accuracy: 0.7564\n",
      "Epoch 1426/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3748 - accuracy: 0.8298 - val_loss: 0.5097 - val_accuracy: 0.7592\n",
      "Epoch 1427/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3749 - accuracy: 0.8302 - val_loss: 0.5029 - val_accuracy: 0.7616\n",
      "Epoch 1428/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3749 - accuracy: 0.8287 - val_loss: 0.4919 - val_accuracy: 0.7687\n",
      "Epoch 1429/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3746 - accuracy: 0.8284 - val_loss: 0.5094 - val_accuracy: 0.7592\n",
      "Epoch 1430/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3747 - accuracy: 0.8305 - val_loss: 0.5009 - val_accuracy: 0.7602\n",
      "Epoch 1431/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3751 - accuracy: 0.8289 - val_loss: 0.5044 - val_accuracy: 0.7626\n",
      "Epoch 1432/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3748 - accuracy: 0.8284 - val_loss: 0.5002 - val_accuracy: 0.7616\n",
      "Epoch 1433/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3745 - accuracy: 0.8284 - val_loss: 0.4996 - val_accuracy: 0.7682\n",
      "Epoch 1434/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3751 - accuracy: 0.8294 - val_loss: 0.4936 - val_accuracy: 0.7664\n",
      "Epoch 1435/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3748 - accuracy: 0.8283 - val_loss: 0.5020 - val_accuracy: 0.7649\n",
      "Epoch 1436/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3746 - accuracy: 0.8300 - val_loss: 0.4903 - val_accuracy: 0.7659\n",
      "Epoch 1437/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3748 - accuracy: 0.8309 - val_loss: 0.5094 - val_accuracy: 0.7559\n",
      "Epoch 1438/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3750 - accuracy: 0.8315 - val_loss: 0.5054 - val_accuracy: 0.7611\n",
      "Epoch 1439/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3747 - accuracy: 0.8271 - val_loss: 0.4991 - val_accuracy: 0.7630\n",
      "Epoch 1440/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3748 - accuracy: 0.8294 - val_loss: 0.4964 - val_accuracy: 0.7687\n",
      "Epoch 1441/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3750 - accuracy: 0.8286 - val_loss: 0.4989 - val_accuracy: 0.7654\n",
      "Epoch 1442/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3746 - accuracy: 0.8283 - val_loss: 0.4938 - val_accuracy: 0.7673\n",
      "Epoch 1443/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3750 - accuracy: 0.8291 - val_loss: 0.5041 - val_accuracy: 0.7616\n",
      "Epoch 1444/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3747 - accuracy: 0.8284 - val_loss: 0.5037 - val_accuracy: 0.7592\n",
      "Epoch 1445/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3743 - accuracy: 0.8290 - val_loss: 0.5080 - val_accuracy: 0.7569\n",
      "Epoch 1446/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3751 - accuracy: 0.8286 - val_loss: 0.5038 - val_accuracy: 0.7630\n",
      "Epoch 1447/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3744 - accuracy: 0.8293 - val_loss: 0.5028 - val_accuracy: 0.7626\n",
      "Epoch 1448/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3749 - accuracy: 0.8311 - val_loss: 0.5090 - val_accuracy: 0.7621\n",
      "Epoch 1449/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3748 - accuracy: 0.8291 - val_loss: 0.5024 - val_accuracy: 0.7635\n",
      "Epoch 1450/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3745 - accuracy: 0.8298 - val_loss: 0.4917 - val_accuracy: 0.7711\n",
      "Epoch 1451/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3744 - accuracy: 0.8305 - val_loss: 0.5075 - val_accuracy: 0.7573\n",
      "Epoch 1452/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3748 - accuracy: 0.8300 - val_loss: 0.5159 - val_accuracy: 0.7626\n",
      "Epoch 1453/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3745 - accuracy: 0.8301 - val_loss: 0.5128 - val_accuracy: 0.7583\n",
      "Epoch 1454/1500\n",
      "226/226 [==============================] - 1s 6ms/step - loss: 0.3746 - accuracy: 0.8286 - val_loss: 0.4904 - val_accuracy: 0.7720\n",
      "Epoch 1455/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3749 - accuracy: 0.8307 - val_loss: 0.5083 - val_accuracy: 0.7607\n",
      "Epoch 1456/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3746 - accuracy: 0.8291 - val_loss: 0.5008 - val_accuracy: 0.7640\n",
      "Epoch 1457/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3748 - accuracy: 0.8296 - val_loss: 0.4991 - val_accuracy: 0.7654\n",
      "Epoch 1458/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3746 - accuracy: 0.8293 - val_loss: 0.5004 - val_accuracy: 0.7621\n",
      "Epoch 1459/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3751 - accuracy: 0.8286 - val_loss: 0.5089 - val_accuracy: 0.7597\n",
      "Epoch 1460/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3745 - accuracy: 0.8293 - val_loss: 0.5120 - val_accuracy: 0.7573\n",
      "Epoch 1461/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3751 - accuracy: 0.8275 - val_loss: 0.5075 - val_accuracy: 0.7626\n",
      "Epoch 1462/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3751 - accuracy: 0.8305 - val_loss: 0.5016 - val_accuracy: 0.7640\n",
      "Epoch 1463/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3747 - accuracy: 0.8289 - val_loss: 0.5074 - val_accuracy: 0.7597\n",
      "Epoch 1464/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3742 - accuracy: 0.8311 - val_loss: 0.5125 - val_accuracy: 0.7626\n",
      "Epoch 1465/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3751 - accuracy: 0.8294 - val_loss: 0.5008 - val_accuracy: 0.7635\n",
      "Epoch 1466/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3742 - accuracy: 0.8290 - val_loss: 0.5113 - val_accuracy: 0.7607\n",
      "Epoch 1467/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3750 - accuracy: 0.8284 - val_loss: 0.4978 - val_accuracy: 0.7664\n",
      "Epoch 1468/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3752 - accuracy: 0.8282 - val_loss: 0.4968 - val_accuracy: 0.7630\n",
      "Epoch 1469/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3745 - accuracy: 0.8304 - val_loss: 0.5064 - val_accuracy: 0.7630\n",
      "Epoch 1470/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3748 - accuracy: 0.8300 - val_loss: 0.5038 - val_accuracy: 0.7607\n",
      "Epoch 1471/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3749 - accuracy: 0.8300 - val_loss: 0.4988 - val_accuracy: 0.7630\n",
      "Epoch 1472/1500\n",
      "226/226 [==============================] - 1s 5ms/step - loss: 0.3745 - accuracy: 0.8291 - val_loss: 0.5082 - val_accuracy: 0.7597\n",
      "Epoch 1473/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3744 - accuracy: 0.8296 - val_loss: 0.5032 - val_accuracy: 0.7668\n",
      "Epoch 1474/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3748 - accuracy: 0.8300 - val_loss: 0.5009 - val_accuracy: 0.7611\n",
      "Epoch 1475/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3745 - accuracy: 0.8301 - val_loss: 0.5063 - val_accuracy: 0.7616\n",
      "Epoch 1476/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3747 - accuracy: 0.8297 - val_loss: 0.4954 - val_accuracy: 0.7640\n",
      "Epoch 1477/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3748 - accuracy: 0.8282 - val_loss: 0.5090 - val_accuracy: 0.7588\n",
      "Epoch 1478/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3748 - accuracy: 0.8289 - val_loss: 0.5039 - val_accuracy: 0.7640\n",
      "Epoch 1479/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3746 - accuracy: 0.8300 - val_loss: 0.4981 - val_accuracy: 0.7635\n",
      "Epoch 1480/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3745 - accuracy: 0.8289 - val_loss: 0.5099 - val_accuracy: 0.7611\n",
      "Epoch 1481/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3748 - accuracy: 0.8300 - val_loss: 0.4992 - val_accuracy: 0.7635\n",
      "Epoch 1482/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3747 - accuracy: 0.8287 - val_loss: 0.4989 - val_accuracy: 0.7659\n",
      "Epoch 1483/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3744 - accuracy: 0.8293 - val_loss: 0.4933 - val_accuracy: 0.7649\n",
      "Epoch 1484/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3748 - accuracy: 0.8279 - val_loss: 0.4983 - val_accuracy: 0.7635\n",
      "Epoch 1485/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3746 - accuracy: 0.8298 - val_loss: 0.5036 - val_accuracy: 0.7640\n",
      "Epoch 1486/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3748 - accuracy: 0.8286 - val_loss: 0.5105 - val_accuracy: 0.7607\n",
      "Epoch 1487/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3745 - accuracy: 0.8294 - val_loss: 0.4952 - val_accuracy: 0.7630\n",
      "Epoch 1488/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3750 - accuracy: 0.8302 - val_loss: 0.4983 - val_accuracy: 0.7645\n",
      "Epoch 1489/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3747 - accuracy: 0.8290 - val_loss: 0.5052 - val_accuracy: 0.7592\n",
      "Epoch 1490/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3748 - accuracy: 0.8282 - val_loss: 0.5006 - val_accuracy: 0.7649\n",
      "Epoch 1491/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3744 - accuracy: 0.8284 - val_loss: 0.4950 - val_accuracy: 0.7664\n",
      "Epoch 1492/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3746 - accuracy: 0.8291 - val_loss: 0.5016 - val_accuracy: 0.7635\n",
      "Epoch 1493/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3745 - accuracy: 0.8287 - val_loss: 0.5036 - val_accuracy: 0.7611\n",
      "Epoch 1494/1500\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.3747 - accuracy: 0.8271 - val_loss: 0.4970 - val_accuracy: 0.7649\n",
      "Epoch 1495/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3743 - accuracy: 0.8301 - val_loss: 0.5082 - val_accuracy: 0.7583\n",
      "Epoch 1496/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3750 - accuracy: 0.8284 - val_loss: 0.4978 - val_accuracy: 0.7635\n",
      "Epoch 1497/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3745 - accuracy: 0.8312 - val_loss: 0.5009 - val_accuracy: 0.7626\n",
      "Epoch 1498/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3746 - accuracy: 0.8294 - val_loss: 0.4982 - val_accuracy: 0.7654\n",
      "Epoch 1499/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3745 - accuracy: 0.8289 - val_loss: 0.5052 - val_accuracy: 0.7626\n",
      "Epoch 1500/1500\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.3742 - accuracy: 0.8300 - val_loss: 0.5110 - val_accuracy: 0.7616\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(30,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "669128c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b10dc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6319ee53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 2ms/step\n",
      "66/66 [==============================] - 0s 2ms/step\n",
      "\n",
      "accuracy is 0.762\n",
      "roc-auc is 0.822\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class_nn_2 = (model_2.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
    "\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b1269e",
   "metadata": {},
   "source": [
    "The accuracy increased a bit and AUC decreased a bit. Generally the performance is similar to 1 layer NN with 1000 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a96964",
   "metadata": {},
   "source": [
    "## model evaluation & insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c670e32",
   "metadata": {},
   "source": [
    "To recap the evaluation metrics:\n",
    "\n",
    "Random Forest:\n",
    "- accuracy is 0.769\n",
    "- roc-auc is 0.814\n",
    "\n",
    "Deep learning model (Single Hidden Layer Neural Network, epochs = 200):\n",
    "- accuracy is 0.745\n",
    "- roc-auc is 0.828\n",
    "\n",
    "Deep learning model (Single Hidden Layer Neural Network, epochs = 1000):\n",
    "- accuracy is 0.751\n",
    "- roc-auc is 0.830\n",
    "\n",
    "Deep learning model (two hidden layers, each with 6 nodes, epochs = 1500):\n",
    "- accuracy is 0.762\n",
    "- roc-auc is 0.822\n",
    "\n",
    "Compared among NN models, the accuracy increased with more complex model, while the AUC performs similarly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e936c",
   "metadata": {},
   "source": [
    "# Suggested-action for extra-mile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73524a5b",
   "metadata": {},
   "source": [
    "To further improves the model, generally for NN models, We can try adding more hidden layer with more nodes and different activation function with grid search. After trying more combination, we will find the optized hyperparameteres e.g. epochs, number of nodes in different hidden layers, different activation in different nodes.\n",
    "\n",
    "\n",
    "For above NN model case, compared to Random forest model, Random forest model are more generalized as they randomly select features & sub-sampling for each tree. NN models perform worse may be due to overfitting so we can apply regularization in further experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082b9f75",
   "metadata": {},
   "source": [
    "Appendix:  (NN models speciality)\n",
    "\n",
    "For epochs tuning:\n",
    "The deep learning model improves with adding more epochs when the validation error still going down. And the models starts not improving, when the validation error stabilzes. \n",
    "\n",
    "For model complexility tuning:\n",
    "Adding 1 more hidden layer & setting ReLU activation instead of sigmoid in the hidden layer, which not only between [0,1] , so that increase the variance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
